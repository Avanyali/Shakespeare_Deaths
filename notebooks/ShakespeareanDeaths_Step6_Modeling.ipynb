{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8454501-c447-41cc-9036-ec37c392b79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "from skopt import BayesSearchCV\n",
    "from scipy.stats import uniform, loguniform, randint\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "562c2faa-c261-4e36-b5ad-c11bcda49a31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "line_df = pd.read_csv('../data/csv/ShakespeareCharacterLines_engineered.csv', index_col = ['play', 'name', 'line_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6e48589-cca3-4932-9675-edc7607d804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_df = pd.read_csv('../data/csv/ShakespeareCharacterLines_character_corpus.csv', index_col = ['play', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97aeff29-f0eb-4794-8088-0eb327b78ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colon = slice(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb0ec4b-898f-4432-ab88-af279ff5ddc0",
   "metadata": {},
   "source": [
    "- tragedy/comedy column for predictions, MNB, look for other things that work well on language data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02cd3b99-e00c-4efd-b3a5-f07bfd28f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = list(line_df.columns[:10])\n",
    "to_drop.remove('character_dies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cb47dd7-66e7-463e-9502-cc57bb111be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_df.drop(columns = to_drop, inplace = True)\n",
    "line_df = line_df.astype(dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52c0ccde-d83f-40ed-aed7-d11c7e3ace8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_xlist = line_df.columns.tolist()\n",
    "line_xlist.remove('character_dies')\n",
    "\n",
    "char_xlist = char_df.columns.tolist()\n",
    "char_xlist.remove('character_dies')\n",
    "\n",
    "line_X = line_df[line_xlist]\n",
    "char_X = char_df[char_xlist]\n",
    "\n",
    "line_y = line_df['character_dies']\n",
    "char_y = char_df['character_dies']\n",
    "\n",
    "line_X_train, line_X_test, line_y_train, line_y_test = train_test_split(line_X, line_y, random_state = 42, stratify = line_y)\n",
    "char_X_train, char_X_test, char_y_train, char_y_test = train_test_split(char_X, char_y, random_state = 42, stratify = char_y)\n",
    "\n",
    "sc = StandardScaler()\n",
    "line_Xs_train = sc.fit_transform(line_X_train)\n",
    "line_Xs_test = sc.transform(line_X_test)\n",
    "\n",
    "char_Xs_train = sc.fit_transform(char_X_train)\n",
    "char_Xs_test = sc.transform(char_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda0b566-16b3-433b-8464-4f939c4a71cd",
   "metadata": {},
   "source": [
    "- Move PCA here with images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900b38b6-0b05-41d2-b004-038546b2c5b7",
   "metadata": {},
   "source": [
    "- Baseline accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a366d61-4c65-41af-9cbd-4cce750a8db7",
   "metadata": {},
   "source": [
    "- Char logreg pipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3fe9a23-266c-4caf-b9cd-fc454f38e741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.905958\n",
       "1.0    0.094042\n",
       "Name: character_dies, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_df['character_dies'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "759055c6-8783-429c-8d07-a660bbbd4f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipe = Pipeline([\n",
    "    ('sc', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(random_state = 42, solver = 'liblinear', penalty = 'l1'))\n",
    "])\n",
    "\n",
    "logreg_params = {\n",
    "    'logreg__tol': uniform(0, .1),\n",
    "    'logreg__C': loguniform(0.0001, 100),\n",
    "    'logreg__class_weight': Categorical(['balanced', None]),\n",
    "    'logreg__max_iter': randint(1, 1000),\n",
    "    'logreg__l1_ratio': uniform(0, 1)\n",
    "}\n",
    "\n",
    "logreg_rs_rocauc = RandomizedSearchCV(estimator = logreg_pipe,\n",
    "                     param_distributions = logreg_params,\n",
    "                     scoring = 'roc_auc',\n",
    "                     n_iter = 50,\n",
    "                     n_jobs = 8,\n",
    "                     cv = 5,\n",
    "                     refit = True,\n",
    "                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7af6435-d7a0-460c-ad13-a05762d316f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\"l1_ratio parameter is only used when penalty is \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('sc', StandardScaler()),\n",
       "                                             ('logreg',\n",
       "                                              LogisticRegression(penalty='l1',\n",
       "                                                                 random_state=42,\n",
       "                                                                 solver='liblinear'))]),\n",
       "                   n_iter=50, n_jobs=8,\n",
       "                   param_distributions={'logreg__C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002B2C298A340>,\n",
       "                                        'logreg__class_weight': Categorical(categories=('balanced', None), prior=None),\n",
       "                                        'logreg__l1_ratio': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002B2C298A940>,\n",
       "                                        'logreg__max_iter': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002B1A806BC10>,\n",
       "                                        'logreg__tol': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002B431029D30>},\n",
       "                   random_state=42, scoring='roc_auc')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logreg_rs_rocauc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d9111f9-109a-4795-936f-21be10fdbf29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7990356819260473, 0.7135596471039509)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds = logreg_rs_rocauc.best_estimator_['logreg'].predict(Xs_train)\n",
    "test_preds = logreg_rs_rocauc.best_estimator_['logreg'].predict(Xs_test)\n",
    "\n",
    "metrics.roc_auc_score(y_train, train_preds), metrics.roc_auc_score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f975d17-0d4e-40f4-af85-bd48f0d9be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {key: value for key, value in zip(x_list, logreg_rs_rocauc.best_estimator_['logreg'].coef_[0])}\n",
    "weights = {k: v for k, v in sorted(weights.items(), key=lambda item: item[1], reverse = True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7685e6c2-8fa6-40b0-a71b-9cdc26f2138b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'death_std': 0.12850891631837966,\n",
       " 'unwelcome_person_hyp_std': 0.07553806786164316,\n",
       " 'neg_sentiment_std': 0.06891258369021096,\n",
       " 'ah_std': 0.056450769581478766,\n",
       " 'INTJ_std': 0.05121047413502336,\n",
       " 'life_std': 0.050121440951676435,\n",
       " 'denmark_syn_std': 0.043529132855568815,\n",
       " 'word_std': 0.03470232159352246,\n",
       " 'brow_std': 0.03214397083347529,\n",
       " 'revenge_std': 0.031231511595154398,\n",
       " 'mean_std': 0.025622324887338583,\n",
       " 'eunuch_std': 0.02516520401919758,\n",
       " 'win_hyp_std': 0.02442470233452667,\n",
       " 'tragedy_std': 0.023730703162129035,\n",
       " 'son_std': 0.018765378625682883,\n",
       " 'abused_std': 0.018638307656687742,\n",
       " 'murder_std': 0.017986973946210252,\n",
       " 'being_hyp_std': 0.017760066284526407,\n",
       " 'express_emotion_hyp_std': 0.01693803887373723,\n",
       " 'villain_std': 0.01620860183951193,\n",
       " 'dig_mean': 0.01565939980957762,\n",
       " 'misconstrue_std': 0.014996624343505533,\n",
       " 'unadvise_std': 0.0139210492888509,\n",
       " 'undergo_hyp_mean': 0.01389503467035266,\n",
       " 'standing_hyp_std': 0.01384963142253865,\n",
       " 'writer_hyp_std': 0.012609478055652306,\n",
       " 'generous_syn_mean': 0.012414977313907815,\n",
       " 'mercy_mean': 0.011665378676693849,\n",
       " 'speech_hyp_std': 0.010519193911523742,\n",
       " 'notion_std': 0.010414150612854165,\n",
       " 'ocean_mean': 0.010351901785469417,\n",
       " 'monstrous_std': 0.00991275077872521,\n",
       " 'resign_std': 0.009778219591424678,\n",
       " 'empress_std': 0.00972683896352509,\n",
       " 'propriety_hyp_mean': 0.009394810661804575,\n",
       " 'male_offspring_hyp_std': 0.00930592326600961,\n",
       " 'misconstrue_mean': 0.008740963224318889,\n",
       " 'abominable_syn_mean': 0.00872279329627119,\n",
       " 'emotional_state_hyp_median': 0.008067133779997572,\n",
       " 'clasp_mean': 0.007604044065669856,\n",
       " 'wren_syn_mean': 0.007219202249399632,\n",
       " 'isis_std': 0.00716701257979676,\n",
       " 'encourage_hyp_std': 0.006563417624869842,\n",
       " 'rear_mean': 0.006238586651102999,\n",
       " 'unlucky_syn_std': 0.00596390144811855,\n",
       " 'sword_hyp_std': 0.005918848067797021,\n",
       " 'unretentive_syn_mean': 0.005665153431394587,\n",
       " 'shame_std': 0.005477572223973472,\n",
       " 'dig_std': 0.005269370250317761,\n",
       " 'emmanuel_mean': 0.0050243632746884296,\n",
       " 'icy_std': 0.004983923640854737,\n",
       " 'emperor_hyp_std': 0.004604224822579152,\n",
       " 'smart_std': 0.004396280802260256,\n",
       " 'ordinance_std': 0.004177082997467539,\n",
       " 'cumberland_syn_std': 0.0038374983625878278,\n",
       " 'torment_std': 0.003765439417446982,\n",
       " 'meanly_syn_std': 0.003645591701958303,\n",
       " 'isis_syn_mean': 0.003575992599690386,\n",
       " 'average_hyp_std': 0.0031717795662670506,\n",
       " 'continent_std': 0.0029430959407884183,\n",
       " 'ill-advised_syn_mean': 0.0028469247841047133,\n",
       " 'ague_std': 0.0024099862384140856,\n",
       " 'forgetful_std': 0.0023471887532418374,\n",
       " 'emmanuel_std': 0.0021538910364870367,\n",
       " 'containerful_hyp_mean': 0.0020341738554660845,\n",
       " 'denmark_std': 0.0017435425918495644,\n",
       " 'writer_hyp_mean': 0.0016664319310035088,\n",
       " 'fashion_hyp_std': 0.0016499316493485024,\n",
       " 'successively_syn_std': 0.0015259395480669144,\n",
       " 'domitius_std': 0.0012998949090873065,\n",
       " 'landmass_hyp_std': 0.001266675883156371,\n",
       " 'cask_mean': 0.0012136894211016707,\n",
       " 'hateful_mean': 0.0012041107503588408,\n",
       " 'enfold_std': 0.0011013045703498993,\n",
       " 'emmanuel_median': 0.0010487389288927822,\n",
       " 'player_mean': 0.0006283775266239158,\n",
       " 'keep_hyp_std': 0.0006127891092368838,\n",
       " 'disinherit_std': 0.0005337439460037092,\n",
       " 'notion_mean': 0.00043618566867923374,\n",
       " 'unadvise_mean': 0.000360342406048862,\n",
       " 'retentive_syn_mean': 0.0003365369829926648,\n",
       " 'unretentive_syn_std': 0.0002456603278214552,\n",
       " 'blanch_mean': 7.644357263377127e-05,\n",
       " 'happiness_median': 4.557306924682176e-05,\n",
       " 'isis_mean': 2.3189402889489946e-05,\n",
       " 'pos_sentiment_mean': 0.0,\n",
       " 'neg_sentiment_mean': 0.0,\n",
       " 'neu_sentiment_mean': 0.0,\n",
       " 'compound_sentiment_mean': 0.0,\n",
       " 'endowment_hyp_mean': 0.0,\n",
       " 'hang_mean': 0.0,\n",
       " 'VERB_mean': 0.0,\n",
       " 'character_name_mean': 0.0,\n",
       " 'PROPN_mean': 0.0,\n",
       " 'shall_mean': 0.0,\n",
       " 'attempt_hyp_mean': 0.0,\n",
       " 'good_mean': 0.0,\n",
       " 'ADJ_mean': 0.0,\n",
       " 'by_and_large_syn_mean': 0.0,\n",
       " 'generally_mean': 0.0,\n",
       " 'ADV_mean': 0.0,\n",
       " 'match_hyp_mean': 0.0,\n",
       " 'accord_mean': 0.0,\n",
       " 'security_hyp_mean': 0.0,\n",
       " 'scrip_mean': 0.0,\n",
       " 'advantage_hyp_mean': 0.0,\n",
       " 'dramatic_composition_hyp_mean': 0.0,\n",
       " 'play_mean': 0.0,\n",
       " 'NOUN_mean': 0.0,\n",
       " 'nutriment_hyp_mean': 0.0,\n",
       " 'treat_mean': 0.0,\n",
       " 'publication_hyp_mean': 0.0,\n",
       " 'read_mean': 0.0,\n",
       " 'defamation_hyp_mean': 0.0,\n",
       " 'name_mean': 0.0,\n",
       " 'performer_hyp_mean': 0.0,\n",
       " 'actor_mean': 0.0,\n",
       " 'change_hyp_mean': 0.0,\n",
       " 'grow_mean': 0.0,\n",
       " 'component_hyp_mean': 0.0,\n",
       " 'point_mean': 0.0,\n",
       " 'part_hyp_mean': 0.0,\n",
       " 'piece_mean': 0.0,\n",
       " 'activity_hyp_mean': 0.0,\n",
       " 'work_mean': 0.0,\n",
       " 'guarantee_syn_mean': 0.0,\n",
       " 'assure_mean': 0.0,\n",
       " 'gay_syn_mean': 0.0,\n",
       " 'merry_mean': 0.0,\n",
       " 'forth_syn_mean': 0.0,\n",
       " 'forth_mean': 0.0,\n",
       " 'round_shape_hyp_mean': 0.0,\n",
       " 'scroll_mean': 0.0,\n",
       " 'masters_syn_mean': 0.0,\n",
       " 'masters_mean': 0.0,\n",
       " 'change_of_location_hyp_mean': 0.0,\n",
       " 'spread_mean': 0.0,\n",
       " 'readiness_hyp_mean': 0.0,\n",
       " 'ready_mean': 0.0,\n",
       " 'talk_hyp_mean': 0.0,\n",
       " 'proceed_mean': 0.0,\n",
       " 'pyramus_mean': 0.0,\n",
       " 'person_hyp_mean': 0.0,\n",
       " 'lover_mean': 0.0,\n",
       " 'dictator_hyp_mean': 0.0,\n",
       " 'tyrant_mean': 0.0,\n",
       " 'communicate_hyp_mean': 0.0,\n",
       " 'ask_mean': 0.0,\n",
       " 'bodily_process_hyp_mean': 0.0,\n",
       " 'tear_mean': 0.0,\n",
       " 'alignment_hyp_mean': 0.0,\n",
       " 'true_mean': 0.0,\n",
       " 'performing_mean': 0.0,\n",
       " 'lashkar-e-taiba_syn_mean': 0.0,\n",
       " 'let_mean': 0.0,\n",
       " 'gathering_hyp_mean': 0.0,\n",
       " 'audience_mean': 0.0,\n",
       " 'countenance_hyp_mean': 0.0,\n",
       " 'look_mean': 0.0,\n",
       " 'opinion_hyp_mean': 0.0,\n",
       " 'eye_mean': 0.0,\n",
       " 'atmospheric_phenomenon_hyp_mean': 0.0,\n",
       " 'storm_mean': 0.0,\n",
       " 'commiserate_hyp_mean': 0.0,\n",
       " 'condole_mean': 0.0,\n",
       " 'maneuver_hyp_mean': 0.0,\n",
       " 'measure_mean': 0.0,\n",
       " 'rest_mean': 0.0,\n",
       " 'leader_hyp_mean': 0.0,\n",
       " 'chief_mean': 0.0,\n",
       " 'message_hyp_mean': 0.0,\n",
       " 'humor_mean': 0.0,\n",
       " 'ercles_mean': 0.0,\n",
       " 'rarely_syn_mean': 0.0,\n",
       " 'rarely_mean': 0.0,\n",
       " 'drop_hyp_mean': 0.0,\n",
       " 'feline_hyp_mean': 0.0,\n",
       " 'cat_mean': 0.0,\n",
       " 'acrobatic_stunt_hyp_mean': 0.0,\n",
       " 'split_mean': 0.0,\n",
       " 'act_hyp_mean': 0.0,\n",
       " 'rage_mean': 0.0,\n",
       " 'natural_object_hyp_mean': 0.0,\n",
       " 'rock_mean': 0.0,\n",
       " 'symptom_hyp_mean': 0.0,\n",
       " 'shivering_mean': 0.0,\n",
       " 'stupefaction_hyp_mean': 0.0,\n",
       " 'shock_mean': 0.0,\n",
       " 'happening_hyp_mean': 0.0,\n",
       " 'break_mean': 0.0,\n",
       " 'fastener_hyp_mean': 0.0,\n",
       " 'lock_mean': 0.0,\n",
       " 'correctional_institution_hyp_mean': 0.0,\n",
       " 'prison_mean': 0.0,\n",
       " 'movable_barrier_hyp_mean': 0.0,\n",
       " 'gate_mean': 0.0,\n",
       " 'phibbus_mean': 0.0,\n",
       " 'motor_vehicle_hyp_mean': 0.0,\n",
       " 'car_mean': 0.0,\n",
       " 'brightness_hyp_mean': 0.0,\n",
       " 'shine_mean': 0.0,\n",
       " 'army_for_the_liberation_of_rwanda_syn_mean': 0.0,\n",
       " 'far_mean': 0.0,\n",
       " 'gregorian_calendar_month_hyp_mean': 0.0,\n",
       " 'mar_mean': 0.0,\n",
       " 'foolish_syn_mean': 0.0,\n",
       " 'foolish_mean': 0.0,\n",
       " 'fate_mean': 0.0,\n",
       " 'exalted_syn_mean': 0.0,\n",
       " 'lofty_mean': 0.0,\n",
       " 'contestant_hyp_mean': 0.0,\n",
       " 'blood_vessel_hyp_mean': 0.0,\n",
       " 'vein_mean': 0.0,\n",
       " 'condoling_mean': 0.0,\n",
       " 'animal_skin_hyp_mean': 0.0,\n",
       " 'hide_mean': 0.0,\n",
       " 'external_body_part_hyp_mean': 0.0,\n",
       " 'face_mean': 0.0,\n",
       " 'thisbe_mean': 0.0,\n",
       " 'speak_mean': 0.0,\n",
       " 'monstrous_syn_mean': 0.0,\n",
       " 'monstrous_mean': 0.0,\n",
       " 'small_indefinite_quantity_hyp_mean': 0.0,\n",
       " 'little_mean': 0.0,\n",
       " 'sound_hyp_mean': 0.0,\n",
       " 'voice_mean': 0.0,\n",
       " 'thisne_mean': 0.0,\n",
       " 'ah_mean': 0.0,\n",
       " 'INTJ_mean': 0.0,\n",
       " 'lover_hyp_mean': 0.0,\n",
       " 'dear_mean': 0.0,\n",
       " 'big_cat_hyp_mean': 0.0,\n",
       " 'lion_mean': 0.0,\n",
       " 'noise_hyp_mean': 0.0,\n",
       " 'roar_mean': 0.0,\n",
       " 'intuition_hyp_mean': 0.0,\n",
       " 'heart_mean': 0.0,\n",
       " 'perceive_hyp_mean': 0.0,\n",
       " 'hear_mean': 0.0,\n",
       " 'aid_hyp_mean': 0.0,\n",
       " 'grant_mean': 0.0,\n",
       " 'friend_mean': 0.0,\n",
       " 'emotion_hyp_mean': 0.0,\n",
       " 'fright_mean': 0.0,\n",
       " 'intelligence_hyp_mean': 0.0,\n",
       " 'wit_mean': 0.0,\n",
       " 'liberty_hyp_mean': 0.0,\n",
       " 'discretion_mean': 0.0,\n",
       " 'aggravate_mean': 0.0,\n",
       " 'gently_syn_mean': 0.0,\n",
       " 'gently_mean': 0.0,\n",
       " 'consumption_hyp_mean': 0.0,\n",
       " 'sucking_mean': 0.0,\n",
       " 'pigeon_hyp_mean': 0.0,\n",
       " 'dove_mean': 0.0,\n",
       " 'thrush_hyp_mean': 0.0,\n",
       " 'nightingale_mean': 0.0,\n",
       " 'initiate_hyp_mean': 0.0,\n",
       " 'undertake_mean': 0.0,\n",
       " 'facial_hair_hyp_mean': 0.0,\n",
       " 'beard_mean': 0.0,\n",
       " 'discharge_mean': 0.0,\n",
       " 'plant_fiber_hyp_mean': 0.0,\n",
       " 'straw_mean': 0.0,\n",
       " 'visual_property_hyp_mean': 0.0,\n",
       " 'color_mean': 0.0,\n",
       " 'citrus_hyp_mean': 0.0,\n",
       " 'orange_mean': 0.0,\n",
       " 'tawny_syn_mean': 0.0,\n",
       " 'tawny_mean': 0.0,\n",
       " 'chromatic_color_hyp_mean': 0.0,\n",
       " 'purple_mean': 0.0,\n",
       " 'atom_hyp_mean': 0.0,\n",
       " 'grain_mean': 0.0,\n",
       " 'romance_hyp_mean': 0.0,\n",
       " 'french_mean': 0.0,\n",
       " 'symbol_hyp_mean': 0.0,\n",
       " 'crown_mean': 0.0,\n",
       " 'perfit_mean': 0.0,\n",
       " 'yellow_mean': 0.0,\n",
       " 'athletic_contest_hyp_mean': 0.0,\n",
       " 'meet_mean': 0.0,\n",
       " 'perform_hyp_mean': 0.0,\n",
       " 'rehearse_mean': 0.0,\n",
       " 'obscenely_syn_mean': 0.0,\n",
       " 'obscenely_mean': 0.0,\n",
       " 'bravely_syn_mean': 0.0,\n",
       " 'courageously_mean': 0.0,\n",
       " 'pain_mean': 0.0,\n",
       " 'farewell_hyp_mean': 0.0,\n",
       " 'adieu_mean': 0.0,\n",
       " 'grasping_hyp_mean': 0.0,\n",
       " 'hold_mean': 0.0,\n",
       " 'share_hyp_mean': 0.0,\n",
       " 'cut_mean': 0.0,\n",
       " 'cord_hyp_mean': 0.0,\n",
       " 'bowstring_mean': 0.0,\n",
       " 'property_hyp_mean': 0.0,\n",
       " 'thing_mean': 0.0,\n",
       " 'drama_hyp_mean': 0.0,\n",
       " 'comedy_mean': 0.0,\n",
       " 'gully_hyp_mean': 0.0,\n",
       " 'draw_mean': 0.0,\n",
       " 'weapon_hyp_mean': 0.0,\n",
       " 'sword_mean': 0.0,\n",
       " 'termination_hyp_mean': 0.0,\n",
       " 'kill_mean': 0.0,\n",
       " 'stay_hyp_mean': 0.0,\n",
       " 'abide_mean': 0.0,\n",
       " 'statement_hyp_mean': 0.0,\n",
       " 'answer_mean': 0.0,\n",
       " 'whit_mean': 0.0,\n",
       " 'instrumentality_hyp_mean': 0.0,\n",
       " 'device_mean': 0.0,\n",
       " 'create_verbally_hyp_mean': 0.0,\n",
       " 'write_mean': 0.0,\n",
       " 'ill_health_hyp_mean': 0.0,\n",
       " 'harm_mean': 0.0,\n",
       " 'good_hyp_mean': 0.0,\n",
       " 'well_mean': 0.0,\n",
       " 'certainty_hyp_mean': 0.0,\n",
       " 'assurance_mean': 0.0,\n",
       " 'tell_syn_mean': 0.0,\n",
       " 'tell_mean': 0.0,\n",
       " 'craftsman_hyp_mean': 0.0,\n",
       " 'weaver_mean': 0.0,\n",
       " 'fear_mean': 0.0,\n",
       " 'artist_hyp_mean': 0.0,\n",
       " 'master_mean': 0.0,\n",
       " 'ought_mean': 0.0,\n",
       " 'think_hyp_mean': 0.0,\n",
       " 'consider_mean': 0.0,\n",
       " 'transport_hyp_mean': 0.0,\n",
       " 'bring_mean': 0.0,\n",
       " 'god_syn_mean': 0.0,\n",
       " 'god_mean': 0.0,\n",
       " 'protective_covering_hyp_mean': 0.0,\n",
       " 'shield_mean': 0.0,\n",
       " 'awful_syn_mean': 0.0,\n",
       " 'dreadful_mean': 0.0,\n",
       " 'situation_hyp_mean': 0.0,\n",
       " 'fearful_syn_mean': 0.0,\n",
       " 'fearful_mean': 0.0,\n",
       " 'bird_hyp_mean': 0.0,\n",
       " 'wildfowl_mean': 0.0,\n",
       " 'experience_hyp_mean': 0.0,\n",
       " 'living_mean': 0.0,\n",
       " 'negative_hyp_mean': 0.0,\n",
       " 'nay_mean': 0.0,\n",
       " 'common_fraction_hyp_mean': 0.0,\n",
       " 'half_mean': 0.0,\n",
       " 'DET_mean': 0.0,\n",
       " 'see_mean': 0.0,\n",
       " 'neck_mean': 0.0,\n",
       " 'speech_hyp_mean': 0.0,\n",
       " 'say_mean': 0.0,\n",
       " 'imperfection_hyp_mean': 0.0,\n",
       " 'defect_mean': 0.0,\n",
       " 'show_hyp_mean': 0.0,\n",
       " 'fair_mean': 0.0,\n",
       " 'desire_hyp_mean': 0.0,\n",
       " 'wish_mean': 0.0,\n",
       " 'request_mean': 0.0,\n",
       " 'plead_hyp_mean': 0.0,\n",
       " 'entreat_mean': 0.0,\n",
       " 'reflex_hyp_mean': 0.0,\n",
       " 'tremble_mean': 0.0,\n",
       " 'being_hyp_mean': 0.0,\n",
       " 'life_mean': 0.0,\n",
       " 'deliberation_hyp_mean': 0.0,\n",
       " 'think_mean': 0.0,\n",
       " 'liquid_body_substance_hyp_mean': 0.0,\n",
       " 'come_mean': 0.0,\n",
       " 'here_syn_mean': 0.0,\n",
       " 'hither_mean': 0.0,\n",
       " 'sympathy_hyp_mean': 0.0,\n",
       " 'pity_mean': 0.0,\n",
       " 'force_hyp_mean': 0.0,\n",
       " 'man_mean': 0.0,\n",
       " 'obviously_syn_mean': 0.0,\n",
       " 'plainly_mean': 0.0,\n",
       " 'member_hyp_mean': 0.0,\n",
       " 'joiner_mean': 0.0,\n",
       " 'arrangement_hyp_mean': 0.0,\n",
       " 'calendar_mean': 0.0,\n",
       " 'annual_hyp_mean': 0.0,\n",
       " 'almanac_mean': 0.0,\n",
       " 'insight_hyp_mean': 0.0,\n",
       " 'find_mean': 0.0,\n",
       " 'light_hyp_mean': 0.0,\n",
       " 'moonshine_mean': 0.0,\n",
       " 'time_off_hyp_mean': 0.0,\n",
       " 'leave_mean': 0.0,\n",
       " 'sash_hyp_mean': 0.0,\n",
       " 'casement_mean': 0.0,\n",
       " 'achiever_hyp_mean': 0.0,\n",
       " 'great_mean': 0.0,\n",
       " 'enclosure_hyp_mean': 0.0,\n",
       " 'chamber_mean': 0.0,\n",
       " 'framework_hyp_mean': 0.0,\n",
       " 'window_mean': 0.0,\n",
       " 'area_hyp_mean': 0.0,\n",
       " 'open_mean': 0.0,\n",
       " 'moon_syn_mean': 0.0,\n",
       " 'moon_mean': 0.0,\n",
       " 'time_hyp_mean': 0.0,\n",
       " 'present_mean': 0.0,\n",
       " 'partition_hyp_mean': 0.0,\n",
       " 'wall_mean': 0.0,\n",
       " 'covering_material_hyp_mean': 0.0,\n",
       " 'plaster_mean': 0.0,\n",
       " 'soil_hyp_mean': 0.0,\n",
       " 'loam_mean': 0.0,\n",
       " 'plaster_hyp_mean': 0.0,\n",
       " 'roughcast_mean': 0.0,\n",
       " 'mean_syn_mean': 0.0,\n",
       " 'signify_mean': 0.0,\n",
       " 'digit_hyp_mean': 0.0,\n",
       " 'finger_mean': 0.0,\n",
       " 'depression_hyp_mean': 0.0,\n",
       " 'cranny_mean': 0.0,\n",
       " 'speaking_hyp_mean': 0.0,\n",
       " 'whisper_mean': 0.0,\n",
       " 'angiosperm_hyp_mean': 0.0,\n",
       " 'flower_mean': 0.0,\n",
       " 'odious_mean': 0.0,\n",
       " 'taste_hyp_mean': 0.0,\n",
       " 'savor_mean': 0.0,\n",
       " 'sweet_syn_mean': 0.0,\n",
       " 'sweet_mean': 0.0,\n",
       " 'odor_mean': 0.0,\n",
       " 'breath_mean': 0.0,\n",
       " 'listen_hyp_mean': 0.0,\n",
       " 'hark_mean': 0.0,\n",
       " 'stay_mean': 0.0,\n",
       " 'awhile_syn_mean': 0.0,\n",
       " 'awhile_mean': 0.0,\n",
       " 'be_hyp_mean': 0.0,\n",
       " 'appear_mean': 0.0,\n",
       " 'score_hyp_mean': 0.0,\n",
       " 'run_mean': 0.0,\n",
       " 'away_syn_mean': 0.0,\n",
       " 'away_mean': 0.0,\n",
       " 'wrongdoing_hyp_mean': 0.0,\n",
       " 'knavery_mean': 0.0,\n",
       " 'afeard_syn_mean': 0.0,\n",
       " 'afeard_mean': 0.0,\n",
       " 'body_part_hyp_mean': 0.0,\n",
       " 'ass_mean': 0.0,\n",
       " 'head_mean': 0.0,\n",
       " 'disturbance_hyp_mean': 0.0,\n",
       " 'stir_mean': 0.0,\n",
       " 'point_hyp_mean': 0.0,\n",
       " 'place_mean': 0.0,\n",
       " 'locomotion_hyp_mean': 0.0,\n",
       " 'walk_mean': 0.0,\n",
       " 'interpret_hyp_mean': 0.0,\n",
       " 'sing_mean': 0.0,\n",
       " 'afraid_syn_mean': 0.0,\n",
       " 'afraid_mean': 0.0,\n",
       " 'ouzel_mean': 0.0,\n",
       " 'penis_hyp_mean': 0.0,\n",
       " 'cock_mean': 0.0,\n",
       " 'achromatic_color_hyp_mean': 0.0,\n",
       " 'black_mean': 0.0,\n",
       " 'color_property_hyp_mean': 0.0,\n",
       " 'hue_mean': 0.0,\n",
       " 'legal_document_hyp_mean': 0.0,\n",
       " 'bill_mean': 0.0,\n",
       " 'spinning_machine_hyp_mean': 0.0,\n",
       " 'throstle_mean': 0.0,\n",
       " 'written_record_hyp_mean': 0.0,\n",
       " 'note_mean': 0.0,\n",
       " 'wren_mean': 0.0,\n",
       " 'pen_hyp_mean': 0.0,\n",
       " 'quill_mean': 0.0,\n",
       " 'oscine_hyp_mean': 0.0,\n",
       " 'finch_mean': 0.0,\n",
       " 'passerine_hyp_mean': 0.0,\n",
       " 'sparrow_mean': 0.0,\n",
       " 'new_world_oriole_hyp_mean': 0.0,\n",
       " 'lark_mean': 0.0,\n",
       " 'chant_hyp_mean': 0.0,\n",
       " 'plainsong_mean': 0.0,\n",
       " 'fool_hyp_mean': 0.0,\n",
       " 'cuckoo_mean': 0.0,\n",
       " 'gray_mean': 0.0,\n",
       " 'evaluation_hyp_mean': 0.0,\n",
       " 'mark_mean': 0.0,\n",
       " 'challenge_hyp_mean': 0.0,\n",
       " 'dare_mean': 0.0,\n",
       " 'collection_hyp_mean': 0.0,\n",
       " 'set_mean': 0.0,\n",
       " 'vertebrate_hyp_mean': 0.0,\n",
       " 'bird_mean': 0.0,\n",
       " 'falsehood_hyp_mean': 0.0,\n",
       " 'lie_mean': 0.0,\n",
       " 'utterance_hyp_mean': 0.0,\n",
       " 'cry_mean': 0.0,\n",
       " 'mistress_mean': 0.0,\n",
       " 'rational_motive_hyp_mean': 0.0,\n",
       " 'reason_mean': 0.0,\n",
       " 'fact_hyp_mean': 0.0,\n",
       " 'truth_mean': 0.0,\n",
       " 'love_mean': 0.0,\n",
       " 'institution_hyp_mean': 0.0,\n",
       " 'company_mean': 0.0,\n",
       " 'nowadays_mean': 0.0,\n",
       " 'honest_syn_mean': 0.0,\n",
       " 'honest_mean': 0.0,\n",
       " 'neighbor_mean': 0.0,\n",
       " 'disrespect_hyp_mean': 0.0,\n",
       " 'insult_mean': 0.0,\n",
       " 'occasion_mean': 0.0,\n",
       " 'plant_material_hyp_mean': 0.0,\n",
       " 'wood_mean': 0.0,\n",
       " 'tennis_stroke_hyp_mean': 0.0,\n",
       " 'serve_mean': 0.0,\n",
       " 'curve_hyp_mean': 0.0,\n",
       " 'turn_mean': 0.0,\n",
       " 'worships_mean': 0.0,\n",
       " 'lenience_hyp_mean': 0.0,\n",
       " 'heartily_syn_mean': 0.0,\n",
       " 'heartily_mean': 0.0,\n",
       " 'beseech_mean': 0.0,\n",
       " 'worship_mean': 0.0,\n",
       " 'feeling_hyp_mean': 0.0,\n",
       " 'desire_mean': 0.0,\n",
       " 'information_hyp_mean': 0.0,\n",
       " 'acquaintance_mean': 0.0,\n",
       " 'font_hyp_mean': 0.0,\n",
       " 'bold_mean': 0.0,\n",
       " 'commune_hyp_mean': 0.0,\n",
       " 'pray_mean': 0.0,\n",
       " 'praise_hyp_mean': 0.0,\n",
       " 'commend_mean': 0.0,\n",
       " 'vine_hyp_mean': 0.0,\n",
       " 'squash_mean': 0.0,\n",
       " 'peascod_mean': 0.0,\n",
       " 'man_hyp_mean': 0.0,\n",
       " 'sir_mean': 0.0,\n",
       " 'crucifer_hyp_mean': 0.0,\n",
       " 'mustard_mean': 0.0,\n",
       " 'fruit_hyp_mean': 0.0,\n",
       " 'seed_mean': 0.0,\n",
       " 'knowing_hyp_mean': 0.0,\n",
       " 'know_mean': 0.0,\n",
       " 'cowardly_syn_mean': 0.0,\n",
       " 'cowardly_mean': 0.0,\n",
       " 'animal_hyp_mean': 0.0,\n",
       " 'giant_mean': 0.0,\n",
       " 'kind_hyp_mean': 0.0,\n",
       " 'like_mean': 0.0,\n",
       " 'SCONJ_mean': 0.0,\n",
       " 'cattle_hyp_mean': 0.0,\n",
       " 'ox_mean': 0.0,\n",
       " 'beef_mean': 0.0,\n",
       " 'destroy_hyp_mean': 0.0,\n",
       " 'devour_mean': 0.0,\n",
       " 'building_hyp_mean': 0.0,\n",
       " 'house_mean': 0.0,\n",
       " 'commitment_hyp_mean': 0.0,\n",
       " 'promise_mean': 0.0,\n",
       " 'social_group_hyp_mean': 0.0,\n",
       " 'kindred_mean': 0.0,\n",
       " 'binary_compound_hyp_mean': 0.0,\n",
       " 'water_mean': 0.0,\n",
       " 'wound_hyp_mean': 0.0,\n",
       " 'scratch_mean': 0.0,\n",
       " 'monsieur_mean': 0.0,\n",
       " 'instrument_hyp_mean': 0.0,\n",
       " 'weapon_mean': 0.0,\n",
       " 'extremity_hyp_mean': 0.0,\n",
       " 'hand_mean': 0.0,\n",
       " 'red_mean': 0.0,\n",
       " 'hipped_syn_mean': 0.0,\n",
       " 'hippe_mean': 0.0,\n",
       " 'humble_mean': 0.0,\n",
       " 'hymenopterous_insect_hyp_mean': 0.0,\n",
       " 'bee_mean': 0.0,\n",
       " 'weed_hyp_mean': 0.0,\n",
       " 'thistle_mean': 0.0,\n",
       " 'sweetening_hyp_mean': 0.0,\n",
       " 'honey_mean': 0.0,\n",
       " 'container_hyp_mean': 0.0,\n",
       " 'bag_mean': 0.0,\n",
       " 'agitation_hyp_mean': 0.0,\n",
       " 'fret_mean': 0.0,\n",
       " 'action_mean': 0.0,\n",
       " 'work_hyp_mean': 0.0,\n",
       " 'care_mean': 0.0,\n",
       " 'loath_syn_mean': 0.0,\n",
       " 'loath_mean': 0.0,\n",
       " 'spill_hyp_mean': 0.0,\n",
       " 'overflown_mean': 0.0,\n",
       " 'signior_mean': 0.0,\n",
       " 'politeness_hyp_mean': 0.0,\n",
       " 'courtesy_mean': 0.0,\n",
       " 'help_mean': 0.0,\n",
       " 'military_personnel_hyp_mean': 0.0,\n",
       " 'cavalry_mean': 0.0,\n",
       " 'barber_syn_mean': 0.0,\n",
       " 'barber_mean': 0.0,\n",
       " 'marvel_mean': 0.0,\n",
       " 'hairy_syn_mean': 0.0,\n",
       " 'hairy_mean': 0.0,\n",
       " 'medium_of_exchange_hyp_mean': 0.0,\n",
       " 'tender_mean': 0.0,\n",
       " 'body_covering_hyp_mean': 0.0,\n",
       " 'hair_mean': 0.0,\n",
       " 'cutaneous_sensation_hyp_mean': 0.0,\n",
       " 'tickle_mean': 0.0,\n",
       " 'reasonable_syn_mean': 0.0,\n",
       " 'reasonable_mean': 0.0,\n",
       " 'sense_organ_hyp_mean': 0.0,\n",
       " 'ear_mean': 0.0,\n",
       " 'auditory_communication_hyp_mean': 0.0,\n",
       " 'music_mean': 0.0,\n",
       " 'device_hyp_mean': 0.0,\n",
       " 'tong_mean': 0.0,\n",
       " 'percussion_instrument_hyp_mean': 0.0,\n",
       " 'bone_mean': 0.0,\n",
       " 'truly_syn_mean': 0.0,\n",
       " 'truly_mean': 0.0,\n",
       " 'large_indefinite_quantity_hyp_mean': 0.0,\n",
       " 'peck_mean': 0.0,\n",
       " 'food_hyp_mean': 0.0,\n",
       " 'provender_mean': 0.0,\n",
       " 'munch_syn_mean': 0.0,\n",
       " 'munch_mean': 0.0,\n",
       " 'reformer_hyp_mean': 0.0,\n",
       " 'dry_mean': 0.0,\n",
       " 'cereal_hyp_mean': 0.0,\n",
       " 'oats_mean': 0.0,\n",
       " 'vessel_hyp_mean': 0.0,\n",
       " 'bottle_mean': 0.0,\n",
       " 'fodder_hyp_mean': 0.0,\n",
       " 'hay_mean': 0.0,\n",
       " 'male_hyp_mean': 0.0,\n",
       " 'fellow_mean': 0.0,\n",
       " 'handful_mean': 0.0,\n",
       " 'legume_hyp_mean': 0.0,\n",
       " 'pea_mean': 0.0,\n",
       " 'group_hyp_mean': 0.0,\n",
       " 'people_mean': 0.0,\n",
       " 'interpretation_hyp_mean': 0.0,\n",
       " 'exposition_mean': 0.0,\n",
       " 'physical_condition_hyp_mean': 0.0,\n",
       " 'sleep_mean': 0.0,\n",
       " \"actor's_line_hyp_mean\": 0.0,\n",
       " 'cue_mean': 0.0,\n",
       " 'hey_mean': 0.0,\n",
       " 'metallic_element_hyp_mean': 0.0,\n",
       " 'ho_mean': 0.0,\n",
       " 'blower_hyp_mean': 0.0,\n",
       " 'bellow_mean': 0.0,\n",
       " 'skilled_worker_hyp_mean': 0.0,\n",
       " 'mender_mean': 0.0,\n",
       " 'experimenter_hyp_mean': 0.0,\n",
       " 'tinker_mean': 0.0,\n",
       " 'take_hyp_mean': 0.0,\n",
       " 'steal_mean': 0.0,\n",
       " 'position_hyp_mean': 0.0,\n",
       " 'asleep_syn_mean': 0.0,\n",
       " 'asleep_mean': 0.0,\n",
       " 'rare_syn_mean': 0.0,\n",
       " 'rare_mean': 0.0,\n",
       " 'imagination_hyp_mean': 0.0,\n",
       " 'vision_mean': 0.0,\n",
       " 'dream_mean': 0.0,\n",
       " 'past_mean': 0.0,\n",
       " 'ADP_mean': 0.0,\n",
       " 'clarify_hyp_mean': 0.0,\n",
       " 'expound_mean': 0.0,\n",
       " 'content_hyp_mean': 0.0,\n",
       " 'join_hyp_mean': 0.0,\n",
       " 'patched_mean': 0.0,\n",
       " 'speech_act_hyp_mean': 0.0,\n",
       " 'offer_mean': 0.0,\n",
       " 'able_syn_mean': 0.0,\n",
       " 'able_mean': 0.0,\n",
       " 'sensation_hyp_mean': 0.0,\n",
       " 'taste_mean': 0.0,\n",
       " 'articulator_hyp_mean': 0.0,\n",
       " 'tongue_mean': 0.0,\n",
       " 'create_by_mental_act_hyp_mean': 0.0,\n",
       " 'conceive_mean': 0.0,\n",
       " 'document_hyp_mean': 0.0,\n",
       " 'report_mean': 0.0,\n",
       " 'song_hyp_mean': 0.0,\n",
       " 'ballad_mean': 0.0,\n",
       " 'label_hyp_mean': 0.0,\n",
       " 'call_mean': 0.0,\n",
       " 'end_mean': 0.0,\n",
       " 'doubt_hyp_mean': 0.0,\n",
       " 'peradventure_mean': 0.0,\n",
       " 'gracious_syn_mean': 0.0,\n",
       " 'gracious_mean': 0.0,\n",
       " 'death_mean': 0.0,\n",
       " 'lad_mean': 0.0,\n",
       " 'whist_hyp_mean': 0.0,\n",
       " 'language_unit_hyp_mean': 0.0,\n",
       " 'discourse_mean': 0.0,\n",
       " 'astonishment_hyp_mean': 0.0,\n",
       " 'wonder_mean': 0.0,\n",
       " 'greek_hyp_mean': 0.0,\n",
       " 'athenian_mean': 0.0,\n",
       " 'abstraction_hyp_mean': 0.0,\n",
       " 'right_mean': 0.0,\n",
       " 'fall_mean': 0.0,\n",
       " 'word_mean': 0.0,\n",
       " 'eat_hyp_mean': 0.0,\n",
       " 'dine_mean': 0.0,\n",
       " 'clothing_hyp_mean': 0.0,\n",
       " 'apparel_mean': 0.0,\n",
       " 'section_hyp_mean': 0.0,\n",
       " 'string_mean': 0.0,\n",
       " 'new_syn_mean': 0.0,\n",
       " 'new_mean': 0.0,\n",
       " 'object_hyp_mean': 0.0,\n",
       " 'ribbon_mean': 0.0,\n",
       " 'mechanical_device_hyp_mean': 0.0,\n",
       " 'pump_mean': 0.0,\n",
       " 'soon_syn_mean': 0.0,\n",
       " 'presently_mean': 0.0,\n",
       " 'mansion_hyp_mean': 0.0,\n",
       " 'palace_mean': 0.0,\n",
       " 'tract_hyp_mean': 0.0,\n",
       " 'short_mean': 0.0,\n",
       " 'long_mean': 0.0,\n",
       " 'like_hyp_mean': 0.0,\n",
       " 'prefer_mean': 0.0,\n",
       " 'case_mean': 0.0,\n",
       " 'weightlift_hyp_mean': 0.0,\n",
       " 'clean_mean': 0.0,\n",
       " 'fabric_hyp_mean': 0.0,\n",
       " 'linen_mean': 0.0,\n",
       " 'decrease_hyp_mean': 0.0,\n",
       " 'pare_mean': 0.0,\n",
       " 'horny_structure_hyp_mean': 0.0,\n",
       " 'nail_mean': 0.0,\n",
       " 'claws_mean': 0.0,\n",
       " 'consume_hyp_mean': 0.0,\n",
       " 'eat_mean': 0.0,\n",
       " 'bulb_hyp_mean': 0.0,\n",
       " 'onion_mean': 0.0,\n",
       " 'alliaceous_plant_hyp_mean': 0.0,\n",
       " 'garlic_mean': 0.0,\n",
       " 'express_syn_mean': 0.0,\n",
       " 'utter_mean': 0.0,\n",
       " 'cognitive_state_hyp_mean': 0.0,\n",
       " 'doubt_mean': 0.0,\n",
       " 'grim_syn_mean': 0.0,\n",
       " 'grim_mean': 0.0,\n",
       " 'time_period_hyp_mean': 0.0,\n",
       " 'night_mean': 0.0,\n",
       " 'creation_hyp_mean': 0.0,\n",
       " 'art_mean': 0.0,\n",
       " 'time_unit_hyp_mean': 0.0,\n",
       " 'day_mean': 0.0,\n",
       " 'process_hyp_mean': 0.0,\n",
       " 'alas_mean': 0.0,\n",
       " 'forget_syn_mean': 0.0,\n",
       " 'forgot_mean': 0.0,\n",
       " \"photographer's_model_hyp_mean\": 0.0,\n",
       " 'lovely_mean': 0.0,\n",
       " 'support_hyp_mean': 0.0,\n",
       " 'stand_mean': 0.0,\n",
       " 'ground_mean': 0.0,\n",
       " 'chinese_hyp_mean': 0.0,\n",
       " 'chink_mean': 0.0,\n",
       " 'blink_mean': 0.0,\n",
       " 'acknowledgment_hyp_mean': 0.0,\n",
       " 'thank_mean': 0.0,\n",
       " 'courteous_syn_mean': 0.0,\n",
       " 'courteous_mean': 0.0,\n",
       " 'jupiter_syn_mean': 0.0,\n",
       " 'jove_mean': 0.0,\n",
       " 'wicked_syn_mean': 0.0,\n",
       " 'wicked_mean': 0.0,\n",
       " 'elation_hyp_mean': 0.0,\n",
       " 'bliss_mean': 0.0,\n",
       " 'express_hyp_mean': 0.0,\n",
       " 'cursed_mean': 0.0,\n",
       " 'stone_mean': 0.0,\n",
       " 'victimize_hyp_mean': 0.0,\n",
       " 'deceive_mean': 0.0,\n",
       " 'enter_syn_mean': 0.0,\n",
       " 'enter_mean': 0.0,\n",
       " 'secret_agent_hyp_mean': 0.0,\n",
       " 'spy_mean': 0.0,\n",
       " 'season_hyp_mean': 0.0,\n",
       " 'pat_mean': 0.0,\n",
       " 'yonder_syn_mean': 0.0,\n",
       " 'yonder_mean': 0.0,\n",
       " 'plant_disease_hyp_mean': 0.0,\n",
       " 'wilt_mean': 0.0,\n",
       " 'state_hyp_mean': 0.0,\n",
       " 'grace_mean': 0.0,\n",
       " 'limander_mean': 0.0,\n",
       " 'convict_hyp_mean': 0.0,\n",
       " 'trusty_mean': 0.0,\n",
       " 'shafalus_mean': 0.0,\n",
       " 'procrus_mean': 0.0,\n",
       " 'touch_hyp_mean': 0.0,\n",
       " 'kiss_mean': 0.0,\n",
       " 'opening_hyp_mean': 0.0,\n",
       " 'hole_mean': 0.0,\n",
       " 'despicable_syn_mean': 0.0,\n",
       " 'vile_mean': 0.0,\n",
       " 'simpleton_hyp_mean': 0.0,\n",
       " 'ninny_mean': 0.0,\n",
       " 'topographic_point_hyp_mean': 0.0,\n",
       " 'tomb_mean': 0.0,\n",
       " 'straightway_syn_mean': 0.0,\n",
       " 'straightway_mean': 0.0,\n",
       " 'convey_hyp_mean': 0.0,\n",
       " 'cheery_syn_mean': 0.0,\n",
       " 'sunny_mean': 0.0,\n",
       " 'signal_hyp_mean': 0.0,\n",
       " 'beam_mean': 0.0,\n",
       " 'bright_syn_mean': 0.0,\n",
       " 'bright_mean': 0.0,\n",
       " 'aureate_syn_mean': 0.0,\n",
       " 'golden_mean': 0.0,\n",
       " 'look_hyp_mean': 0.0,\n",
       " 'glitter_mean': 0.0,\n",
       " 'radiance_hyp_mean': 0.0,\n",
       " 'gleam_mean': 0.0,\n",
       " 'trust_mean': 0.0,\n",
       " 'visual_percept_hyp_mean': 0.0,\n",
       " 'sight_mean': 0.0,\n",
       " 'malevolence_hyp_mean': 0.0,\n",
       " 'spite_mean': 0.0,\n",
       " 'people_hyp_mean': 0.0,\n",
       " 'poor_mean': 0.0,\n",
       " 'dole_mean': 0.0,\n",
       " 'dainty_mean': 0.0,\n",
       " 'anseriform_bird_hyp_mean': 0.0,\n",
       " 'duck_mean': 0.0,\n",
       " 'mantle_mean': 0.0,\n",
       " 'dye_hyp_mean': 0.0,\n",
       " 'stain_mean': 0.0,\n",
       " 'blood_mean': 0.0,\n",
       " 'conceptualization_hyp_mean': 0.0,\n",
       " 'approach_mean': 0.0,\n",
       " 'anger_hyp_mean': 0.0,\n",
       " 'furies_mean': 0.0,\n",
       " 'thread_mean': 0.0,\n",
       " 'thrum_mean': 0.0,\n",
       " 'wildfowl_hyp_mean': 0.0,\n",
       " 'quail_mean': 0.0,\n",
       " 'leather_hyp_mean': 0.0,\n",
       " 'crush_mean': 0.0,\n",
       " 'conclude_mean': 0.0,\n",
       " 'suppress_hyp_mean': 0.0,\n",
       " 'quell_mean': 0.0,\n",
       " 'reason_hyp_mean': 0.0,\n",
       " 'wherefore_mean': 0.0,\n",
       " 'quality_hyp_mean': 0.0,\n",
       " 'nature_mean': 0.0,\n",
       " 'frame_mean': 0.0,\n",
       " 'copulate_hyp_mean': 0.0,\n",
       " 'deflower_mean': 0.0,\n",
       " 'girl_hyp_mean': 0.0,\n",
       " 'dame_mean': 0.0,\n",
       " 'live_mean': 0.0,\n",
       " 'approval_hyp_mean': 0.0,\n",
       " 'cheer_mean': 0.0,\n",
       " 'confound_mean': 0.0,\n",
       " 'injury_hyp_mean': 0.0,\n",
       " 'wound_mean': 0.0,\n",
       " 'drivel_hyp_mean': 0.0,\n",
       " 'pap_mean': 0.0,\n",
       " 'ay_mean': 0.0,\n",
       " 'jump_hyp_mean': 0.0,\n",
       " 'hop_mean': 0.0,\n",
       " 'cube_hyp_mean': 0.0,\n",
       " 'die_mean': 0.0,\n",
       " 'dead_mean': 0.0,\n",
       " 'scat_hyp_mean': 0.0,\n",
       " 'flee_mean': 0.0,\n",
       " 'spirit_hyp_mean': 0.0,\n",
       " 'soul_mean': 0.0,\n",
       " 'atmosphere_hyp_mean': 0.0,\n",
       " 'sky_mean': 0.0,\n",
       " 'lose_syn_mean': 0.0,\n",
       " 'lose_mean': 0.0,\n",
       " 'actinic_radiation_hyp_mean': 0.0,\n",
       " 'light_mean': 0.0,\n",
       " 'formation_hyp_mean': 0.0,\n",
       " 'flight_mean': 0.0,\n",
       " 'move_hyp_mean': 0.0,\n",
       " 'part_mean': 0.0,\n",
       " 'parent_hyp_mean': 0.0,\n",
       " 'father_mean': 0.0,\n",
       " 'conclusion_hyp_mean': 0.0,\n",
       " 'epilogue_mean': 0.0,\n",
       " 'bergomask_mean': 0.0,\n",
       " 'art_hyp_mean': 0.0,\n",
       " 'dance_mean': 0.0,\n",
       " 'philomel_mean': 0.0,\n",
       " 'music_hyp_mean': 0.0,\n",
       " 'melody_mean': 0.0,\n",
       " 'lullaby_mean': 0.0,\n",
       " 'lulla_mean': 0.0,\n",
       " 'psychological_state_hyp_mean': 0.0,\n",
       " 'spell_mean': 0.0,\n",
       " 'attractiveness_hyp_mean': 0.0,\n",
       " 'charm_mean': 0.0,\n",
       " 'near_syn_mean': 0.0,\n",
       " 'nigh_mean': 0.0,\n",
       " 'precipitation_hyp_mean': 0.0,\n",
       " 'hail_mean': 0.0,\n",
       " 'yield_syn_mean': 0.0,\n",
       " 'relent_mean': 0.0,\n",
       " 'production_hyp_mean': 0.0,\n",
       " 'yield_mean': 0.0,\n",
       " 'madden_syn_mean': 0.0,\n",
       " 'crazed_mean': 0.0,\n",
       " 'heading_hyp_mean': 0.0,\n",
       " 'title_mean': 0.0,\n",
       " 'certain_syn_mean': 0.0,\n",
       " 'certain_mean': 0.0,\n",
       " 'pursue_mean': 0.0,\n",
       " 'foundation_garment_hyp_mean': 0.0,\n",
       " 'unto_mean': 0.0,\n",
       " 'shift_hyp_mean': 0.0,\n",
       " 'go_mean': 0.0,\n",
       " 'travel_hyp_mean': 0.0,\n",
       " 'follow_mean': 0.0,\n",
       " 'provoke_hyp_mean': 0.0,\n",
       " 'entice_mean': 0.0,\n",
       " 'land_hyp_mean': 0.0,\n",
       " 'plain_mean': 0.0,\n",
       " 'invite_hyp_mean': 0.0,\n",
       " 'tempt_mean': 0.0,\n",
       " 'hatred_mean': 0.0,\n",
       " 'sick_mean': 0.0,\n",
       " 'impeach_mean': 0.0,\n",
       " 'decency_hyp_mean': 0.0,\n",
       " 'modesty_mean': 0.0,\n",
       " 'municipality_hyp_mean': 0.0,\n",
       " 'city_mean': 0.0,\n",
       " 'commit_mean': 0.0,\n",
       " 'guardianship_hyp_mean': 0.0,\n",
       " 'possibility_hyp_mean': 0.0,\n",
       " 'opportunity_mean': 0.0,\n",
       " 'disorder_hyp_mean': 0.0,\n",
       " 'ill_mean': 0.0,\n",
       " 'lawyer_hyp_mean': 0.0,\n",
       " 'counsel_mean': 0.0,\n",
       " 'biome_hyp_mean': 0.0,\n",
       " 'desert_mean': 0.0,\n",
       " 'rich_mean': 0.0,\n",
       " 'indefinite_quantity_hyp_mean': 0.0,\n",
       " 'worth_mean': 0.0,\n",
       " 'condition_hyp_mean': 0.0,\n",
       " 'virginity_mean': 0.0,\n",
       " 'brake_hyp_mean': 0.0,\n",
       " 'brake_mean': 0.0,\n",
       " 'wild_mean': 0.0,\n",
       " 'organism_hyp_mean': 0.0,\n",
       " 'beast_mean': 0.0,\n",
       " 'questioning_hyp_mean': 0.0,\n",
       " 'question_mean': 0.0,\n",
       " 'accept_hyp_mean': 0.0,\n",
       " 'believe_mean': 0.0,\n",
       " 'misbehavior_hyp_mean': 0.0,\n",
       " 'mischief_mean': 0.0,\n",
       " 'attack_hyp_mean': 0.0,\n",
       " 'charge_mean': 0.0,\n",
       " 'haunt_mean': 0.0,\n",
       " 'danger_hyp_mean': 0.0,\n",
       " 'peril_mean': 0.0,\n",
       " 'criticism_hyp_mean': 0.0,\n",
       " 'rebuke_mean': 0.0,\n",
       " 'lay_mean': 0.0,\n",
       " 'ale_hyp_mean': 0.0,\n",
       " 'bitter_mean': 0.0,\n",
       " 'adversary_hyp_mean': 0.0,\n",
       " 'foe_mean': 0.0,\n",
       " 'kill_hyp_mean': 0.0,\n",
       " 'murdered_mean': 0.0,\n",
       " 'penetrate_hyp_mean': 0.0,\n",
       " 'pierce_mean': 0.0,\n",
       " 'rear_hyp_mean': 0.0,\n",
       " 'stern_mean': 0.0,\n",
       " 'maltreatment_hyp_mean': 0.0,\n",
       " 'cruelty_mean': 0.0,\n",
       " 'innocence_hyp_mean': 0.0,\n",
       " 'clear_mean': 0.0,\n",
       " 'venus_syn_mean': 0.0,\n",
       " 'venus_mean': 0.0,\n",
       " 'suggestion_hyp_mean': 0.0,\n",
       " 'glimmering_mean': 0.0,\n",
       " 'environment_hyp_mean': 0.0,\n",
       " 'sphere_mean': 0.0,\n",
       " 'body_hyp_mean': 0.0,\n",
       " 'carcass_mean': 0.0,\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a52a06e8-05a3-47bc-80a9-5de88baa5f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2b1ad5f4100>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(logreg_rs_rocauc.best_estimator_['logreg'], Xs_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf32525-c2e6-48c3-9239-53f199383159",
   "metadata": {},
   "source": [
    "- Line NN with PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59baf372-3b40-4f6e-9801-489897d8099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_pca = PCA(n_components = 10000, random_state = 42)\n",
    "line_Z_train = pca.fit_transform(line_Xs_train)\n",
    "line_Z_test = pca.transform(line_Xs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4b4c000-41ad-4a65-9543-57c26ed5355c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 3.7048 - val_loss: 2.8784\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 2.3387 - val_loss: 1.8531\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.5088 - val_loss: 1.2423\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 1.0393 - val_loss: 0.9140\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.7923 - val_loss: 0.7455\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6684 - val_loss: 0.6599\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.6033 - val_loss: 0.6150\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5716 - val_loss: 0.5938\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5520 - val_loss: 0.5789\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5393 - val_loss: 0.5744\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5365 - val_loss: 0.5725\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5340 - val_loss: 0.5710\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.5285 - val_loss: 0.5705\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5301 - val_loss: 0.5737\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5276 - val_loss: 0.5750\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5268 - val_loss: 0.5761\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5258 - val_loss: 0.5848\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5299 - val_loss: 0.5882\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5289 - val_loss: 0.5893\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5279 - val_loss: 0.5930\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5257 - val_loss: 0.5954\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5283 - val_loss: 0.5968\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5271 - val_loss: 0.6051\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5286 - val_loss: 0.6073\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5277 - val_loss: 0.6118\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5300 - val_loss: 0.6113\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5260 - val_loss: 0.6182\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5216 - val_loss: 0.6137\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5179 - val_loss: 0.6236\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5248 - val_loss: 0.6188\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5156 - val_loss: 0.6318\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5211 - val_loss: 0.6290\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5117 - val_loss: 0.6367\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5125 - val_loss: 0.6403\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5103 - val_loss: 0.6376\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5102 - val_loss: 0.6451\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5077 - val_loss: 0.6454\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5054 - val_loss: 0.6484\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.5051 - val_loss: 0.6501\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4997 - val_loss: 0.6455\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4985 - val_loss: 0.6477\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4982 - val_loss: 0.6552\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4954 - val_loss: 0.6641\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4926 - val_loss: 0.6601\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4973 - val_loss: 0.6700\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4945 - val_loss: 0.6566\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4925 - val_loss: 0.6680\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4932 - val_loss: 0.6821\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4909 - val_loss: 0.6649\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4861 - val_loss: 0.6761\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4817 - val_loss: 0.6852\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4814 - val_loss: 0.6938\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4888 - val_loss: 0.6859\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4796 - val_loss: 0.6871\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4830 - val_loss: 0.6919\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4805 - val_loss: 0.6902\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4839 - val_loss: 0.6842\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4825 - val_loss: 0.6874\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4758 - val_loss: 0.6922\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4825 - val_loss: 0.6950\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4729 - val_loss: 0.6971\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4706 - val_loss: 0.7124\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4640 - val_loss: 0.7052\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4736 - val_loss: 0.6996\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4722 - val_loss: 0.7041\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4710 - val_loss: 0.7132\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4646 - val_loss: 0.7191\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4684 - val_loss: 0.7253\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4703 - val_loss: 0.7123\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4710 - val_loss: 0.7126\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4715 - val_loss: 0.7129\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4684 - val_loss: 0.7222\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4654 - val_loss: 0.7214\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4626 - val_loss: 0.7255\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4611 - val_loss: 0.7362\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4650 - val_loss: 0.7264\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4601 - val_loss: 0.7282\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4576 - val_loss: 0.7270\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4594 - val_loss: 0.7285\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4635 - val_loss: 0.7115\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4621 - val_loss: 0.7329\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4603 - val_loss: 0.7207\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4599 - val_loss: 0.7245\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4625 - val_loss: 0.7299\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4551 - val_loss: 0.7335\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4590 - val_loss: 0.7399\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4541 - val_loss: 0.7464\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4580 - val_loss: 0.7423\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4568 - val_loss: 0.7256\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4587 - val_loss: 0.7531\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4524 - val_loss: 0.7450\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4540 - val_loss: 0.7446\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4532 - val_loss: 0.7542\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4502 - val_loss: 0.7469\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4534 - val_loss: 0.7579\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4549 - val_loss: 0.7400\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4480 - val_loss: 0.7559\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4545 - val_loss: 0.7419\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4450 - val_loss: 0.7548\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.4484 - val_loss: 0.7662\n",
      "Wall time: 20.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clear_session()\n",
    "line_model = Sequential()\n",
    "\n",
    "\n",
    "line_model.add(Dense(100, input_dim = line_Z_train.shape[1], activation = 'relu', kernel_regularizer = l2(.01)))\n",
    "line_model.add(Dropout(0.15))\n",
    "line_model.add(Dense(100, activation = 'relu', kernel_regularizer = l2(.01)))\n",
    "line_model.add(Dropout(0.15))\n",
    "line_model.add(Dense(100, activation = 'relu', kernel_regularizer = l2(.01)))\n",
    "line_model.add(Dropout(0.15))\n",
    "line_model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "line_model.compile(loss = 'binary_crossentropy', optimizer = 'adam')\n",
    "\n",
    "line_history = line_model.fit(line_Z_train, line_y_train, validation_data = (line_Z_test, line_y_test), batch_size = 512, \n",
    "                   epochs = 100, verbosity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ede169b5-d78b-4304-8f5c-98c09405827e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(line_history.epoch, line_history.history['loss'], c='g');      # green - training loss # Loss\n",
    "plt.plot(line_history.epoch, line_history.history['val_loss'], c='b');  # blue - test loss # Val loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdbb031-d5da-447e-86db-9457482ebd20",
   "metadata": {},
   "source": [
    "- Char NN with PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "825fba8e-b694-4582-be77-5b47297fb0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 1000, random_state = 42)\n",
    "char_Z_train = pca.fit_transform(char_Xs_train)\n",
    "char_Z_test = pca.transform(char_Xs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69d99f45-eb09-445f-ba8a-33494ffaf499",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 4.1261 - val_loss: 1.9712\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.5643 - val_loss: 1.5581\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6109 - val_loss: 1.2297\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0173 - val_loss: 0.9994\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6514 - val_loss: 0.8546\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4428 - val_loss: 0.7589\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3049 - val_loss: 0.6961\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2183 - val_loss: 0.6498\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1650 - val_loss: 0.6156\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1273 - val_loss: 0.5913\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1026 - val_loss: 0.5747\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0830 - val_loss: 0.5639\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0697 - val_loss: 0.5564\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0590 - val_loss: 0.5518\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0502 - val_loss: 0.5489\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0442 - val_loss: 0.5461\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.5429\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0338 - val_loss: 0.5399\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0302 - val_loss: 0.5372\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0272 - val_loss: 0.5344\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0248 - val_loss: 0.5316\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0227 - val_loss: 0.5293\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0209 - val_loss: 0.5271\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0194 - val_loss: 0.5249\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0180 - val_loss: 0.5234\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.5223\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.5213\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.5202\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.5191\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.5183\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.5176\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.5172\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.5168\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.5168\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.5171\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.5173\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.5175\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.5175\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.5174\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.5173\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.5172\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.5171\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.5170\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0071 - val_loss: 0.5168\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.5163\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.5158\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.5158\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.5161\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.5167\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.5171\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.5174\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.5177\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.5180\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.5181\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.5183\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.5184\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.5187\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.5190\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.5191\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.5191\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.5192\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.5192\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.5195\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.5198\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.5200\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.5201\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.5202\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.5202\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.5203\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.5204\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.5205\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.5207\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.5208\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.5208\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0030 - val_loss: 0.5209\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.5211\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.5209\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.5206\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.002 - 0s 5ms/step - loss: 0.0027 - val_loss: 0.5205\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.5204\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.5204\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.5203\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.5204\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.5206\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.5207\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.5208\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.5210\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.5213\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.5216\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.5218\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.5222\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.5225\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.5229\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.5233\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.5235\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.5238\n",
      "Epoch 97/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.5240\n",
      "Epoch 98/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.5242\n",
      "Epoch 99/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.5245\n",
      "Epoch 100/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.5247\n",
      "Epoch 101/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.5249\n",
      "Epoch 102/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.5252\n",
      "Epoch 103/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.5254\n",
      "Epoch 104/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.5257\n",
      "Epoch 105/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.5260\n",
      "Epoch 106/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.5262\n",
      "Epoch 107/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.5264\n",
      "Epoch 108/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.5266\n",
      "Epoch 109/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.5269\n",
      "Epoch 110/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.5271\n",
      "Epoch 111/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.5274\n",
      "Epoch 112/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.5279\n",
      "Epoch 113/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.5283\n",
      "Epoch 114/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.5287\n",
      "Epoch 115/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.5293\n",
      "Epoch 116/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.5297\n",
      "Epoch 117/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.5301\n",
      "Epoch 118/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.5304\n",
      "Epoch 119/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.5308\n",
      "Epoch 120/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.5311\n",
      "Epoch 121/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.5313\n",
      "Epoch 122/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.5315\n",
      "Epoch 123/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.5317\n",
      "Epoch 124/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.5318\n",
      "Epoch 125/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.5319\n",
      "Epoch 126/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.5321\n",
      "Epoch 127/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.5323\n",
      "Epoch 128/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.5325\n",
      "Epoch 129/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.5327\n",
      "Epoch 130/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.5329\n",
      "Epoch 131/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.5332\n",
      "Epoch 132/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.5335\n",
      "Epoch 133/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.5337\n",
      "Epoch 134/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.5339\n",
      "Epoch 135/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.5342\n",
      "Epoch 136/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.5346\n",
      "Epoch 137/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.5350\n",
      "Epoch 138/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.5354\n",
      "Epoch 139/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 9.7459e-0 - 0s 5ms/step - loss: 0.0010 - val_loss: 0.5358\n",
      "Epoch 140/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.5362\n",
      "Epoch 141/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.5365\n",
      "Epoch 142/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.5367\n",
      "Epoch 143/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.5370\n",
      "Epoch 144/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.9036e-04 - val_loss: 0.5373\n",
      "Epoch 145/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.7985e-04 - val_loss: 0.5376\n",
      "Epoch 146/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.6980e-04 - val_loss: 0.5378\n",
      "Epoch 147/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.5973e-04 - val_loss: 0.5380\n",
      "Epoch 148/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.4925e-04 - val_loss: 0.5382\n",
      "Epoch 149/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.3934e-04 - val_loss: 0.5383\n",
      "Epoch 150/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.2951e-04 - val_loss: 0.5385\n",
      "Epoch 151/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.1979e-04 - val_loss: 0.5386\n",
      "Epoch 152/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.1049e-04 - val_loss: 0.5387\n",
      "Epoch 153/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.0093e-04 - val_loss: 0.5388\n",
      "Epoch 154/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.9169e-04 - val_loss: 0.5389\n",
      "Epoch 155/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.8234e-04 - val_loss: 0.5391\n",
      "Epoch 156/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.7364e-04 - val_loss: 0.5392\n",
      "Epoch 157/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.6512e-04 - val_loss: 0.5393\n",
      "Epoch 158/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.5684e-04 - val_loss: 0.5395\n",
      "Epoch 159/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.4894e-04 - val_loss: 0.5396\n",
      "Epoch 160/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.4082e-04 - val_loss: 0.5398\n",
      "Epoch 161/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.3295e-04 - val_loss: 0.5400\n",
      "Epoch 162/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.2513e-04 - val_loss: 0.5402\n",
      "Epoch 163/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.1737e-04 - val_loss: 0.5405\n",
      "Epoch 164/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.0940e-04 - val_loss: 0.5407\n",
      "Epoch 165/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.0128e-04 - val_loss: 0.5410\n",
      "Epoch 166/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.9292e-04 - val_loss: 0.5412\n",
      "Epoch 167/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.8526e-04 - val_loss: 0.5415\n",
      "Epoch 168/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.7716e-04 - val_loss: 0.5417\n",
      "Epoch 169/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.6876e-04 - val_loss: 0.5420\n",
      "Epoch 170/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.6095e-04 - val_loss: 0.5423\n",
      "Epoch 171/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.5323e-04 - val_loss: 0.5426\n",
      "Epoch 172/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.4536e-04 - val_loss: 0.5429\n",
      "Epoch 173/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.3833e-04 - val_loss: 0.5432\n",
      "Epoch 174/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.3124e-04 - val_loss: 0.5435\n",
      "Epoch 175/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.2402e-04 - val_loss: 0.5437\n",
      "Epoch 176/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.1713e-04 - val_loss: 0.5439\n",
      "Epoch 177/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.1030e-04 - val_loss: 0.5442\n",
      "Epoch 178/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.0367e-04 - val_loss: 0.5445\n",
      "Epoch 179/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.9703e-04 - val_loss: 0.5449\n",
      "Epoch 180/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.9084e-04 - val_loss: 0.5453\n",
      "Epoch 181/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.8457e-04 - val_loss: 0.5457\n",
      "Epoch 182/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.7831e-04 - val_loss: 0.5460\n",
      "Epoch 183/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.7195e-04 - val_loss: 0.5463\n",
      "Epoch 184/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.6574e-04 - val_loss: 0.5466\n",
      "Epoch 185/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.5974e-04 - val_loss: 0.5467\n",
      "Epoch 186/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.5383e-04 - val_loss: 0.5469\n",
      "Epoch 187/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.4814e-04 - val_loss: 0.5472\n",
      "Epoch 188/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.4203e-04 - val_loss: 0.5474\n",
      "Epoch 189/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.3619e-04 - val_loss: 0.5476\n",
      "Epoch 190/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.2999e-04 - val_loss: 0.5480\n",
      "Epoch 191/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.2431e-04 - val_loss: 0.5483\n",
      "Epoch 192/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.1847e-04 - val_loss: 0.5486\n",
      "Epoch 193/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.1300e-04 - val_loss: 0.5488\n",
      "Epoch 194/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.0797e-04 - val_loss: 0.5490\n",
      "Epoch 195/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.0316e-04 - val_loss: 0.5493\n",
      "Epoch 196/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.9840e-04 - val_loss: 0.5495\n",
      "Epoch 197/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.9372e-04 - val_loss: 0.5497\n",
      "Epoch 198/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.8918e-04 - val_loss: 0.5499\n",
      "Epoch 199/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.8450e-04 - val_loss: 0.5502\n",
      "Epoch 200/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.7990e-04 - val_loss: 0.5504\n",
      "Epoch 201/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.7483e-04 - val_loss: 0.5506\n",
      "Epoch 202/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.6980e-04 - val_loss: 0.5508\n",
      "Epoch 203/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.6489e-04 - val_loss: 0.5510\n",
      "Epoch 204/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.6024e-04 - val_loss: 0.5512\n",
      "Epoch 205/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.5528e-04 - val_loss: 0.5515\n",
      "Epoch 206/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.5044e-04 - val_loss: 0.5517\n",
      "Epoch 207/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.4607e-04 - val_loss: 0.5520\n",
      "Epoch 208/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.4138e-04 - val_loss: 0.5522\n",
      "Epoch 209/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.3697e-04 - val_loss: 0.5524\n",
      "Epoch 210/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.3273e-04 - val_loss: 0.5526\n",
      "Epoch 211/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.2847e-04 - val_loss: 0.5527\n",
      "Epoch 212/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.2420e-04 - val_loss: 0.5529\n",
      "Epoch 213/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.2032e-04 - val_loss: 0.5531\n",
      "Epoch 214/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.1635e-04 - val_loss: 0.5533\n",
      "Epoch 215/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.1264e-04 - val_loss: 0.5535\n",
      "Epoch 216/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.0894e-04 - val_loss: 0.5537\n",
      "Epoch 217/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.0531e-04 - val_loss: 0.5540\n",
      "Epoch 218/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.0142e-04 - val_loss: 0.5542\n",
      "Epoch 219/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.9774e-04 - val_loss: 0.5544\n",
      "Epoch 220/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.9404e-04 - val_loss: 0.5546\n",
      "Epoch 221/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.9032e-04 - val_loss: 0.5549\n",
      "Epoch 222/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.8661e-04 - val_loss: 0.5551\n",
      "Epoch 223/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.8288e-04 - val_loss: 0.5554\n",
      "Epoch 224/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.7932e-04 - val_loss: 0.5555\n",
      "Epoch 225/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.7582e-04 - val_loss: 0.5558\n",
      "Epoch 226/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.7237e-04 - val_loss: 0.5560\n",
      "Epoch 227/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.6884e-04 - val_loss: 0.5563\n",
      "Epoch 228/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.6536e-04 - val_loss: 0.5566\n",
      "Epoch 229/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.6163e-04 - val_loss: 0.5569\n",
      "Epoch 230/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.5762e-04 - val_loss: 0.5570\n",
      "Epoch 231/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.5351e-04 - val_loss: 0.5571\n",
      "Epoch 232/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.4946e-04 - val_loss: 0.5573\n",
      "Epoch 233/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.4551e-04 - val_loss: 0.5574\n",
      "Epoch 234/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.4218e-04 - val_loss: 0.5576\n",
      "Epoch 235/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.3871e-04 - val_loss: 0.5577\n",
      "Epoch 236/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.3541e-04 - val_loss: 0.5579\n",
      "Epoch 237/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.3202e-04 - val_loss: 0.5581\n",
      "Epoch 238/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.2888e-04 - val_loss: 0.5583\n",
      "Epoch 239/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.2565e-04 - val_loss: 0.5585\n",
      "Epoch 240/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.2268e-04 - val_loss: 0.5586\n",
      "Epoch 241/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.1985e-04 - val_loss: 0.5587\n",
      "Epoch 242/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.1720e-04 - val_loss: 0.5589\n",
      "Epoch 243/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.1453e-04 - val_loss: 0.5590\n",
      "Epoch 244/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.1175e-04 - val_loss: 0.5590\n",
      "Epoch 245/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.0854e-04 - val_loss: 0.5590\n",
      "Epoch 246/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.0560e-04 - val_loss: 0.5591\n",
      "Epoch 247/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.0282e-04 - val_loss: 0.5593\n",
      "Epoch 248/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.0012e-04 - val_loss: 0.5594\n",
      "Epoch 249/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.9750e-04 - val_loss: 0.5596\n",
      "Epoch 250/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.9506e-04 - val_loss: 0.5598\n",
      "Epoch 251/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 3.8861e-0 - 0s 4ms/step - loss: 3.9247e-04 - val_loss: 0.5600\n",
      "Epoch 252/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.8992e-04 - val_loss: 0.5603\n",
      "Epoch 253/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.8743e-04 - val_loss: 0.5606\n",
      "Epoch 254/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.8493e-04 - val_loss: 0.5609\n",
      "Epoch 255/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.8233e-04 - val_loss: 0.5612\n",
      "Epoch 256/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.7973e-04 - val_loss: 0.5614\n",
      "Epoch 257/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.7728e-04 - val_loss: 0.5617\n",
      "Epoch 258/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.7480e-04 - val_loss: 0.5619\n",
      "Epoch 259/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.7241e-04 - val_loss: 0.5621\n",
      "Epoch 260/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.7013e-04 - val_loss: 0.5622\n",
      "Epoch 261/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.6797e-04 - val_loss: 0.5624\n",
      "Epoch 262/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.6565e-04 - val_loss: 0.5626\n",
      "Epoch 263/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.6344e-04 - val_loss: 0.5628\n",
      "Epoch 264/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.6114e-04 - val_loss: 0.5630\n",
      "Epoch 265/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.5861e-04 - val_loss: 0.5633\n",
      "Epoch 266/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.5629e-04 - val_loss: 0.5634\n",
      "Epoch 267/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.5399e-04 - val_loss: 0.5636\n",
      "Epoch 268/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.5177e-04 - val_loss: 0.5637\n",
      "Epoch 269/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.4969e-04 - val_loss: 0.5639\n",
      "Epoch 270/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.4757e-04 - val_loss: 0.5641\n",
      "Epoch 271/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.4550e-04 - val_loss: 0.5643\n",
      "Epoch 272/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.4349e-04 - val_loss: 0.5644\n",
      "Epoch 273/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.4149e-04 - val_loss: 0.5645\n",
      "Epoch 274/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.3960e-04 - val_loss: 0.5647\n",
      "Epoch 275/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.3736e-04 - val_loss: 0.5648\n",
      "Epoch 276/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.3531e-04 - val_loss: 0.5650\n",
      "Epoch 277/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.3326e-04 - val_loss: 0.5651\n",
      "Epoch 278/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.3123e-04 - val_loss: 0.5652\n",
      "Epoch 279/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.2915e-04 - val_loss: 0.5654\n",
      "Epoch 280/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.2711e-04 - val_loss: 0.5656\n",
      "Epoch 281/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.2506e-04 - val_loss: 0.5658\n",
      "Epoch 282/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.2314e-04 - val_loss: 0.5660\n",
      "Epoch 283/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.2125e-04 - val_loss: 0.5661\n",
      "Epoch 284/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.1934e-04 - val_loss: 0.5663\n",
      "Epoch 285/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.1751e-04 - val_loss: 0.5665\n",
      "Epoch 286/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.1565e-04 - val_loss: 0.5668\n",
      "Epoch 287/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.1374e-04 - val_loss: 0.5670\n",
      "Epoch 288/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.1189e-04 - val_loss: 0.5672\n",
      "Epoch 289/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.1002e-04 - val_loss: 0.5673\n",
      "Epoch 290/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.0797e-04 - val_loss: 0.5674\n",
      "Epoch 291/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.0583e-04 - val_loss: 0.5675\n",
      "Epoch 292/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.0379e-04 - val_loss: 0.5676\n",
      "Epoch 293/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.0176e-04 - val_loss: 0.5678\n",
      "Epoch 294/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.9981e-04 - val_loss: 0.5679\n",
      "Epoch 295/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.9798e-04 - val_loss: 0.5681\n",
      "Epoch 296/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.9612e-04 - val_loss: 0.5682\n",
      "Epoch 297/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.9442e-04 - val_loss: 0.5684\n",
      "Epoch 298/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.9275e-04 - val_loss: 0.5685\n",
      "Epoch 299/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.9107e-04 - val_loss: 0.5687\n",
      "Epoch 300/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.8945e-04 - val_loss: 0.5689\n",
      "Epoch 301/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.8788e-04 - val_loss: 0.5692\n",
      "Epoch 302/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.8630e-04 - val_loss: 0.5694\n",
      "Epoch 303/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.8474e-04 - val_loss: 0.5696\n",
      "Epoch 304/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.8317e-04 - val_loss: 0.5698\n",
      "Epoch 305/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.8162e-04 - val_loss: 0.5699\n",
      "Epoch 306/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.8004e-04 - val_loss: 0.5701\n",
      "Epoch 307/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7849e-04 - val_loss: 0.5703\n",
      "Epoch 308/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7695e-04 - val_loss: 0.5705\n",
      "Epoch 309/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.7541e-04 - val_loss: 0.5707\n",
      "Epoch 310/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7394e-04 - val_loss: 0.5709\n",
      "Epoch 311/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7246e-04 - val_loss: 0.5712\n",
      "Epoch 312/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7096e-04 - val_loss: 0.5715\n",
      "Epoch 313/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.6954e-04 - val_loss: 0.5718\n",
      "Epoch 314/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.6801e-04 - val_loss: 0.5720\n",
      "Epoch 315/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.9057e-0 - 0s 4ms/step - loss: 2.6658e-04 - val_loss: 0.5722\n",
      "Epoch 316/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.6509e-04 - val_loss: 0.5724\n",
      "Epoch 317/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.6362e-04 - val_loss: 0.5726\n",
      "Epoch 318/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.6221e-04 - val_loss: 0.5728\n",
      "Epoch 319/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.6077e-04 - val_loss: 0.5730\n",
      "Epoch 320/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.5934e-04 - val_loss: 0.5732\n",
      "Epoch 321/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.5798e-04 - val_loss: 0.5734\n",
      "Epoch 322/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.5661e-04 - val_loss: 0.5735\n",
      "Epoch 323/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.5518e-04 - val_loss: 0.5737\n",
      "Epoch 324/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.5362e-04 - val_loss: 0.5737\n",
      "Epoch 325/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.5203e-04 - val_loss: 0.5738\n",
      "Epoch 326/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.5062e-04 - val_loss: 0.5738\n",
      "Epoch 327/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.4911e-04 - val_loss: 0.5739\n",
      "Epoch 328/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.4771e-04 - val_loss: 0.5741\n",
      "Epoch 329/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.4639e-04 - val_loss: 0.5742\n",
      "Epoch 330/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.4508e-04 - val_loss: 0.5743\n",
      "Epoch 331/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.4380e-04 - val_loss: 0.5744\n",
      "Epoch 332/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.4253e-04 - val_loss: 0.5745\n",
      "Epoch 333/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.4134e-04 - val_loss: 0.5746\n",
      "Epoch 334/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.4005e-04 - val_loss: 0.5747\n",
      "Epoch 335/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.3886e-04 - val_loss: 0.5749\n",
      "Epoch 336/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.3763e-04 - val_loss: 0.5750\n",
      "Epoch 337/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.3646e-04 - val_loss: 0.5751\n",
      "Epoch 338/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.3533e-04 - val_loss: 0.5752\n",
      "Epoch 339/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.3422e-04 - val_loss: 0.5754\n",
      "Epoch 340/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.3311e-04 - val_loss: 0.5755\n",
      "Epoch 341/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.3200e-04 - val_loss: 0.5756\n",
      "Epoch 342/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.3087e-04 - val_loss: 0.5757\n",
      "Epoch 343/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.2975e-04 - val_loss: 0.5759\n",
      "Epoch 344/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.2871e-04 - val_loss: 0.5760\n",
      "Epoch 345/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.2763e-04 - val_loss: 0.5762\n",
      "Epoch 346/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.2652e-04 - val_loss: 0.5764\n",
      "Epoch 347/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.2537e-04 - val_loss: 0.5766\n",
      "Epoch 348/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.2420e-04 - val_loss: 0.5768\n",
      "Epoch 349/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.2305e-04 - val_loss: 0.5770\n",
      "Epoch 350/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.2191e-04 - val_loss: 0.5772\n",
      "Epoch 351/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 2.1948e-0 - 0s 4ms/step - loss: 2.2079e-04 - val_loss: 0.5774\n",
      "Epoch 352/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.1970e-04 - val_loss: 0.5776\n",
      "Epoch 353/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.1862e-04 - val_loss: 0.5778\n",
      "Epoch 354/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.1756e-04 - val_loss: 0.5779\n",
      "Epoch 355/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.1651e-04 - val_loss: 0.5781\n",
      "Epoch 356/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.1545e-04 - val_loss: 0.5782\n",
      "Epoch 357/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.1440e-04 - val_loss: 0.5783\n",
      "Epoch 358/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.1337e-04 - val_loss: 0.5785\n",
      "Epoch 359/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.1235e-04 - val_loss: 0.5787\n",
      "Epoch 360/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.1125e-04 - val_loss: 0.5789\n",
      "Epoch 361/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.1017e-04 - val_loss: 0.5792\n",
      "Epoch 362/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.0908e-04 - val_loss: 0.5794\n",
      "Epoch 363/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.0803e-04 - val_loss: 0.5795\n",
      "Epoch 364/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.0701e-04 - val_loss: 0.5797\n",
      "Epoch 365/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.0602e-04 - val_loss: 0.5799\n",
      "Epoch 366/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.0503e-04 - val_loss: 0.5801\n",
      "Epoch 367/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.0407e-04 - val_loss: 0.5803\n",
      "Epoch 368/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.0309e-04 - val_loss: 0.5804\n",
      "Epoch 369/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.0211e-04 - val_loss: 0.5806\n",
      "Epoch 370/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.0114e-04 - val_loss: 0.5807\n",
      "Epoch 371/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.0023e-04 - val_loss: 0.5809\n",
      "Epoch 372/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9931e-04 - val_loss: 0.5811\n",
      "Epoch 373/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9837e-04 - val_loss: 0.5812\n",
      "Epoch 374/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9746e-04 - val_loss: 0.5814\n",
      "Epoch 375/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9657e-04 - val_loss: 0.5817\n",
      "Epoch 376/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9567e-04 - val_loss: 0.5819\n",
      "Epoch 377/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.9481e-04 - val_loss: 0.5820\n",
      "Epoch 378/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9393e-04 - val_loss: 0.5822\n",
      "Epoch 379/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9308e-04 - val_loss: 0.5824\n",
      "Epoch 380/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9223e-04 - val_loss: 0.5826\n",
      "Epoch 381/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9139e-04 - val_loss: 0.5828\n",
      "Epoch 382/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.9056e-04 - val_loss: 0.5829\n",
      "Epoch 383/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.8972e-04 - val_loss: 0.5831\n",
      "Epoch 384/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.8885e-04 - val_loss: 0.5832\n",
      "Epoch 385/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.8799e-04 - val_loss: 0.5834\n",
      "Epoch 386/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.8712e-04 - val_loss: 0.5836\n",
      "Epoch 387/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.8626e-04 - val_loss: 0.5838\n",
      "Epoch 388/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.8544e-04 - val_loss: 0.5840\n",
      "Epoch 389/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.8463e-04 - val_loss: 0.5841\n",
      "Epoch 390/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.8378e-04 - val_loss: 0.5843\n",
      "Epoch 391/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.8297e-04 - val_loss: 0.5845\n",
      "Epoch 392/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.8218e-04 - val_loss: 0.5847\n",
      "Epoch 393/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.8138e-04 - val_loss: 0.5848\n",
      "Epoch 394/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.8065e-04 - val_loss: 0.5850\n",
      "Epoch 395/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.7991e-04 - val_loss: 0.5851\n",
      "Epoch 396/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7915e-04 - val_loss: 0.5852\n",
      "Epoch 397/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7844e-04 - val_loss: 0.5853\n",
      "Epoch 398/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7770e-04 - val_loss: 0.5854\n",
      "Epoch 399/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7697e-04 - val_loss: 0.5855\n",
      "Epoch 400/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7621e-04 - val_loss: 0.5857\n",
      "Epoch 401/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7545e-04 - val_loss: 0.5858\n",
      "Epoch 402/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7466e-04 - val_loss: 0.5860\n",
      "Epoch 403/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7391e-04 - val_loss: 0.5861\n",
      "Epoch 404/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7316e-04 - val_loss: 0.5863\n",
      "Epoch 405/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7239e-04 - val_loss: 0.5864\n",
      "Epoch 406/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.7166e-04 - val_loss: 0.5865\n",
      "Epoch 407/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7087e-04 - val_loss: 0.5867\n",
      "Epoch 408/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.7011e-04 - val_loss: 0.5869\n",
      "Epoch 409/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6939e-04 - val_loss: 0.5870\n",
      "Epoch 410/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6869e-04 - val_loss: 0.5872\n",
      "Epoch 411/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6796e-04 - val_loss: 0.5874\n",
      "Epoch 412/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6726e-04 - val_loss: 0.5875\n",
      "Epoch 413/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6653e-04 - val_loss: 0.5877\n",
      "Epoch 414/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6582e-04 - val_loss: 0.5878\n",
      "Epoch 415/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6516e-04 - val_loss: 0.5879\n",
      "Epoch 416/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6447e-04 - val_loss: 0.5881\n",
      "Epoch 417/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.6379e-04 - val_loss: 0.5882\n",
      "Epoch 418/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6311e-04 - val_loss: 0.5883\n",
      "Epoch 419/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6246e-04 - val_loss: 0.5884\n",
      "Epoch 420/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6181e-04 - val_loss: 0.5885\n",
      "Epoch 421/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6117e-04 - val_loss: 0.5886\n",
      "Epoch 422/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.6044e-04 - val_loss: 0.5886\n",
      "Epoch 423/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5968e-04 - val_loss: 0.5887\n",
      "Epoch 424/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5888e-04 - val_loss: 0.5888\n",
      "Epoch 425/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5816e-04 - val_loss: 0.5889\n",
      "Epoch 426/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5743e-04 - val_loss: 0.5890\n",
      "Epoch 427/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5676e-04 - val_loss: 0.5891\n",
      "Epoch 428/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5607e-04 - val_loss: 0.5893\n",
      "Epoch 429/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5538e-04 - val_loss: 0.5895\n",
      "Epoch 430/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5474e-04 - val_loss: 0.5896\n",
      "Epoch 431/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5410e-04 - val_loss: 0.5897\n",
      "Epoch 432/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.5346e-04 - val_loss: 0.5898\n",
      "Epoch 433/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5283e-04 - val_loss: 0.5900\n",
      "Epoch 434/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5220e-04 - val_loss: 0.5901\n",
      "Epoch 435/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5157e-04 - val_loss: 0.5904\n",
      "Epoch 436/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5092e-04 - val_loss: 0.5907\n",
      "Epoch 437/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.5023e-04 - val_loss: 0.5909\n",
      "Epoch 438/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4958e-04 - val_loss: 0.5911\n",
      "Epoch 439/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4897e-04 - val_loss: 0.5912\n",
      "Epoch 440/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4834e-04 - val_loss: 0.5914\n",
      "Epoch 441/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4769e-04 - val_loss: 0.5916\n",
      "Epoch 442/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4707e-04 - val_loss: 0.5919\n",
      "Epoch 443/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4640e-04 - val_loss: 0.5922\n",
      "Epoch 444/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4574e-04 - val_loss: 0.5924\n",
      "Epoch 445/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4511e-04 - val_loss: 0.5926\n",
      "Epoch 446/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4449e-04 - val_loss: 0.5928\n",
      "Epoch 447/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4389e-04 - val_loss: 0.5929\n",
      "Epoch 448/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4328e-04 - val_loss: 0.5931\n",
      "Epoch 449/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4269e-04 - val_loss: 0.5932\n",
      "Epoch 450/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4210e-04 - val_loss: 0.5934\n",
      "Epoch 451/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4147e-04 - val_loss: 0.5935\n",
      "Epoch 452/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4085e-04 - val_loss: 0.5937\n",
      "Epoch 453/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4025e-04 - val_loss: 0.5939\n",
      "Epoch 454/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3962e-04 - val_loss: 0.5941\n",
      "Epoch 455/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3902e-04 - val_loss: 0.5943\n",
      "Epoch 456/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3842e-04 - val_loss: 0.5945\n",
      "Epoch 457/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3785e-04 - val_loss: 0.5946\n",
      "Epoch 458/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3727e-04 - val_loss: 0.5947\n",
      "Epoch 459/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3664e-04 - val_loss: 0.5948\n",
      "Epoch 460/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3602e-04 - val_loss: 0.5949\n",
      "Epoch 461/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.4316e-0 - 0s 5ms/step - loss: 1.3539e-04 - val_loss: 0.5950\n",
      "Epoch 462/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3476e-04 - val_loss: 0.5951\n",
      "Epoch 463/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3415e-04 - val_loss: 0.5952\n",
      "Epoch 464/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3357e-04 - val_loss: 0.5953\n",
      "Epoch 465/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3302e-04 - val_loss: 0.5954\n",
      "Epoch 466/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3248e-04 - val_loss: 0.5956\n",
      "Epoch 467/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3194e-04 - val_loss: 0.5957\n",
      "Epoch 468/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3143e-04 - val_loss: 0.5958\n",
      "Epoch 469/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3092e-04 - val_loss: 0.5959\n",
      "Epoch 470/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3039e-04 - val_loss: 0.5960\n",
      "Epoch 471/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2985e-04 - val_loss: 0.5961\n",
      "Epoch 472/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2928e-04 - val_loss: 0.5963\n",
      "Epoch 473/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2876e-04 - val_loss: 0.5964\n",
      "Epoch 474/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2824e-04 - val_loss: 0.5965\n",
      "Epoch 475/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2772e-04 - val_loss: 0.5966\n",
      "Epoch 476/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2723e-04 - val_loss: 0.5968\n",
      "Epoch 477/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2666e-04 - val_loss: 0.5970\n",
      "Epoch 478/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2614e-04 - val_loss: 0.5972\n",
      "Epoch 479/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.2070e-0 - 0s 5ms/step - loss: 1.2563e-04 - val_loss: 0.5973\n",
      "Epoch 480/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2514e-04 - val_loss: 0.5974\n",
      "Epoch 481/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2467e-04 - val_loss: 0.5975\n",
      "Epoch 482/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2421e-04 - val_loss: 0.5977\n",
      "Epoch 483/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2372e-04 - val_loss: 0.5978\n",
      "Epoch 484/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2324e-04 - val_loss: 0.5979\n",
      "Epoch 485/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2277e-04 - val_loss: 0.5980\n",
      "Epoch 486/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2229e-04 - val_loss: 0.5982\n",
      "Epoch 487/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2183e-04 - val_loss: 0.5983\n",
      "Epoch 488/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2133e-04 - val_loss: 0.5985\n",
      "Epoch 489/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2086e-04 - val_loss: 0.5986\n",
      "Epoch 490/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2038e-04 - val_loss: 0.5988\n",
      "Epoch 491/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1989e-04 - val_loss: 0.5989\n",
      "Epoch 492/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1941e-04 - val_loss: 0.5989\n",
      "Epoch 493/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1891e-04 - val_loss: 0.5990\n",
      "Epoch 494/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1839e-04 - val_loss: 0.5990\n",
      "Epoch 495/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1789e-04 - val_loss: 0.5991\n",
      "Epoch 496/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1733e-04 - val_loss: 0.5991\n",
      "Epoch 497/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1682e-04 - val_loss: 0.5992\n",
      "Epoch 498/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1623e-04 - val_loss: 0.5992\n",
      "Epoch 499/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1566e-04 - val_loss: 0.5993\n",
      "Epoch 500/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1514e-04 - val_loss: 0.5994\n",
      "Epoch 501/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1462e-04 - val_loss: 0.5995\n",
      "Epoch 502/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1412e-04 - val_loss: 0.5995\n",
      "Epoch 503/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1358e-04 - val_loss: 0.5996\n",
      "Epoch 504/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.1069e-0 - 0s 4ms/step - loss: 1.1305e-04 - val_loss: 0.5996\n",
      "Epoch 505/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1260e-04 - val_loss: 0.5997\n",
      "Epoch 506/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1214e-04 - val_loss: 0.5998\n",
      "Epoch 507/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1172e-04 - val_loss: 0.5999\n",
      "Epoch 508/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.1722e-0 - 0s 5ms/step - loss: 1.1128e-04 - val_loss: 0.6000\n",
      "Epoch 509/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1085e-04 - val_loss: 0.6001\n",
      "Epoch 510/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1042e-04 - val_loss: 0.6003\n",
      "Epoch 511/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1002e-04 - val_loss: 0.6004\n",
      "Epoch 512/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0961e-04 - val_loss: 0.6005\n",
      "Epoch 513/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0923e-04 - val_loss: 0.6006\n",
      "Epoch 514/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0885e-04 - val_loss: 0.6007\n",
      "Epoch 515/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0847e-04 - val_loss: 0.6008\n",
      "Epoch 516/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0807e-04 - val_loss: 0.6009\n",
      "Epoch 517/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0766e-04 - val_loss: 0.6010\n",
      "Epoch 518/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0725e-04 - val_loss: 0.6012\n",
      "Epoch 519/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0684e-04 - val_loss: 0.6014\n",
      "Epoch 520/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0642e-04 - val_loss: 0.6016\n",
      "Epoch 521/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0602e-04 - val_loss: 0.6018\n",
      "Epoch 522/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0560e-04 - val_loss: 0.6019\n",
      "Epoch 523/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0522e-04 - val_loss: 0.6021\n",
      "Epoch 524/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0484e-04 - val_loss: 0.6022\n",
      "Epoch 525/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0446e-04 - val_loss: 0.6024\n",
      "Epoch 526/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0405e-04 - val_loss: 0.6026\n",
      "Epoch 527/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0366e-04 - val_loss: 0.6027\n",
      "Epoch 528/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0326e-04 - val_loss: 0.6029\n",
      "Epoch 529/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0287e-04 - val_loss: 0.6030\n",
      "Epoch 530/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0248e-04 - val_loss: 0.6031\n",
      "Epoch 531/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0211e-04 - val_loss: 0.6033\n",
      "Epoch 532/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0176e-04 - val_loss: 0.6034\n",
      "Epoch 533/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0140e-04 - val_loss: 0.6035\n",
      "Epoch 534/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0106e-04 - val_loss: 0.6036\n",
      "Epoch 535/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0070e-04 - val_loss: 0.6037\n",
      "Epoch 536/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0034e-04 - val_loss: 0.6039\n",
      "Epoch 537/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.9977e-05 - val_loss: 0.6040\n",
      "Epoch 538/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.9595e-05 - val_loss: 0.6041\n",
      "Epoch 539/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.9225e-05 - val_loss: 0.6042\n",
      "Epoch 540/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.8871e-05 - val_loss: 0.6044\n",
      "Epoch 541/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.8510e-05 - val_loss: 0.6045\n",
      "Epoch 542/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.8138e-05 - val_loss: 0.6046\n",
      "Epoch 543/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.7768e-05 - val_loss: 0.6047\n",
      "Epoch 544/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.7422e-05 - val_loss: 0.6049\n",
      "Epoch 545/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.7085e-05 - val_loss: 0.6050\n",
      "Epoch 546/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.6731e-05 - val_loss: 0.6051\n",
      "Epoch 547/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.6392e-05 - val_loss: 0.6052\n",
      "Epoch 548/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.6057e-05 - val_loss: 0.6053\n",
      "Epoch 549/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.5737e-05 - val_loss: 0.6054\n",
      "Epoch 550/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.5392e-05 - val_loss: 0.6055\n",
      "Epoch 551/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 9.7422e-0 - 0s 4ms/step - loss: 9.5056e-05 - val_loss: 0.6057\n",
      "Epoch 552/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.4730e-05 - val_loss: 0.6058\n",
      "Epoch 553/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.4403e-05 - val_loss: 0.6059\n",
      "Epoch 554/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.4083e-05 - val_loss: 0.6059\n",
      "Epoch 555/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.3765e-05 - val_loss: 0.6060\n",
      "Epoch 556/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.3449e-05 - val_loss: 0.6061\n",
      "Epoch 557/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.3141e-05 - val_loss: 0.6062\n",
      "Epoch 558/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.2808e-05 - val_loss: 0.6063\n",
      "Epoch 559/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.2467e-05 - val_loss: 0.6064\n",
      "Epoch 560/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.2146e-05 - val_loss: 0.6065\n",
      "Epoch 561/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.1822e-05 - val_loss: 0.6066\n",
      "Epoch 562/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.1503e-05 - val_loss: 0.6068\n",
      "Epoch 563/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.1176e-05 - val_loss: 0.6069\n",
      "Epoch 564/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 9.0870e-05 - val_loss: 0.6071\n",
      "Epoch 565/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.0567e-05 - val_loss: 0.6072\n",
      "Epoch 566/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.0246e-05 - val_loss: 0.6073\n",
      "Epoch 567/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.9949e-05 - val_loss: 0.6075\n",
      "Epoch 568/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.9645e-05 - val_loss: 0.6076\n",
      "Epoch 569/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.9323e-05 - val_loss: 0.6077\n",
      "Epoch 570/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.9023e-05 - val_loss: 0.6078\n",
      "Epoch 571/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.8715e-05 - val_loss: 0.6079\n",
      "Epoch 572/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.8426e-05 - val_loss: 0.6080\n",
      "Epoch 573/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.8116e-05 - val_loss: 0.6082\n",
      "Epoch 574/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.7829e-05 - val_loss: 0.6083\n",
      "Epoch 575/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.7539e-05 - val_loss: 0.6084\n",
      "Epoch 576/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.7260e-05 - val_loss: 0.6086\n",
      "Epoch 577/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.6980e-05 - val_loss: 0.6087\n",
      "Epoch 578/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.6681e-05 - val_loss: 0.6088\n",
      "Epoch 579/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.6395e-05 - val_loss: 0.6090\n",
      "Epoch 580/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.6115e-05 - val_loss: 0.6091\n",
      "Epoch 581/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.5831e-05 - val_loss: 0.6092\n",
      "Epoch 582/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.5548e-05 - val_loss: 0.6093\n",
      "Epoch 583/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.5267e-05 - val_loss: 0.6094\n",
      "Epoch 584/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.4991e-05 - val_loss: 0.6095\n",
      "Epoch 585/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.4718e-05 - val_loss: 0.6096\n",
      "Epoch 586/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.4443e-05 - val_loss: 0.6097\n",
      "Epoch 587/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.4173e-05 - val_loss: 0.6098\n",
      "Epoch 588/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.3908e-05 - val_loss: 0.6098\n",
      "Epoch 589/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.3628e-05 - val_loss: 0.6099\n",
      "Epoch 590/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.3359e-05 - val_loss: 0.6100\n",
      "Epoch 591/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.3104e-05 - val_loss: 0.6101\n",
      "Epoch 592/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.2847e-05 - val_loss: 0.6103\n",
      "Epoch 593/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.2590e-05 - val_loss: 0.6104\n",
      "Epoch 594/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.2334e-05 - val_loss: 0.6105\n",
      "Epoch 595/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.2077e-05 - val_loss: 0.6106\n",
      "Epoch 596/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.1812e-05 - val_loss: 0.6107\n",
      "Epoch 597/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.1554e-05 - val_loss: 0.6108\n",
      "Epoch 598/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 8.1287e-05 - val_loss: 0.6109\n",
      "Epoch 599/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.1018e-05 - val_loss: 0.6110\n",
      "Epoch 600/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 9.1420e-0 - 0s 4ms/step - loss: 8.0757e-05 - val_loss: 0.6111\n",
      "Epoch 601/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.0499e-05 - val_loss: 0.6112\n",
      "Epoch 602/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 8.0239e-05 - val_loss: 0.6113\n",
      "Epoch 603/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.9978e-05 - val_loss: 0.6115\n",
      "Epoch 604/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 7.8938e-0 - 0s 5ms/step - loss: 7.9721e-05 - val_loss: 0.6116\n",
      "Epoch 605/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.9477e-05 - val_loss: 0.6117\n",
      "Epoch 606/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.9229e-05 - val_loss: 0.6118\n",
      "Epoch 607/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.8968e-05 - val_loss: 0.6119\n",
      "Epoch 608/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.8726e-05 - val_loss: 0.6120\n",
      "Epoch 609/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.8487e-05 - val_loss: 0.6120\n",
      "Epoch 610/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.8251e-05 - val_loss: 0.6121\n",
      "Epoch 611/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.8021e-05 - val_loss: 0.6122\n",
      "Epoch 612/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.7791e-05 - val_loss: 0.6124\n",
      "Epoch 613/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.7543e-05 - val_loss: 0.6125\n",
      "Epoch 614/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.7299e-05 - val_loss: 0.6127\n",
      "Epoch 615/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.7037e-05 - val_loss: 0.6128\n",
      "Epoch 616/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.6785e-05 - val_loss: 0.6129\n",
      "Epoch 617/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.6523e-05 - val_loss: 0.6130\n",
      "Epoch 618/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.6246e-05 - val_loss: 0.6131\n",
      "Epoch 619/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.5941e-05 - val_loss: 0.6131\n",
      "Epoch 620/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.5642e-05 - val_loss: 0.6132\n",
      "Epoch 621/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.5337e-05 - val_loss: 0.6132\n",
      "Epoch 622/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.5053e-05 - val_loss: 0.6133\n",
      "Epoch 623/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.4795e-05 - val_loss: 0.6134\n",
      "Epoch 624/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.4540e-05 - val_loss: 0.6134\n",
      "Epoch 625/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.4295e-05 - val_loss: 0.6135\n",
      "Epoch 626/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.4063e-05 - val_loss: 0.6135\n",
      "Epoch 627/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.3838e-05 - val_loss: 0.6136\n",
      "Epoch 628/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.3610e-05 - val_loss: 0.6136\n",
      "Epoch 629/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.3383e-05 - val_loss: 0.6137\n",
      "Epoch 630/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.3147e-05 - val_loss: 0.6138\n",
      "Epoch 631/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 7.6301e-0 - 0s 4ms/step - loss: 7.2923e-05 - val_loss: 0.6138\n",
      "Epoch 632/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 8.1266e-0 - 0s 4ms/step - loss: 7.2703e-05 - val_loss: 0.6139\n",
      "Epoch 633/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.2476e-05 - val_loss: 0.6140\n",
      "Epoch 634/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.2250e-05 - val_loss: 0.6140\n",
      "Epoch 635/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.2023e-05 - val_loss: 0.6141\n",
      "Epoch 636/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.1796e-05 - val_loss: 0.6142\n",
      "Epoch 637/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.1589e-05 - val_loss: 0.6143\n",
      "Epoch 638/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.1370e-05 - val_loss: 0.6144\n",
      "Epoch 639/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.1149e-05 - val_loss: 0.6144\n",
      "Epoch 640/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.0920e-05 - val_loss: 0.6145\n",
      "Epoch 641/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.0704e-05 - val_loss: 0.6145\n",
      "Epoch 642/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 7.0488e-05 - val_loss: 0.6146\n",
      "Epoch 643/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.0272e-05 - val_loss: 0.6147\n",
      "Epoch 644/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 7.0063e-05 - val_loss: 0.6147\n",
      "Epoch 645/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.9846e-05 - val_loss: 0.6148\n",
      "Epoch 646/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.9638e-05 - val_loss: 0.6148\n",
      "Epoch 647/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.9425e-05 - val_loss: 0.6149\n",
      "Epoch 648/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.9218e-05 - val_loss: 0.6150\n",
      "Epoch 649/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.9013e-05 - val_loss: 0.6151\n",
      "Epoch 650/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.8807e-05 - val_loss: 0.6152\n",
      "Epoch 651/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.8602e-05 - val_loss: 0.6153\n",
      "Epoch 652/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.8385e-05 - val_loss: 0.6154\n",
      "Epoch 653/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.8164e-05 - val_loss: 0.6155\n",
      "Epoch 654/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.7951e-05 - val_loss: 0.6156\n",
      "Epoch 655/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.7750e-05 - val_loss: 0.6157\n",
      "Epoch 656/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.7551e-05 - val_loss: 0.6159\n",
      "Epoch 657/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.7343e-05 - val_loss: 0.6160\n",
      "Epoch 658/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.7131e-05 - val_loss: 0.6161\n",
      "Epoch 659/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.6924e-05 - val_loss: 0.6162\n",
      "Epoch 660/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.6705e-05 - val_loss: 0.6163\n",
      "Epoch 661/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.6496e-05 - val_loss: 0.6164\n",
      "Epoch 662/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.6290e-05 - val_loss: 0.6165\n",
      "Epoch 663/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.6073e-05 - val_loss: 0.6167\n",
      "Epoch 664/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.5852e-05 - val_loss: 0.6168\n",
      "Epoch 665/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.5642e-05 - val_loss: 0.6168\n",
      "Epoch 666/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.5434e-05 - val_loss: 0.6169\n",
      "Epoch 667/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.5237e-05 - val_loss: 0.6170\n",
      "Epoch 668/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.5040e-05 - val_loss: 0.6171\n",
      "Epoch 669/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.4846e-05 - val_loss: 0.6171\n",
      "Epoch 670/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.4652e-05 - val_loss: 0.6172\n",
      "Epoch 671/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.4452e-05 - val_loss: 0.6173\n",
      "Epoch 672/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.4251e-05 - val_loss: 0.6173\n",
      "Epoch 673/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.4014e-05 - val_loss: 0.6174\n",
      "Epoch 674/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.3805e-05 - val_loss: 0.6174\n",
      "Epoch 675/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.3590e-05 - val_loss: 0.6175\n",
      "Epoch 676/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.3396e-05 - val_loss: 0.6176\n",
      "Epoch 677/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.3203e-05 - val_loss: 0.6177\n",
      "Epoch 678/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.3006e-05 - val_loss: 0.6177\n",
      "Epoch 679/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.2821e-05 - val_loss: 0.6178\n",
      "Epoch 680/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.2635e-05 - val_loss: 0.6179\n",
      "Epoch 681/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.2449e-05 - val_loss: 0.6180\n",
      "Epoch 682/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.2263e-05 - val_loss: 0.6181\n",
      "Epoch 683/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.2073e-05 - val_loss: 0.6182\n",
      "Epoch 684/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.1863e-05 - val_loss: 0.6183\n",
      "Epoch 685/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.1673e-05 - val_loss: 0.6184\n",
      "Epoch 686/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.1489e-05 - val_loss: 0.6185\n",
      "Epoch 687/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.1301e-05 - val_loss: 0.6186\n",
      "Epoch 688/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.1119e-05 - val_loss: 0.6187\n",
      "Epoch 689/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.0939e-05 - val_loss: 0.6188\n",
      "Epoch 690/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.0757e-05 - val_loss: 0.6189\n",
      "Epoch 691/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.0568e-05 - val_loss: 0.6190\n",
      "Epoch 692/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.0385e-05 - val_loss: 0.6191\n",
      "Epoch 693/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 6.0197e-05 - val_loss: 0.6192\n",
      "Epoch 694/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.0008e-05 - val_loss: 0.6193\n",
      "Epoch 695/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.9828e-05 - val_loss: 0.6194\n",
      "Epoch 696/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.9641e-05 - val_loss: 0.6195\n",
      "Epoch 697/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.9459e-05 - val_loss: 0.6196\n",
      "Epoch 698/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.9282e-05 - val_loss: 0.6196\n",
      "Epoch 699/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.9115e-05 - val_loss: 0.6197\n",
      "Epoch 700/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.8953e-05 - val_loss: 0.6198\n",
      "Epoch 701/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.8785e-05 - val_loss: 0.6199\n",
      "Epoch 702/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.8613e-05 - val_loss: 0.6200\n",
      "Epoch 703/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.8445e-05 - val_loss: 0.6201\n",
      "Epoch 704/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.8278e-05 - val_loss: 0.6202\n",
      "Epoch 705/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.8110e-05 - val_loss: 0.6203\n",
      "Epoch 706/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.7946e-05 - val_loss: 0.6204\n",
      "Epoch 707/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.7789e-05 - val_loss: 0.6206\n",
      "Epoch 708/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.7627e-05 - val_loss: 0.6207\n",
      "Epoch 709/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 5.3356e-0 - 0s 4ms/step - loss: 5.7459e-05 - val_loss: 0.6208\n",
      "Epoch 710/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.7300e-05 - val_loss: 0.6209\n",
      "Epoch 711/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.7138e-05 - val_loss: 0.6210\n",
      "Epoch 712/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.6977e-05 - val_loss: 0.6211\n",
      "Epoch 713/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 5.4473e-0 - 0s 4ms/step - loss: 5.6799e-05 - val_loss: 0.6212\n",
      "Epoch 714/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.6627e-05 - val_loss: 0.6214\n",
      "Epoch 715/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.6434e-05 - val_loss: 0.6215\n",
      "Epoch 716/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.6251e-05 - val_loss: 0.6216\n",
      "Epoch 717/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.6063e-05 - val_loss: 0.6217\n",
      "Epoch 718/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.5878e-05 - val_loss: 0.6218\n",
      "Epoch 719/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.5708e-05 - val_loss: 0.6219\n",
      "Epoch 720/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.5538e-05 - val_loss: 0.6220\n",
      "Epoch 721/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.5366e-05 - val_loss: 0.6221\n",
      "Epoch 722/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.5198e-05 - val_loss: 0.6222\n",
      "Epoch 723/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.5041e-05 - val_loss: 0.6223\n",
      "Epoch 724/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 5.1157e-0 - 0s 4ms/step - loss: 5.4879e-05 - val_loss: 0.6224\n",
      "Epoch 725/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.4719e-05 - val_loss: 0.6225\n",
      "Epoch 726/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.4556e-05 - val_loss: 0.6226\n",
      "Epoch 727/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.4395e-05 - val_loss: 0.6228\n",
      "Epoch 728/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.4230e-05 - val_loss: 0.6229\n",
      "Epoch 729/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.4070e-05 - val_loss: 0.6230\n",
      "Epoch 730/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.3903e-05 - val_loss: 0.6232\n",
      "Epoch 731/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.3747e-05 - val_loss: 0.6233\n",
      "Epoch 732/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.3595e-05 - val_loss: 0.6233\n",
      "Epoch 733/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.3445e-05 - val_loss: 0.6235\n",
      "Epoch 734/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.3293e-05 - val_loss: 0.6236\n",
      "Epoch 735/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.3137e-05 - val_loss: 0.6237\n",
      "Epoch 736/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.2982e-05 - val_loss: 0.6238\n",
      "Epoch 737/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.2839e-05 - val_loss: 0.6239\n",
      "Epoch 738/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.2695e-05 - val_loss: 0.6240\n",
      "Epoch 739/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.2552e-05 - val_loss: 0.6241\n",
      "Epoch 740/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.2418e-05 - val_loss: 0.6242\n",
      "Epoch 741/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.2277e-05 - val_loss: 0.6243\n",
      "Epoch 742/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.2140e-05 - val_loss: 0.6244\n",
      "Epoch 743/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.2001e-05 - val_loss: 0.6245\n",
      "Epoch 744/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.1866e-05 - val_loss: 0.6246\n",
      "Epoch 745/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.1723e-05 - val_loss: 0.6248\n",
      "Epoch 746/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.1586e-05 - val_loss: 0.6249\n",
      "Epoch 747/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.1444e-05 - val_loss: 0.6250\n",
      "Epoch 748/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.1305e-05 - val_loss: 0.6251\n",
      "Epoch 749/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 5.1157e-05 - val_loss: 0.6251\n",
      "Epoch 750/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.0997e-05 - val_loss: 0.6252\n",
      "Epoch 751/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.0839e-05 - val_loss: 0.6252\n",
      "Epoch 752/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.0695e-05 - val_loss: 0.6253\n",
      "Epoch 753/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.0542e-05 - val_loss: 0.6254\n",
      "Epoch 754/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.0395e-05 - val_loss: 0.6255\n",
      "Epoch 755/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.0251e-05 - val_loss: 0.6256\n",
      "Epoch 756/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 5.0110e-05 - val_loss: 0.6257\n",
      "Epoch 757/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.9962e-05 - val_loss: 0.6258\n",
      "Epoch 758/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.9818e-05 - val_loss: 0.6259\n",
      "Epoch 759/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.9669e-05 - val_loss: 0.6261\n",
      "Epoch 760/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.9520e-05 - val_loss: 0.6262\n",
      "Epoch 761/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.9382e-05 - val_loss: 0.6264\n",
      "Epoch 762/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.9244e-05 - val_loss: 0.6265\n",
      "Epoch 763/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.9111e-05 - val_loss: 0.6266\n",
      "Epoch 764/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.8975e-05 - val_loss: 0.6268\n",
      "Epoch 765/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.8837e-05 - val_loss: 0.6269\n",
      "Epoch 766/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.8696e-05 - val_loss: 0.6271\n",
      "Epoch 767/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.8558e-05 - val_loss: 0.6272\n",
      "Epoch 768/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.8424e-05 - val_loss: 0.6273\n",
      "Epoch 769/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.8286e-05 - val_loss: 0.6274\n",
      "Epoch 770/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.8152e-05 - val_loss: 0.6275\n",
      "Epoch 771/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.8009e-05 - val_loss: 0.6277\n",
      "Epoch 772/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.7875e-05 - val_loss: 0.6278\n",
      "Epoch 773/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.7740e-05 - val_loss: 0.6279\n",
      "Epoch 774/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.7612e-05 - val_loss: 0.6281\n",
      "Epoch 775/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.7475e-05 - val_loss: 0.6282\n",
      "Epoch 776/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.7343e-05 - val_loss: 0.6283\n",
      "Epoch 777/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.7214e-05 - val_loss: 0.6284\n",
      "Epoch 778/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.7087e-05 - val_loss: 0.6285\n",
      "Epoch 779/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.6954e-05 - val_loss: 0.6286\n",
      "Epoch 780/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.6820e-05 - val_loss: 0.6287\n",
      "Epoch 781/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.6690e-05 - val_loss: 0.6289\n",
      "Epoch 782/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.6557e-05 - val_loss: 0.6290\n",
      "Epoch 783/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.6428e-05 - val_loss: 0.6291\n",
      "Epoch 784/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.6295e-05 - val_loss: 0.6292\n",
      "Epoch 785/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.6169e-05 - val_loss: 0.6293\n",
      "Epoch 786/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.6045e-05 - val_loss: 0.6294\n",
      "Epoch 787/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.5919e-05 - val_loss: 0.6295\n",
      "Epoch 788/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.5796e-05 - val_loss: 0.6296\n",
      "Epoch 789/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.5675e-05 - val_loss: 0.6297\n",
      "Epoch 790/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.5553e-05 - val_loss: 0.6298\n",
      "Epoch 791/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.5433e-05 - val_loss: 0.6299\n",
      "Epoch 792/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.5313e-05 - val_loss: 0.6300\n",
      "Epoch 793/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.5194e-05 - val_loss: 0.6300\n",
      "Epoch 794/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.5075e-05 - val_loss: 0.6301\n",
      "Epoch 795/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.4957e-05 - val_loss: 0.6302\n",
      "Epoch 796/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.4842e-05 - val_loss: 0.6302\n",
      "Epoch 797/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.4722e-05 - val_loss: 0.6303\n",
      "Epoch 798/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.4604e-05 - val_loss: 0.6304\n",
      "Epoch 799/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.4487e-05 - val_loss: 0.6305\n",
      "Epoch 800/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.4365e-05 - val_loss: 0.6306\n",
      "Epoch 801/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.4237e-05 - val_loss: 0.6306\n",
      "Epoch 802/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.4113e-05 - val_loss: 0.6307\n",
      "Epoch 803/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.3984e-05 - val_loss: 0.6308\n",
      "Epoch 804/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.3860e-05 - val_loss: 0.6308\n",
      "Epoch 805/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.3742e-05 - val_loss: 0.6309\n",
      "Epoch 806/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.3630e-05 - val_loss: 0.6310\n",
      "Epoch 807/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.3515e-05 - val_loss: 0.6310\n",
      "Epoch 808/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.3400e-05 - val_loss: 0.6311\n",
      "Epoch 809/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.3291e-05 - val_loss: 0.6311\n",
      "Epoch 810/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.3180e-05 - val_loss: 0.6312\n",
      "Epoch 811/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.3071e-05 - val_loss: 0.6313\n",
      "Epoch 812/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.2967e-05 - val_loss: 0.6314\n",
      "Epoch 813/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.2851e-05 - val_loss: 0.6314\n",
      "Epoch 814/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.2742e-05 - val_loss: 0.6315\n",
      "Epoch 815/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.2631e-05 - val_loss: 0.6316\n",
      "Epoch 816/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.2519e-05 - val_loss: 0.6316\n",
      "Epoch 817/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.2398e-05 - val_loss: 0.6316\n",
      "Epoch 818/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.2271e-05 - val_loss: 0.6317\n",
      "Epoch 819/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.2153e-05 - val_loss: 0.6317\n",
      "Epoch 820/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.2027e-05 - val_loss: 0.6318\n",
      "Epoch 821/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.1913e-05 - val_loss: 0.6318\n",
      "Epoch 822/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.1801e-05 - val_loss: 0.6319\n",
      "Epoch 823/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.1680e-05 - val_loss: 0.6320\n",
      "Epoch 824/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.1567e-05 - val_loss: 0.6321\n",
      "Epoch 825/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.1453e-05 - val_loss: 0.6322\n",
      "Epoch 826/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.1342e-05 - val_loss: 0.6323\n",
      "Epoch 827/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.1226e-05 - val_loss: 0.6325\n",
      "Epoch 828/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.1109e-05 - val_loss: 0.6326\n",
      "Epoch 829/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.0996e-05 - val_loss: 0.6327\n",
      "Epoch 830/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.0887e-05 - val_loss: 0.6328\n",
      "Epoch 831/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.0772e-05 - val_loss: 0.6329\n",
      "Epoch 832/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.0655e-05 - val_loss: 0.6330\n",
      "Epoch 833/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.0546e-05 - val_loss: 0.6331\n",
      "Epoch 834/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.0429e-05 - val_loss: 0.6332\n",
      "Epoch 835/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 4.0319e-05 - val_loss: 0.6333\n",
      "Epoch 836/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.0208e-05 - val_loss: 0.6334\n",
      "Epoch 837/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 4.0101e-05 - val_loss: 0.6335\n",
      "Epoch 838/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.9984e-05 - val_loss: 0.6336\n",
      "Epoch 839/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.9881e-05 - val_loss: 0.6338\n",
      "Epoch 840/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.9777e-05 - val_loss: 0.6339\n",
      "Epoch 841/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.9675e-05 - val_loss: 0.6340\n",
      "Epoch 842/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.9579e-05 - val_loss: 0.6341\n",
      "Epoch 843/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.9480e-05 - val_loss: 0.6342\n",
      "Epoch 844/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.9383e-05 - val_loss: 0.6342\n",
      "Epoch 845/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.9278e-05 - val_loss: 0.6343\n",
      "Epoch 846/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.9182e-05 - val_loss: 0.6344\n",
      "Epoch 847/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.9082e-05 - val_loss: 0.6345\n",
      "Epoch 848/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.8986e-05 - val_loss: 0.6345\n",
      "Epoch 849/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.8879e-05 - val_loss: 0.6346\n",
      "Epoch 850/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.8754e-05 - val_loss: 0.6347\n",
      "Epoch 851/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.8648e-05 - val_loss: 0.6347\n",
      "Epoch 852/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.8520e-05 - val_loss: 0.6348\n",
      "Epoch 853/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.8413e-05 - val_loss: 0.6348\n",
      "Epoch 854/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.8307e-05 - val_loss: 0.6349\n",
      "Epoch 855/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.8206e-05 - val_loss: 0.6350\n",
      "Epoch 856/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.8109e-05 - val_loss: 0.6350\n",
      "Epoch 857/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.8008e-05 - val_loss: 0.6351\n",
      "Epoch 858/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.7908e-05 - val_loss: 0.6352\n",
      "Epoch 859/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.7811e-05 - val_loss: 0.6353\n",
      "Epoch 860/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.7711e-05 - val_loss: 0.6354\n",
      "Epoch 861/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.7610e-05 - val_loss: 0.6355\n",
      "Epoch 862/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.7514e-05 - val_loss: 0.6356\n",
      "Epoch 863/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.7420e-05 - val_loss: 0.6357\n",
      "Epoch 864/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.7329e-05 - val_loss: 0.6357\n",
      "Epoch 865/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.7235e-05 - val_loss: 0.6358\n",
      "Epoch 866/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.7142e-05 - val_loss: 0.6358\n",
      "Epoch 867/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.7051e-05 - val_loss: 0.6359\n",
      "Epoch 868/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.6961e-05 - val_loss: 0.6359\n",
      "Epoch 869/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.6869e-05 - val_loss: 0.6360\n",
      "Epoch 870/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.6779e-05 - val_loss: 0.6361\n",
      "Epoch 871/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.6691e-05 - val_loss: 0.6361\n",
      "Epoch 872/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.6605e-05 - val_loss: 0.6362\n",
      "Epoch 873/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.6520e-05 - val_loss: 0.6363\n",
      "Epoch 874/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.6428e-05 - val_loss: 0.6364\n",
      "Epoch 875/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.6336e-05 - val_loss: 0.6365\n",
      "Epoch 876/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.6246e-05 - val_loss: 0.6365\n",
      "Epoch 877/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 3.7405e-0 - 0s 5ms/step - loss: 3.6156e-05 - val_loss: 0.6366\n",
      "Epoch 878/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.6068e-05 - val_loss: 0.6367\n",
      "Epoch 879/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.5978e-05 - val_loss: 0.6368\n",
      "Epoch 880/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.5886e-05 - val_loss: 0.6369\n",
      "Epoch 881/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.5792e-05 - val_loss: 0.6370\n",
      "Epoch 882/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.5703e-05 - val_loss: 0.6371\n",
      "Epoch 883/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.5610e-05 - val_loss: 0.6372\n",
      "Epoch 884/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.5521e-05 - val_loss: 0.6373\n",
      "Epoch 885/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.5432e-05 - val_loss: 0.6374\n",
      "Epoch 886/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 3.4177e-0 - 0s 4ms/step - loss: 3.5340e-05 - val_loss: 0.6375\n",
      "Epoch 887/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.5245e-05 - val_loss: 0.6376\n",
      "Epoch 888/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.5153e-05 - val_loss: 0.6376\n",
      "Epoch 889/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.5062e-05 - val_loss: 0.6377\n",
      "Epoch 890/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.4976e-05 - val_loss: 0.6378\n",
      "Epoch 891/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.4892e-05 - val_loss: 0.6378\n",
      "Epoch 892/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.4807e-05 - val_loss: 0.6379\n",
      "Epoch 893/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.4727e-05 - val_loss: 0.6380\n",
      "Epoch 894/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.4642e-05 - val_loss: 0.6381\n",
      "Epoch 895/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.4558e-05 - val_loss: 0.6382\n",
      "Epoch 896/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.4474e-05 - val_loss: 0.6383\n",
      "Epoch 897/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.4384e-05 - val_loss: 0.6385\n",
      "Epoch 898/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.4300e-05 - val_loss: 0.6386\n",
      "Epoch 899/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.4211e-05 - val_loss: 0.6387\n",
      "Epoch 900/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.4122e-05 - val_loss: 0.6388\n",
      "Epoch 901/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.4032e-05 - val_loss: 0.6389\n",
      "Epoch 902/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.3933e-05 - val_loss: 0.6390\n",
      "Epoch 903/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.3830e-05 - val_loss: 0.6391\n",
      "Epoch 904/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.3735e-05 - val_loss: 0.6392\n",
      "Epoch 905/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.3646e-05 - val_loss: 0.6393\n",
      "Epoch 906/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.3559e-05 - val_loss: 0.6394\n",
      "Epoch 907/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.3465e-05 - val_loss: 0.6395\n",
      "Epoch 908/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.3374e-05 - val_loss: 0.6396\n",
      "Epoch 909/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.3285e-05 - val_loss: 0.6397\n",
      "Epoch 910/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.3202e-05 - val_loss: 0.6398\n",
      "Epoch 911/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.3118e-05 - val_loss: 0.6399\n",
      "Epoch 912/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.3030e-05 - val_loss: 0.6400\n",
      "Epoch 913/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.2944e-05 - val_loss: 0.6401\n",
      "Epoch 914/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.2862e-05 - val_loss: 0.6402\n",
      "Epoch 915/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.2779e-05 - val_loss: 0.6403\n",
      "Epoch 916/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.2702e-05 - val_loss: 0.6404\n",
      "Epoch 917/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.2625e-05 - val_loss: 0.6405\n",
      "Epoch 918/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.2548e-05 - val_loss: 0.6405\n",
      "Epoch 919/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.2471e-05 - val_loss: 0.6406\n",
      "Epoch 920/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.2397e-05 - val_loss: 0.6407\n",
      "Epoch 921/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.2323e-05 - val_loss: 0.6408\n",
      "Epoch 922/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.2248e-05 - val_loss: 0.6408\n",
      "Epoch 923/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.2174e-05 - val_loss: 0.6409\n",
      "Epoch 924/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.2102e-05 - val_loss: 0.6410\n",
      "Epoch 925/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.2029e-05 - val_loss: 0.6411\n",
      "Epoch 926/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.1958e-05 - val_loss: 0.6411\n",
      "Epoch 927/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.1887e-05 - val_loss: 0.6412\n",
      "Epoch 928/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.1815e-05 - val_loss: 0.6413\n",
      "Epoch 929/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.1741e-05 - val_loss: 0.6414\n",
      "Epoch 930/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.1668e-05 - val_loss: 0.6415\n",
      "Epoch 931/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.1595e-05 - val_loss: 0.6416\n",
      "Epoch 932/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.1517e-05 - val_loss: 0.6418\n",
      "Epoch 933/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.1431e-05 - val_loss: 0.6419\n",
      "Epoch 934/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.1340e-05 - val_loss: 0.6420\n",
      "Epoch 935/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.1261e-05 - val_loss: 0.6422\n",
      "Epoch 936/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.1183e-05 - val_loss: 0.6423\n",
      "Epoch 937/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.1103e-05 - val_loss: 0.6424\n",
      "Epoch 938/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.1025e-05 - val_loss: 0.6425\n",
      "Epoch 939/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.0948e-05 - val_loss: 0.6426\n",
      "Epoch 940/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.0875e-05 - val_loss: 0.6427\n",
      "Epoch 941/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.0802e-05 - val_loss: 0.6428\n",
      "Epoch 942/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.0728e-05 - val_loss: 0.6429\n",
      "Epoch 943/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.0656e-05 - val_loss: 0.6430\n",
      "Epoch 944/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.0582e-05 - val_loss: 0.6431\n",
      "Epoch 945/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.0506e-05 - val_loss: 0.6432\n",
      "Epoch 946/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.0432e-05 - val_loss: 0.6433\n",
      "Epoch 947/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.0354e-05 - val_loss: 0.6434\n",
      "Epoch 948/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.0275e-05 - val_loss: 0.6435\n",
      "Epoch 949/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.0201e-05 - val_loss: 0.6436\n",
      "Epoch 950/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.0124e-05 - val_loss: 0.6437\n",
      "Epoch 951/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.0049e-05 - val_loss: 0.6438\n",
      "Epoch 952/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.9976e-05 - val_loss: 0.6438\n",
      "Epoch 953/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.9899e-05 - val_loss: 0.6439\n",
      "Epoch 954/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.9816e-05 - val_loss: 0.6439\n",
      "Epoch 955/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.9734e-05 - val_loss: 0.6440\n",
      "Epoch 956/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.9657e-05 - val_loss: 0.6440\n",
      "Epoch 957/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.9581e-05 - val_loss: 0.6441\n",
      "Epoch 958/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.9505e-05 - val_loss: 0.6442\n",
      "Epoch 959/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.9435e-05 - val_loss: 0.6442\n",
      "Epoch 960/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.9364e-05 - val_loss: 0.6443\n",
      "Epoch 961/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.9294e-05 - val_loss: 0.6443\n",
      "Epoch 962/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.9223e-05 - val_loss: 0.6444\n",
      "Epoch 963/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.9156e-05 - val_loss: 0.6445\n",
      "Epoch 964/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.9089e-05 - val_loss: 0.6446\n",
      "Epoch 965/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.9019e-05 - val_loss: 0.6446\n",
      "Epoch 966/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.8946e-05 - val_loss: 0.6447\n",
      "Epoch 967/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.8873e-05 - val_loss: 0.6448\n",
      "Epoch 968/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.8801e-05 - val_loss: 0.6449\n",
      "Epoch 969/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.8732e-05 - val_loss: 0.6450\n",
      "Epoch 970/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.8661e-05 - val_loss: 0.6450\n",
      "Epoch 971/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.8590e-05 - val_loss: 0.6451\n",
      "Epoch 972/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 2.8516e-05 - val_loss: 0.6452\n",
      "Epoch 973/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.8447e-05 - val_loss: 0.6452\n",
      "Epoch 974/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.8381e-05 - val_loss: 0.6453\n",
      "Epoch 975/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.8315e-05 - val_loss: 0.6454\n",
      "Epoch 976/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.8247e-05 - val_loss: 0.6454\n",
      "Epoch 977/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.8183e-05 - val_loss: 0.6455\n",
      "Epoch 978/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.8118e-05 - val_loss: 0.6456\n",
      "Epoch 979/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.8050e-05 - val_loss: 0.6457\n",
      "Epoch 980/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7983e-05 - val_loss: 0.6458\n",
      "Epoch 981/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7916e-05 - val_loss: 0.6459\n",
      "Epoch 982/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7851e-05 - val_loss: 0.6459\n",
      "Epoch 983/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7785e-05 - val_loss: 0.6460\n",
      "Epoch 984/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7717e-05 - val_loss: 0.6461\n",
      "Epoch 985/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7652e-05 - val_loss: 0.6462\n",
      "Epoch 986/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7587e-05 - val_loss: 0.6463\n",
      "Epoch 987/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7522e-05 - val_loss: 0.6464\n",
      "Epoch 988/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7458e-05 - val_loss: 0.6465\n",
      "Epoch 989/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7394e-05 - val_loss: 0.6466\n",
      "Epoch 990/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7333e-05 - val_loss: 0.6467\n",
      "Epoch 991/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7272e-05 - val_loss: 0.6468\n",
      "Epoch 992/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7207e-05 - val_loss: 0.6468\n",
      "Epoch 993/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7143e-05 - val_loss: 0.6469\n",
      "Epoch 994/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7079e-05 - val_loss: 0.6470\n",
      "Epoch 995/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.7016e-05 - val_loss: 0.6471\n",
      "Epoch 996/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.6949e-05 - val_loss: 0.6471\n",
      "Epoch 997/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.6882e-05 - val_loss: 0.6472\n",
      "Epoch 998/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.6813e-05 - val_loss: 0.6473\n",
      "Epoch 999/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.6746e-05 - val_loss: 0.6474\n",
      "Epoch 1000/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.6683e-05 - val_loss: 0.6474\n",
      "Wall time: 16.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(30, activation = 'relu', input_shape = (1000,)))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam')\n",
    "\n",
    "history = model.fit(char_Z_train, char_y_train, validation_data = (char_Z_test, char_y_test), batch_size = 512, \n",
    "                   epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eab6b40b-b459-41e3-b7e5-6c022d9afff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history['loss'], c='g');      # green - training loss # Loss\n",
    "plt.plot(history.epoch, history.history['val_loss'], c='b');  # blue - test loss # Val loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7ecfd-0d99-4509-8156-6e860112be9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c96bf29-2d47-481a-89fd-b0546c183932",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#credit to: lesson 7.6\n",
    "def model_func(layers, loss_fn = 'binary_crossentropy'):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    flag_first = True\n",
    "    \n",
    "    for layer in layers:\n",
    "        if flag_first:\n",
    "            model.add(Dense(layer, activation = 'relu', input_shape = (14258,)))\n",
    "            flag_first = False\n",
    "        else:\n",
    "            model.add(Dense(layer, activation = 'relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(loss = loss_fn, optimizer = 'adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "nn = KerasClassifier(build_fn = model, batch_size = 512, epochs = 20, verbose = 0)\n",
    "\n",
    "params = {'batch_size': [126, 512],\n",
    "          'epochs': [10, 15, 20]\n",
    "         }\n",
    "\n",
    "grid = GridSearchCV(nn, params, cv = 3, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8953eb9-b97b-442a-9e9b-9fa8306fa3c9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sc = StandardScaler()\n",
    "Xs_train = sc.fit_transform(X_train)\n",
    "grid.fit(Xs_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
