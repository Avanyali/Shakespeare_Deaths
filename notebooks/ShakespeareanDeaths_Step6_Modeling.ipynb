{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8454501-c447-41cc-9036-ec37c392b79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "from skopt import BayesSearchCV\n",
    "from scipy.stats import uniform, loguniform, randint\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "562c2faa-c261-4e36-b5ad-c11bcda49a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_df = pd.read_csv('../data/csv/ShakespeareCharacterLines_engineered.csv', index_col = ['play', 'name', 'line_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6e48589-cca3-4932-9675-edc7607d804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_df = pd.read_csv('../data/csv/ShakespeareCharacterLines_character_corpus.csv', index_col = ['play', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97aeff29-f0eb-4794-8088-0eb327b78ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colon = slice(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02cd3b99-e00c-4efd-b3a5-f07bfd28f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = list(line_df.columns[:10])\n",
    "to_drop.remove('character_dies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cb47dd7-66e7-463e-9502-cc57bb111be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = line_df.drop(columns = to_drop).copy()\n",
    "df = char_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87ce8dc5-62a3-4690-8360-597710398b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = df.columns.tolist()\n",
    "x_list.remove('character_dies')\n",
    "X = df[x_list]\n",
    "y = df['character_dies']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, stratify = y)\n",
    "\n",
    "sc = StandardScaler()\n",
    "Xs_train = sc.fit_transform(X_train)\n",
    "Xs_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c111bfdc-d09b-4297-b7cf-7d9f4151d75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93071902"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "900b38b6-0b05-41d2-b004-038546b2c5b7",
   "metadata": {},
   "source": [
    "- Baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3fe9a23-266c-4caf-b9cd-fc454f38e741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.905958\n",
       "1.0    0.094042\n",
       "Name: character_dies, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['character_dies'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "759055c6-8783-429c-8d07-a660bbbd4f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipe = Pipeline([\n",
    "    ('sc', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(random_state = 42, solver = 'liblinear', penalty = 'l1'))\n",
    "])\n",
    "\n",
    "logreg_params = {\n",
    "    'logreg__tol': uniform(0, .1),\n",
    "    'logreg__C': loguniform(0.0001, 100),\n",
    "    'logreg__class_weight': Categorical(['balanced', None]),\n",
    "    'logreg__max_iter': randint(1, 1000),\n",
    "    'logreg__l1_ratio': uniform(0, 1)\n",
    "}\n",
    "\n",
    "logreg_rs_rocauc = RandomizedSearchCV(estimator = logreg_pipe,\n",
    "                     param_distributions = logreg_params,\n",
    "                     scoring = 'roc_auc',\n",
    "                     n_iter = 50,\n",
    "                     n_jobs = 8,\n",
    "                     cv = 5,\n",
    "                     refit = True,\n",
    "                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7af6435-d7a0-460c-ad13-a05762d316f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1317: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\"l1_ratio parameter is only used when penalty is \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('sc', StandardScaler()),\n",
       "                                             ('logreg',\n",
       "                                              LogisticRegression(penalty='l1',\n",
       "                                                                 random_state=42,\n",
       "                                                                 solver='liblinear'))]),\n",
       "                   n_iter=50, n_jobs=8,\n",
       "                   param_distributions={'logreg__C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002B2C298A340>,\n",
       "                                        'logreg__class_weight': Categorical(categories=('balanced', None), prior=None),\n",
       "                                        'logreg__l1_ratio': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002B2C298A940>,\n",
       "                                        'logreg__max_iter': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002B1A806BC10>,\n",
       "                                        'logreg__tol': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002B431029D30>},\n",
       "                   random_state=42, scoring='roc_auc')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logreg_rs_rocauc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d9111f9-109a-4795-936f-21be10fdbf29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7990356819260473, 0.7135596471039509)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds = logreg_rs_rocauc.best_estimator_['logreg'].predict(Xs_train)\n",
    "test_preds = logreg_rs_rocauc.best_estimator_['logreg'].predict(Xs_test)\n",
    "\n",
    "metrics.roc_auc_score(y_train, train_preds), metrics.roc_auc_score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f975d17-0d4e-40f4-af85-bd48f0d9be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {key: value for key, value in zip(x_list, logreg_rs_rocauc.best_estimator_['logreg'].coef_[0])}\n",
    "weights = {k: v for k, v in sorted(weights.items(), key=lambda item: item[1], reverse = True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7685e6c2-8fa6-40b0-a71b-9cdc26f2138b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'death_std': 0.12850891631837966,\n",
       " 'unwelcome_person_hyp_std': 0.07553806786164316,\n",
       " 'neg_sentiment_std': 0.06891258369021096,\n",
       " 'ah_std': 0.056450769581478766,\n",
       " 'INTJ_std': 0.05121047413502336,\n",
       " 'life_std': 0.050121440951676435,\n",
       " 'denmark_syn_std': 0.043529132855568815,\n",
       " 'word_std': 0.03470232159352246,\n",
       " 'brow_std': 0.03214397083347529,\n",
       " 'revenge_std': 0.031231511595154398,\n",
       " 'mean_std': 0.025622324887338583,\n",
       " 'eunuch_std': 0.02516520401919758,\n",
       " 'win_hyp_std': 0.02442470233452667,\n",
       " 'tragedy_std': 0.023730703162129035,\n",
       " 'son_std': 0.018765378625682883,\n",
       " 'abused_std': 0.018638307656687742,\n",
       " 'murder_std': 0.017986973946210252,\n",
       " 'being_hyp_std': 0.017760066284526407,\n",
       " 'express_emotion_hyp_std': 0.01693803887373723,\n",
       " 'villain_std': 0.01620860183951193,\n",
       " 'dig_mean': 0.01565939980957762,\n",
       " 'misconstrue_std': 0.014996624343505533,\n",
       " 'unadvise_std': 0.0139210492888509,\n",
       " 'undergo_hyp_mean': 0.01389503467035266,\n",
       " 'standing_hyp_std': 0.01384963142253865,\n",
       " 'writer_hyp_std': 0.012609478055652306,\n",
       " 'generous_syn_mean': 0.012414977313907815,\n",
       " 'mercy_mean': 0.011665378676693849,\n",
       " 'speech_hyp_std': 0.010519193911523742,\n",
       " 'notion_std': 0.010414150612854165,\n",
       " 'ocean_mean': 0.010351901785469417,\n",
       " 'monstrous_std': 0.00991275077872521,\n",
       " 'resign_std': 0.009778219591424678,\n",
       " 'empress_std': 0.00972683896352509,\n",
       " 'propriety_hyp_mean': 0.009394810661804575,\n",
       " 'male_offspring_hyp_std': 0.00930592326600961,\n",
       " 'misconstrue_mean': 0.008740963224318889,\n",
       " 'abominable_syn_mean': 0.00872279329627119,\n",
       " 'emotional_state_hyp_median': 0.008067133779997572,\n",
       " 'clasp_mean': 0.007604044065669856,\n",
       " 'wren_syn_mean': 0.007219202249399632,\n",
       " 'isis_std': 0.00716701257979676,\n",
       " 'encourage_hyp_std': 0.006563417624869842,\n",
       " 'rear_mean': 0.006238586651102999,\n",
       " 'unlucky_syn_std': 0.00596390144811855,\n",
       " 'sword_hyp_std': 0.005918848067797021,\n",
       " 'unretentive_syn_mean': 0.005665153431394587,\n",
       " 'shame_std': 0.005477572223973472,\n",
       " 'dig_std': 0.005269370250317761,\n",
       " 'emmanuel_mean': 0.0050243632746884296,\n",
       " 'icy_std': 0.004983923640854737,\n",
       " 'emperor_hyp_std': 0.004604224822579152,\n",
       " 'smart_std': 0.004396280802260256,\n",
       " 'ordinance_std': 0.004177082997467539,\n",
       " 'cumberland_syn_std': 0.0038374983625878278,\n",
       " 'torment_std': 0.003765439417446982,\n",
       " 'meanly_syn_std': 0.003645591701958303,\n",
       " 'isis_syn_mean': 0.003575992599690386,\n",
       " 'average_hyp_std': 0.0031717795662670506,\n",
       " 'continent_std': 0.0029430959407884183,\n",
       " 'ill-advised_syn_mean': 0.0028469247841047133,\n",
       " 'ague_std': 0.0024099862384140856,\n",
       " 'forgetful_std': 0.0023471887532418374,\n",
       " 'emmanuel_std': 0.0021538910364870367,\n",
       " 'containerful_hyp_mean': 0.0020341738554660845,\n",
       " 'denmark_std': 0.0017435425918495644,\n",
       " 'writer_hyp_mean': 0.0016664319310035088,\n",
       " 'fashion_hyp_std': 0.0016499316493485024,\n",
       " 'successively_syn_std': 0.0015259395480669144,\n",
       " 'domitius_std': 0.0012998949090873065,\n",
       " 'landmass_hyp_std': 0.001266675883156371,\n",
       " 'cask_mean': 0.0012136894211016707,\n",
       " 'hateful_mean': 0.0012041107503588408,\n",
       " 'enfold_std': 0.0011013045703498993,\n",
       " 'emmanuel_median': 0.0010487389288927822,\n",
       " 'player_mean': 0.0006283775266239158,\n",
       " 'keep_hyp_std': 0.0006127891092368838,\n",
       " 'disinherit_std': 0.0005337439460037092,\n",
       " 'notion_mean': 0.00043618566867923374,\n",
       " 'unadvise_mean': 0.000360342406048862,\n",
       " 'retentive_syn_mean': 0.0003365369829926648,\n",
       " 'unretentive_syn_std': 0.0002456603278214552,\n",
       " 'blanch_mean': 7.644357263377127e-05,\n",
       " 'happiness_median': 4.557306924682176e-05,\n",
       " 'isis_mean': 2.3189402889489946e-05,\n",
       " 'pos_sentiment_mean': 0.0,\n",
       " 'neg_sentiment_mean': 0.0,\n",
       " 'neu_sentiment_mean': 0.0,\n",
       " 'compound_sentiment_mean': 0.0,\n",
       " 'endowment_hyp_mean': 0.0,\n",
       " 'hang_mean': 0.0,\n",
       " 'VERB_mean': 0.0,\n",
       " 'character_name_mean': 0.0,\n",
       " 'PROPN_mean': 0.0,\n",
       " 'shall_mean': 0.0,\n",
       " 'attempt_hyp_mean': 0.0,\n",
       " 'good_mean': 0.0,\n",
       " 'ADJ_mean': 0.0,\n",
       " 'by_and_large_syn_mean': 0.0,\n",
       " 'generally_mean': 0.0,\n",
       " 'ADV_mean': 0.0,\n",
       " 'match_hyp_mean': 0.0,\n",
       " 'accord_mean': 0.0,\n",
       " 'security_hyp_mean': 0.0,\n",
       " 'scrip_mean': 0.0,\n",
       " 'advantage_hyp_mean': 0.0,\n",
       " 'dramatic_composition_hyp_mean': 0.0,\n",
       " 'play_mean': 0.0,\n",
       " 'NOUN_mean': 0.0,\n",
       " 'nutriment_hyp_mean': 0.0,\n",
       " 'treat_mean': 0.0,\n",
       " 'publication_hyp_mean': 0.0,\n",
       " 'read_mean': 0.0,\n",
       " 'defamation_hyp_mean': 0.0,\n",
       " 'name_mean': 0.0,\n",
       " 'performer_hyp_mean': 0.0,\n",
       " 'actor_mean': 0.0,\n",
       " 'change_hyp_mean': 0.0,\n",
       " 'grow_mean': 0.0,\n",
       " 'component_hyp_mean': 0.0,\n",
       " 'point_mean': 0.0,\n",
       " 'part_hyp_mean': 0.0,\n",
       " 'piece_mean': 0.0,\n",
       " 'activity_hyp_mean': 0.0,\n",
       " 'work_mean': 0.0,\n",
       " 'guarantee_syn_mean': 0.0,\n",
       " 'assure_mean': 0.0,\n",
       " 'gay_syn_mean': 0.0,\n",
       " 'merry_mean': 0.0,\n",
       " 'forth_syn_mean': 0.0,\n",
       " 'forth_mean': 0.0,\n",
       " 'round_shape_hyp_mean': 0.0,\n",
       " 'scroll_mean': 0.0,\n",
       " 'masters_syn_mean': 0.0,\n",
       " 'masters_mean': 0.0,\n",
       " 'change_of_location_hyp_mean': 0.0,\n",
       " 'spread_mean': 0.0,\n",
       " 'readiness_hyp_mean': 0.0,\n",
       " 'ready_mean': 0.0,\n",
       " 'talk_hyp_mean': 0.0,\n",
       " 'proceed_mean': 0.0,\n",
       " 'pyramus_mean': 0.0,\n",
       " 'person_hyp_mean': 0.0,\n",
       " 'lover_mean': 0.0,\n",
       " 'dictator_hyp_mean': 0.0,\n",
       " 'tyrant_mean': 0.0,\n",
       " 'communicate_hyp_mean': 0.0,\n",
       " 'ask_mean': 0.0,\n",
       " 'bodily_process_hyp_mean': 0.0,\n",
       " 'tear_mean': 0.0,\n",
       " 'alignment_hyp_mean': 0.0,\n",
       " 'true_mean': 0.0,\n",
       " 'performing_mean': 0.0,\n",
       " 'lashkar-e-taiba_syn_mean': 0.0,\n",
       " 'let_mean': 0.0,\n",
       " 'gathering_hyp_mean': 0.0,\n",
       " 'audience_mean': 0.0,\n",
       " 'countenance_hyp_mean': 0.0,\n",
       " 'look_mean': 0.0,\n",
       " 'opinion_hyp_mean': 0.0,\n",
       " 'eye_mean': 0.0,\n",
       " 'atmospheric_phenomenon_hyp_mean': 0.0,\n",
       " 'storm_mean': 0.0,\n",
       " 'commiserate_hyp_mean': 0.0,\n",
       " 'condole_mean': 0.0,\n",
       " 'maneuver_hyp_mean': 0.0,\n",
       " 'measure_mean': 0.0,\n",
       " 'rest_mean': 0.0,\n",
       " 'leader_hyp_mean': 0.0,\n",
       " 'chief_mean': 0.0,\n",
       " 'message_hyp_mean': 0.0,\n",
       " 'humor_mean': 0.0,\n",
       " 'ercles_mean': 0.0,\n",
       " 'rarely_syn_mean': 0.0,\n",
       " 'rarely_mean': 0.0,\n",
       " 'drop_hyp_mean': 0.0,\n",
       " 'feline_hyp_mean': 0.0,\n",
       " 'cat_mean': 0.0,\n",
       " 'acrobatic_stunt_hyp_mean': 0.0,\n",
       " 'split_mean': 0.0,\n",
       " 'act_hyp_mean': 0.0,\n",
       " 'rage_mean': 0.0,\n",
       " 'natural_object_hyp_mean': 0.0,\n",
       " 'rock_mean': 0.0,\n",
       " 'symptom_hyp_mean': 0.0,\n",
       " 'shivering_mean': 0.0,\n",
       " 'stupefaction_hyp_mean': 0.0,\n",
       " 'shock_mean': 0.0,\n",
       " 'happening_hyp_mean': 0.0,\n",
       " 'break_mean': 0.0,\n",
       " 'fastener_hyp_mean': 0.0,\n",
       " 'lock_mean': 0.0,\n",
       " 'correctional_institution_hyp_mean': 0.0,\n",
       " 'prison_mean': 0.0,\n",
       " 'movable_barrier_hyp_mean': 0.0,\n",
       " 'gate_mean': 0.0,\n",
       " 'phibbus_mean': 0.0,\n",
       " 'motor_vehicle_hyp_mean': 0.0,\n",
       " 'car_mean': 0.0,\n",
       " 'brightness_hyp_mean': 0.0,\n",
       " 'shine_mean': 0.0,\n",
       " 'army_for_the_liberation_of_rwanda_syn_mean': 0.0,\n",
       " 'far_mean': 0.0,\n",
       " 'gregorian_calendar_month_hyp_mean': 0.0,\n",
       " 'mar_mean': 0.0,\n",
       " 'foolish_syn_mean': 0.0,\n",
       " 'foolish_mean': 0.0,\n",
       " 'fate_mean': 0.0,\n",
       " 'exalted_syn_mean': 0.0,\n",
       " 'lofty_mean': 0.0,\n",
       " 'contestant_hyp_mean': 0.0,\n",
       " 'blood_vessel_hyp_mean': 0.0,\n",
       " 'vein_mean': 0.0,\n",
       " 'condoling_mean': 0.0,\n",
       " 'animal_skin_hyp_mean': 0.0,\n",
       " 'hide_mean': 0.0,\n",
       " 'external_body_part_hyp_mean': 0.0,\n",
       " 'face_mean': 0.0,\n",
       " 'thisbe_mean': 0.0,\n",
       " 'speak_mean': 0.0,\n",
       " 'monstrous_syn_mean': 0.0,\n",
       " 'monstrous_mean': 0.0,\n",
       " 'small_indefinite_quantity_hyp_mean': 0.0,\n",
       " 'little_mean': 0.0,\n",
       " 'sound_hyp_mean': 0.0,\n",
       " 'voice_mean': 0.0,\n",
       " 'thisne_mean': 0.0,\n",
       " 'ah_mean': 0.0,\n",
       " 'INTJ_mean': 0.0,\n",
       " 'lover_hyp_mean': 0.0,\n",
       " 'dear_mean': 0.0,\n",
       " 'big_cat_hyp_mean': 0.0,\n",
       " 'lion_mean': 0.0,\n",
       " 'noise_hyp_mean': 0.0,\n",
       " 'roar_mean': 0.0,\n",
       " 'intuition_hyp_mean': 0.0,\n",
       " 'heart_mean': 0.0,\n",
       " 'perceive_hyp_mean': 0.0,\n",
       " 'hear_mean': 0.0,\n",
       " 'aid_hyp_mean': 0.0,\n",
       " 'grant_mean': 0.0,\n",
       " 'friend_mean': 0.0,\n",
       " 'emotion_hyp_mean': 0.0,\n",
       " 'fright_mean': 0.0,\n",
       " 'intelligence_hyp_mean': 0.0,\n",
       " 'wit_mean': 0.0,\n",
       " 'liberty_hyp_mean': 0.0,\n",
       " 'discretion_mean': 0.0,\n",
       " 'aggravate_mean': 0.0,\n",
       " 'gently_syn_mean': 0.0,\n",
       " 'gently_mean': 0.0,\n",
       " 'consumption_hyp_mean': 0.0,\n",
       " 'sucking_mean': 0.0,\n",
       " 'pigeon_hyp_mean': 0.0,\n",
       " 'dove_mean': 0.0,\n",
       " 'thrush_hyp_mean': 0.0,\n",
       " 'nightingale_mean': 0.0,\n",
       " 'initiate_hyp_mean': 0.0,\n",
       " 'undertake_mean': 0.0,\n",
       " 'facial_hair_hyp_mean': 0.0,\n",
       " 'beard_mean': 0.0,\n",
       " 'discharge_mean': 0.0,\n",
       " 'plant_fiber_hyp_mean': 0.0,\n",
       " 'straw_mean': 0.0,\n",
       " 'visual_property_hyp_mean': 0.0,\n",
       " 'color_mean': 0.0,\n",
       " 'citrus_hyp_mean': 0.0,\n",
       " 'orange_mean': 0.0,\n",
       " 'tawny_syn_mean': 0.0,\n",
       " 'tawny_mean': 0.0,\n",
       " 'chromatic_color_hyp_mean': 0.0,\n",
       " 'purple_mean': 0.0,\n",
       " 'atom_hyp_mean': 0.0,\n",
       " 'grain_mean': 0.0,\n",
       " 'romance_hyp_mean': 0.0,\n",
       " 'french_mean': 0.0,\n",
       " 'symbol_hyp_mean': 0.0,\n",
       " 'crown_mean': 0.0,\n",
       " 'perfit_mean': 0.0,\n",
       " 'yellow_mean': 0.0,\n",
       " 'athletic_contest_hyp_mean': 0.0,\n",
       " 'meet_mean': 0.0,\n",
       " 'perform_hyp_mean': 0.0,\n",
       " 'rehearse_mean': 0.0,\n",
       " 'obscenely_syn_mean': 0.0,\n",
       " 'obscenely_mean': 0.0,\n",
       " 'bravely_syn_mean': 0.0,\n",
       " 'courageously_mean': 0.0,\n",
       " 'pain_mean': 0.0,\n",
       " 'farewell_hyp_mean': 0.0,\n",
       " 'adieu_mean': 0.0,\n",
       " 'grasping_hyp_mean': 0.0,\n",
       " 'hold_mean': 0.0,\n",
       " 'share_hyp_mean': 0.0,\n",
       " 'cut_mean': 0.0,\n",
       " 'cord_hyp_mean': 0.0,\n",
       " 'bowstring_mean': 0.0,\n",
       " 'property_hyp_mean': 0.0,\n",
       " 'thing_mean': 0.0,\n",
       " 'drama_hyp_mean': 0.0,\n",
       " 'comedy_mean': 0.0,\n",
       " 'gully_hyp_mean': 0.0,\n",
       " 'draw_mean': 0.0,\n",
       " 'weapon_hyp_mean': 0.0,\n",
       " 'sword_mean': 0.0,\n",
       " 'termination_hyp_mean': 0.0,\n",
       " 'kill_mean': 0.0,\n",
       " 'stay_hyp_mean': 0.0,\n",
       " 'abide_mean': 0.0,\n",
       " 'statement_hyp_mean': 0.0,\n",
       " 'answer_mean': 0.0,\n",
       " 'whit_mean': 0.0,\n",
       " 'instrumentality_hyp_mean': 0.0,\n",
       " 'device_mean': 0.0,\n",
       " 'create_verbally_hyp_mean': 0.0,\n",
       " 'write_mean': 0.0,\n",
       " 'ill_health_hyp_mean': 0.0,\n",
       " 'harm_mean': 0.0,\n",
       " 'good_hyp_mean': 0.0,\n",
       " 'well_mean': 0.0,\n",
       " 'certainty_hyp_mean': 0.0,\n",
       " 'assurance_mean': 0.0,\n",
       " 'tell_syn_mean': 0.0,\n",
       " 'tell_mean': 0.0,\n",
       " 'craftsman_hyp_mean': 0.0,\n",
       " 'weaver_mean': 0.0,\n",
       " 'fear_mean': 0.0,\n",
       " 'artist_hyp_mean': 0.0,\n",
       " 'master_mean': 0.0,\n",
       " 'ought_mean': 0.0,\n",
       " 'think_hyp_mean': 0.0,\n",
       " 'consider_mean': 0.0,\n",
       " 'transport_hyp_mean': 0.0,\n",
       " 'bring_mean': 0.0,\n",
       " 'god_syn_mean': 0.0,\n",
       " 'god_mean': 0.0,\n",
       " 'protective_covering_hyp_mean': 0.0,\n",
       " 'shield_mean': 0.0,\n",
       " 'awful_syn_mean': 0.0,\n",
       " 'dreadful_mean': 0.0,\n",
       " 'situation_hyp_mean': 0.0,\n",
       " 'fearful_syn_mean': 0.0,\n",
       " 'fearful_mean': 0.0,\n",
       " 'bird_hyp_mean': 0.0,\n",
       " 'wildfowl_mean': 0.0,\n",
       " 'experience_hyp_mean': 0.0,\n",
       " 'living_mean': 0.0,\n",
       " 'negative_hyp_mean': 0.0,\n",
       " 'nay_mean': 0.0,\n",
       " 'common_fraction_hyp_mean': 0.0,\n",
       " 'half_mean': 0.0,\n",
       " 'DET_mean': 0.0,\n",
       " 'see_mean': 0.0,\n",
       " 'neck_mean': 0.0,\n",
       " 'speech_hyp_mean': 0.0,\n",
       " 'say_mean': 0.0,\n",
       " 'imperfection_hyp_mean': 0.0,\n",
       " 'defect_mean': 0.0,\n",
       " 'show_hyp_mean': 0.0,\n",
       " 'fair_mean': 0.0,\n",
       " 'desire_hyp_mean': 0.0,\n",
       " 'wish_mean': 0.0,\n",
       " 'request_mean': 0.0,\n",
       " 'plead_hyp_mean': 0.0,\n",
       " 'entreat_mean': 0.0,\n",
       " 'reflex_hyp_mean': 0.0,\n",
       " 'tremble_mean': 0.0,\n",
       " 'being_hyp_mean': 0.0,\n",
       " 'life_mean': 0.0,\n",
       " 'deliberation_hyp_mean': 0.0,\n",
       " 'think_mean': 0.0,\n",
       " 'liquid_body_substance_hyp_mean': 0.0,\n",
       " 'come_mean': 0.0,\n",
       " 'here_syn_mean': 0.0,\n",
       " 'hither_mean': 0.0,\n",
       " 'sympathy_hyp_mean': 0.0,\n",
       " 'pity_mean': 0.0,\n",
       " 'force_hyp_mean': 0.0,\n",
       " 'man_mean': 0.0,\n",
       " 'obviously_syn_mean': 0.0,\n",
       " 'plainly_mean': 0.0,\n",
       " 'member_hyp_mean': 0.0,\n",
       " 'joiner_mean': 0.0,\n",
       " 'arrangement_hyp_mean': 0.0,\n",
       " 'calendar_mean': 0.0,\n",
       " 'annual_hyp_mean': 0.0,\n",
       " 'almanac_mean': 0.0,\n",
       " 'insight_hyp_mean': 0.0,\n",
       " 'find_mean': 0.0,\n",
       " 'light_hyp_mean': 0.0,\n",
       " 'moonshine_mean': 0.0,\n",
       " 'time_off_hyp_mean': 0.0,\n",
       " 'leave_mean': 0.0,\n",
       " 'sash_hyp_mean': 0.0,\n",
       " 'casement_mean': 0.0,\n",
       " 'achiever_hyp_mean': 0.0,\n",
       " 'great_mean': 0.0,\n",
       " 'enclosure_hyp_mean': 0.0,\n",
       " 'chamber_mean': 0.0,\n",
       " 'framework_hyp_mean': 0.0,\n",
       " 'window_mean': 0.0,\n",
       " 'area_hyp_mean': 0.0,\n",
       " 'open_mean': 0.0,\n",
       " 'moon_syn_mean': 0.0,\n",
       " 'moon_mean': 0.0,\n",
       " 'time_hyp_mean': 0.0,\n",
       " 'present_mean': 0.0,\n",
       " 'partition_hyp_mean': 0.0,\n",
       " 'wall_mean': 0.0,\n",
       " 'covering_material_hyp_mean': 0.0,\n",
       " 'plaster_mean': 0.0,\n",
       " 'soil_hyp_mean': 0.0,\n",
       " 'loam_mean': 0.0,\n",
       " 'plaster_hyp_mean': 0.0,\n",
       " 'roughcast_mean': 0.0,\n",
       " 'mean_syn_mean': 0.0,\n",
       " 'signify_mean': 0.0,\n",
       " 'digit_hyp_mean': 0.0,\n",
       " 'finger_mean': 0.0,\n",
       " 'depression_hyp_mean': 0.0,\n",
       " 'cranny_mean': 0.0,\n",
       " 'speaking_hyp_mean': 0.0,\n",
       " 'whisper_mean': 0.0,\n",
       " 'angiosperm_hyp_mean': 0.0,\n",
       " 'flower_mean': 0.0,\n",
       " 'odious_mean': 0.0,\n",
       " 'taste_hyp_mean': 0.0,\n",
       " 'savor_mean': 0.0,\n",
       " 'sweet_syn_mean': 0.0,\n",
       " 'sweet_mean': 0.0,\n",
       " 'odor_mean': 0.0,\n",
       " 'breath_mean': 0.0,\n",
       " 'listen_hyp_mean': 0.0,\n",
       " 'hark_mean': 0.0,\n",
       " 'stay_mean': 0.0,\n",
       " 'awhile_syn_mean': 0.0,\n",
       " 'awhile_mean': 0.0,\n",
       " 'be_hyp_mean': 0.0,\n",
       " 'appear_mean': 0.0,\n",
       " 'score_hyp_mean': 0.0,\n",
       " 'run_mean': 0.0,\n",
       " 'away_syn_mean': 0.0,\n",
       " 'away_mean': 0.0,\n",
       " 'wrongdoing_hyp_mean': 0.0,\n",
       " 'knavery_mean': 0.0,\n",
       " 'afeard_syn_mean': 0.0,\n",
       " 'afeard_mean': 0.0,\n",
       " 'body_part_hyp_mean': 0.0,\n",
       " 'ass_mean': 0.0,\n",
       " 'head_mean': 0.0,\n",
       " 'disturbance_hyp_mean': 0.0,\n",
       " 'stir_mean': 0.0,\n",
       " 'point_hyp_mean': 0.0,\n",
       " 'place_mean': 0.0,\n",
       " 'locomotion_hyp_mean': 0.0,\n",
       " 'walk_mean': 0.0,\n",
       " 'interpret_hyp_mean': 0.0,\n",
       " 'sing_mean': 0.0,\n",
       " 'afraid_syn_mean': 0.0,\n",
       " 'afraid_mean': 0.0,\n",
       " 'ouzel_mean': 0.0,\n",
       " 'penis_hyp_mean': 0.0,\n",
       " 'cock_mean': 0.0,\n",
       " 'achromatic_color_hyp_mean': 0.0,\n",
       " 'black_mean': 0.0,\n",
       " 'color_property_hyp_mean': 0.0,\n",
       " 'hue_mean': 0.0,\n",
       " 'legal_document_hyp_mean': 0.0,\n",
       " 'bill_mean': 0.0,\n",
       " 'spinning_machine_hyp_mean': 0.0,\n",
       " 'throstle_mean': 0.0,\n",
       " 'written_record_hyp_mean': 0.0,\n",
       " 'note_mean': 0.0,\n",
       " 'wren_mean': 0.0,\n",
       " 'pen_hyp_mean': 0.0,\n",
       " 'quill_mean': 0.0,\n",
       " 'oscine_hyp_mean': 0.0,\n",
       " 'finch_mean': 0.0,\n",
       " 'passerine_hyp_mean': 0.0,\n",
       " 'sparrow_mean': 0.0,\n",
       " 'new_world_oriole_hyp_mean': 0.0,\n",
       " 'lark_mean': 0.0,\n",
       " 'chant_hyp_mean': 0.0,\n",
       " 'plainsong_mean': 0.0,\n",
       " 'fool_hyp_mean': 0.0,\n",
       " 'cuckoo_mean': 0.0,\n",
       " 'gray_mean': 0.0,\n",
       " 'evaluation_hyp_mean': 0.0,\n",
       " 'mark_mean': 0.0,\n",
       " 'challenge_hyp_mean': 0.0,\n",
       " 'dare_mean': 0.0,\n",
       " 'collection_hyp_mean': 0.0,\n",
       " 'set_mean': 0.0,\n",
       " 'vertebrate_hyp_mean': 0.0,\n",
       " 'bird_mean': 0.0,\n",
       " 'falsehood_hyp_mean': 0.0,\n",
       " 'lie_mean': 0.0,\n",
       " 'utterance_hyp_mean': 0.0,\n",
       " 'cry_mean': 0.0,\n",
       " 'mistress_mean': 0.0,\n",
       " 'rational_motive_hyp_mean': 0.0,\n",
       " 'reason_mean': 0.0,\n",
       " 'fact_hyp_mean': 0.0,\n",
       " 'truth_mean': 0.0,\n",
       " 'love_mean': 0.0,\n",
       " 'institution_hyp_mean': 0.0,\n",
       " 'company_mean': 0.0,\n",
       " 'nowadays_mean': 0.0,\n",
       " 'honest_syn_mean': 0.0,\n",
       " 'honest_mean': 0.0,\n",
       " 'neighbor_mean': 0.0,\n",
       " 'disrespect_hyp_mean': 0.0,\n",
       " 'insult_mean': 0.0,\n",
       " 'occasion_mean': 0.0,\n",
       " 'plant_material_hyp_mean': 0.0,\n",
       " 'wood_mean': 0.0,\n",
       " 'tennis_stroke_hyp_mean': 0.0,\n",
       " 'serve_mean': 0.0,\n",
       " 'curve_hyp_mean': 0.0,\n",
       " 'turn_mean': 0.0,\n",
       " 'worships_mean': 0.0,\n",
       " 'lenience_hyp_mean': 0.0,\n",
       " 'heartily_syn_mean': 0.0,\n",
       " 'heartily_mean': 0.0,\n",
       " 'beseech_mean': 0.0,\n",
       " 'worship_mean': 0.0,\n",
       " 'feeling_hyp_mean': 0.0,\n",
       " 'desire_mean': 0.0,\n",
       " 'information_hyp_mean': 0.0,\n",
       " 'acquaintance_mean': 0.0,\n",
       " 'font_hyp_mean': 0.0,\n",
       " 'bold_mean': 0.0,\n",
       " 'commune_hyp_mean': 0.0,\n",
       " 'pray_mean': 0.0,\n",
       " 'praise_hyp_mean': 0.0,\n",
       " 'commend_mean': 0.0,\n",
       " 'vine_hyp_mean': 0.0,\n",
       " 'squash_mean': 0.0,\n",
       " 'peascod_mean': 0.0,\n",
       " 'man_hyp_mean': 0.0,\n",
       " 'sir_mean': 0.0,\n",
       " 'crucifer_hyp_mean': 0.0,\n",
       " 'mustard_mean': 0.0,\n",
       " 'fruit_hyp_mean': 0.0,\n",
       " 'seed_mean': 0.0,\n",
       " 'knowing_hyp_mean': 0.0,\n",
       " 'know_mean': 0.0,\n",
       " 'cowardly_syn_mean': 0.0,\n",
       " 'cowardly_mean': 0.0,\n",
       " 'animal_hyp_mean': 0.0,\n",
       " 'giant_mean': 0.0,\n",
       " 'kind_hyp_mean': 0.0,\n",
       " 'like_mean': 0.0,\n",
       " 'SCONJ_mean': 0.0,\n",
       " 'cattle_hyp_mean': 0.0,\n",
       " 'ox_mean': 0.0,\n",
       " 'beef_mean': 0.0,\n",
       " 'destroy_hyp_mean': 0.0,\n",
       " 'devour_mean': 0.0,\n",
       " 'building_hyp_mean': 0.0,\n",
       " 'house_mean': 0.0,\n",
       " 'commitment_hyp_mean': 0.0,\n",
       " 'promise_mean': 0.0,\n",
       " 'social_group_hyp_mean': 0.0,\n",
       " 'kindred_mean': 0.0,\n",
       " 'binary_compound_hyp_mean': 0.0,\n",
       " 'water_mean': 0.0,\n",
       " 'wound_hyp_mean': 0.0,\n",
       " 'scratch_mean': 0.0,\n",
       " 'monsieur_mean': 0.0,\n",
       " 'instrument_hyp_mean': 0.0,\n",
       " 'weapon_mean': 0.0,\n",
       " 'extremity_hyp_mean': 0.0,\n",
       " 'hand_mean': 0.0,\n",
       " 'red_mean': 0.0,\n",
       " 'hipped_syn_mean': 0.0,\n",
       " 'hippe_mean': 0.0,\n",
       " 'humble_mean': 0.0,\n",
       " 'hymenopterous_insect_hyp_mean': 0.0,\n",
       " 'bee_mean': 0.0,\n",
       " 'weed_hyp_mean': 0.0,\n",
       " 'thistle_mean': 0.0,\n",
       " 'sweetening_hyp_mean': 0.0,\n",
       " 'honey_mean': 0.0,\n",
       " 'container_hyp_mean': 0.0,\n",
       " 'bag_mean': 0.0,\n",
       " 'agitation_hyp_mean': 0.0,\n",
       " 'fret_mean': 0.0,\n",
       " 'action_mean': 0.0,\n",
       " 'work_hyp_mean': 0.0,\n",
       " 'care_mean': 0.0,\n",
       " 'loath_syn_mean': 0.0,\n",
       " 'loath_mean': 0.0,\n",
       " 'spill_hyp_mean': 0.0,\n",
       " 'overflown_mean': 0.0,\n",
       " 'signior_mean': 0.0,\n",
       " 'politeness_hyp_mean': 0.0,\n",
       " 'courtesy_mean': 0.0,\n",
       " 'help_mean': 0.0,\n",
       " 'military_personnel_hyp_mean': 0.0,\n",
       " 'cavalry_mean': 0.0,\n",
       " 'barber_syn_mean': 0.0,\n",
       " 'barber_mean': 0.0,\n",
       " 'marvel_mean': 0.0,\n",
       " 'hairy_syn_mean': 0.0,\n",
       " 'hairy_mean': 0.0,\n",
       " 'medium_of_exchange_hyp_mean': 0.0,\n",
       " 'tender_mean': 0.0,\n",
       " 'body_covering_hyp_mean': 0.0,\n",
       " 'hair_mean': 0.0,\n",
       " 'cutaneous_sensation_hyp_mean': 0.0,\n",
       " 'tickle_mean': 0.0,\n",
       " 'reasonable_syn_mean': 0.0,\n",
       " 'reasonable_mean': 0.0,\n",
       " 'sense_organ_hyp_mean': 0.0,\n",
       " 'ear_mean': 0.0,\n",
       " 'auditory_communication_hyp_mean': 0.0,\n",
       " 'music_mean': 0.0,\n",
       " 'device_hyp_mean': 0.0,\n",
       " 'tong_mean': 0.0,\n",
       " 'percussion_instrument_hyp_mean': 0.0,\n",
       " 'bone_mean': 0.0,\n",
       " 'truly_syn_mean': 0.0,\n",
       " 'truly_mean': 0.0,\n",
       " 'large_indefinite_quantity_hyp_mean': 0.0,\n",
       " 'peck_mean': 0.0,\n",
       " 'food_hyp_mean': 0.0,\n",
       " 'provender_mean': 0.0,\n",
       " 'munch_syn_mean': 0.0,\n",
       " 'munch_mean': 0.0,\n",
       " 'reformer_hyp_mean': 0.0,\n",
       " 'dry_mean': 0.0,\n",
       " 'cereal_hyp_mean': 0.0,\n",
       " 'oats_mean': 0.0,\n",
       " 'vessel_hyp_mean': 0.0,\n",
       " 'bottle_mean': 0.0,\n",
       " 'fodder_hyp_mean': 0.0,\n",
       " 'hay_mean': 0.0,\n",
       " 'male_hyp_mean': 0.0,\n",
       " 'fellow_mean': 0.0,\n",
       " 'handful_mean': 0.0,\n",
       " 'legume_hyp_mean': 0.0,\n",
       " 'pea_mean': 0.0,\n",
       " 'group_hyp_mean': 0.0,\n",
       " 'people_mean': 0.0,\n",
       " 'interpretation_hyp_mean': 0.0,\n",
       " 'exposition_mean': 0.0,\n",
       " 'physical_condition_hyp_mean': 0.0,\n",
       " 'sleep_mean': 0.0,\n",
       " \"actor's_line_hyp_mean\": 0.0,\n",
       " 'cue_mean': 0.0,\n",
       " 'hey_mean': 0.0,\n",
       " 'metallic_element_hyp_mean': 0.0,\n",
       " 'ho_mean': 0.0,\n",
       " 'blower_hyp_mean': 0.0,\n",
       " 'bellow_mean': 0.0,\n",
       " 'skilled_worker_hyp_mean': 0.0,\n",
       " 'mender_mean': 0.0,\n",
       " 'experimenter_hyp_mean': 0.0,\n",
       " 'tinker_mean': 0.0,\n",
       " 'take_hyp_mean': 0.0,\n",
       " 'steal_mean': 0.0,\n",
       " 'position_hyp_mean': 0.0,\n",
       " 'asleep_syn_mean': 0.0,\n",
       " 'asleep_mean': 0.0,\n",
       " 'rare_syn_mean': 0.0,\n",
       " 'rare_mean': 0.0,\n",
       " 'imagination_hyp_mean': 0.0,\n",
       " 'vision_mean': 0.0,\n",
       " 'dream_mean': 0.0,\n",
       " 'past_mean': 0.0,\n",
       " 'ADP_mean': 0.0,\n",
       " 'clarify_hyp_mean': 0.0,\n",
       " 'expound_mean': 0.0,\n",
       " 'content_hyp_mean': 0.0,\n",
       " 'join_hyp_mean': 0.0,\n",
       " 'patched_mean': 0.0,\n",
       " 'speech_act_hyp_mean': 0.0,\n",
       " 'offer_mean': 0.0,\n",
       " 'able_syn_mean': 0.0,\n",
       " 'able_mean': 0.0,\n",
       " 'sensation_hyp_mean': 0.0,\n",
       " 'taste_mean': 0.0,\n",
       " 'articulator_hyp_mean': 0.0,\n",
       " 'tongue_mean': 0.0,\n",
       " 'create_by_mental_act_hyp_mean': 0.0,\n",
       " 'conceive_mean': 0.0,\n",
       " 'document_hyp_mean': 0.0,\n",
       " 'report_mean': 0.0,\n",
       " 'song_hyp_mean': 0.0,\n",
       " 'ballad_mean': 0.0,\n",
       " 'label_hyp_mean': 0.0,\n",
       " 'call_mean': 0.0,\n",
       " 'end_mean': 0.0,\n",
       " 'doubt_hyp_mean': 0.0,\n",
       " 'peradventure_mean': 0.0,\n",
       " 'gracious_syn_mean': 0.0,\n",
       " 'gracious_mean': 0.0,\n",
       " 'death_mean': 0.0,\n",
       " 'lad_mean': 0.0,\n",
       " 'whist_hyp_mean': 0.0,\n",
       " 'language_unit_hyp_mean': 0.0,\n",
       " 'discourse_mean': 0.0,\n",
       " 'astonishment_hyp_mean': 0.0,\n",
       " 'wonder_mean': 0.0,\n",
       " 'greek_hyp_mean': 0.0,\n",
       " 'athenian_mean': 0.0,\n",
       " 'abstraction_hyp_mean': 0.0,\n",
       " 'right_mean': 0.0,\n",
       " 'fall_mean': 0.0,\n",
       " 'word_mean': 0.0,\n",
       " 'eat_hyp_mean': 0.0,\n",
       " 'dine_mean': 0.0,\n",
       " 'clothing_hyp_mean': 0.0,\n",
       " 'apparel_mean': 0.0,\n",
       " 'section_hyp_mean': 0.0,\n",
       " 'string_mean': 0.0,\n",
       " 'new_syn_mean': 0.0,\n",
       " 'new_mean': 0.0,\n",
       " 'object_hyp_mean': 0.0,\n",
       " 'ribbon_mean': 0.0,\n",
       " 'mechanical_device_hyp_mean': 0.0,\n",
       " 'pump_mean': 0.0,\n",
       " 'soon_syn_mean': 0.0,\n",
       " 'presently_mean': 0.0,\n",
       " 'mansion_hyp_mean': 0.0,\n",
       " 'palace_mean': 0.0,\n",
       " 'tract_hyp_mean': 0.0,\n",
       " 'short_mean': 0.0,\n",
       " 'long_mean': 0.0,\n",
       " 'like_hyp_mean': 0.0,\n",
       " 'prefer_mean': 0.0,\n",
       " 'case_mean': 0.0,\n",
       " 'weightlift_hyp_mean': 0.0,\n",
       " 'clean_mean': 0.0,\n",
       " 'fabric_hyp_mean': 0.0,\n",
       " 'linen_mean': 0.0,\n",
       " 'decrease_hyp_mean': 0.0,\n",
       " 'pare_mean': 0.0,\n",
       " 'horny_structure_hyp_mean': 0.0,\n",
       " 'nail_mean': 0.0,\n",
       " 'claws_mean': 0.0,\n",
       " 'consume_hyp_mean': 0.0,\n",
       " 'eat_mean': 0.0,\n",
       " 'bulb_hyp_mean': 0.0,\n",
       " 'onion_mean': 0.0,\n",
       " 'alliaceous_plant_hyp_mean': 0.0,\n",
       " 'garlic_mean': 0.0,\n",
       " 'express_syn_mean': 0.0,\n",
       " 'utter_mean': 0.0,\n",
       " 'cognitive_state_hyp_mean': 0.0,\n",
       " 'doubt_mean': 0.0,\n",
       " 'grim_syn_mean': 0.0,\n",
       " 'grim_mean': 0.0,\n",
       " 'time_period_hyp_mean': 0.0,\n",
       " 'night_mean': 0.0,\n",
       " 'creation_hyp_mean': 0.0,\n",
       " 'art_mean': 0.0,\n",
       " 'time_unit_hyp_mean': 0.0,\n",
       " 'day_mean': 0.0,\n",
       " 'process_hyp_mean': 0.0,\n",
       " 'alas_mean': 0.0,\n",
       " 'forget_syn_mean': 0.0,\n",
       " 'forgot_mean': 0.0,\n",
       " \"photographer's_model_hyp_mean\": 0.0,\n",
       " 'lovely_mean': 0.0,\n",
       " 'support_hyp_mean': 0.0,\n",
       " 'stand_mean': 0.0,\n",
       " 'ground_mean': 0.0,\n",
       " 'chinese_hyp_mean': 0.0,\n",
       " 'chink_mean': 0.0,\n",
       " 'blink_mean': 0.0,\n",
       " 'acknowledgment_hyp_mean': 0.0,\n",
       " 'thank_mean': 0.0,\n",
       " 'courteous_syn_mean': 0.0,\n",
       " 'courteous_mean': 0.0,\n",
       " 'jupiter_syn_mean': 0.0,\n",
       " 'jove_mean': 0.0,\n",
       " 'wicked_syn_mean': 0.0,\n",
       " 'wicked_mean': 0.0,\n",
       " 'elation_hyp_mean': 0.0,\n",
       " 'bliss_mean': 0.0,\n",
       " 'express_hyp_mean': 0.0,\n",
       " 'cursed_mean': 0.0,\n",
       " 'stone_mean': 0.0,\n",
       " 'victimize_hyp_mean': 0.0,\n",
       " 'deceive_mean': 0.0,\n",
       " 'enter_syn_mean': 0.0,\n",
       " 'enter_mean': 0.0,\n",
       " 'secret_agent_hyp_mean': 0.0,\n",
       " 'spy_mean': 0.0,\n",
       " 'season_hyp_mean': 0.0,\n",
       " 'pat_mean': 0.0,\n",
       " 'yonder_syn_mean': 0.0,\n",
       " 'yonder_mean': 0.0,\n",
       " 'plant_disease_hyp_mean': 0.0,\n",
       " 'wilt_mean': 0.0,\n",
       " 'state_hyp_mean': 0.0,\n",
       " 'grace_mean': 0.0,\n",
       " 'limander_mean': 0.0,\n",
       " 'convict_hyp_mean': 0.0,\n",
       " 'trusty_mean': 0.0,\n",
       " 'shafalus_mean': 0.0,\n",
       " 'procrus_mean': 0.0,\n",
       " 'touch_hyp_mean': 0.0,\n",
       " 'kiss_mean': 0.0,\n",
       " 'opening_hyp_mean': 0.0,\n",
       " 'hole_mean': 0.0,\n",
       " 'despicable_syn_mean': 0.0,\n",
       " 'vile_mean': 0.0,\n",
       " 'simpleton_hyp_mean': 0.0,\n",
       " 'ninny_mean': 0.0,\n",
       " 'topographic_point_hyp_mean': 0.0,\n",
       " 'tomb_mean': 0.0,\n",
       " 'straightway_syn_mean': 0.0,\n",
       " 'straightway_mean': 0.0,\n",
       " 'convey_hyp_mean': 0.0,\n",
       " 'cheery_syn_mean': 0.0,\n",
       " 'sunny_mean': 0.0,\n",
       " 'signal_hyp_mean': 0.0,\n",
       " 'beam_mean': 0.0,\n",
       " 'bright_syn_mean': 0.0,\n",
       " 'bright_mean': 0.0,\n",
       " 'aureate_syn_mean': 0.0,\n",
       " 'golden_mean': 0.0,\n",
       " 'look_hyp_mean': 0.0,\n",
       " 'glitter_mean': 0.0,\n",
       " 'radiance_hyp_mean': 0.0,\n",
       " 'gleam_mean': 0.0,\n",
       " 'trust_mean': 0.0,\n",
       " 'visual_percept_hyp_mean': 0.0,\n",
       " 'sight_mean': 0.0,\n",
       " 'malevolence_hyp_mean': 0.0,\n",
       " 'spite_mean': 0.0,\n",
       " 'people_hyp_mean': 0.0,\n",
       " 'poor_mean': 0.0,\n",
       " 'dole_mean': 0.0,\n",
       " 'dainty_mean': 0.0,\n",
       " 'anseriform_bird_hyp_mean': 0.0,\n",
       " 'duck_mean': 0.0,\n",
       " 'mantle_mean': 0.0,\n",
       " 'dye_hyp_mean': 0.0,\n",
       " 'stain_mean': 0.0,\n",
       " 'blood_mean': 0.0,\n",
       " 'conceptualization_hyp_mean': 0.0,\n",
       " 'approach_mean': 0.0,\n",
       " 'anger_hyp_mean': 0.0,\n",
       " 'furies_mean': 0.0,\n",
       " 'thread_mean': 0.0,\n",
       " 'thrum_mean': 0.0,\n",
       " 'wildfowl_hyp_mean': 0.0,\n",
       " 'quail_mean': 0.0,\n",
       " 'leather_hyp_mean': 0.0,\n",
       " 'crush_mean': 0.0,\n",
       " 'conclude_mean': 0.0,\n",
       " 'suppress_hyp_mean': 0.0,\n",
       " 'quell_mean': 0.0,\n",
       " 'reason_hyp_mean': 0.0,\n",
       " 'wherefore_mean': 0.0,\n",
       " 'quality_hyp_mean': 0.0,\n",
       " 'nature_mean': 0.0,\n",
       " 'frame_mean': 0.0,\n",
       " 'copulate_hyp_mean': 0.0,\n",
       " 'deflower_mean': 0.0,\n",
       " 'girl_hyp_mean': 0.0,\n",
       " 'dame_mean': 0.0,\n",
       " 'live_mean': 0.0,\n",
       " 'approval_hyp_mean': 0.0,\n",
       " 'cheer_mean': 0.0,\n",
       " 'confound_mean': 0.0,\n",
       " 'injury_hyp_mean': 0.0,\n",
       " 'wound_mean': 0.0,\n",
       " 'drivel_hyp_mean': 0.0,\n",
       " 'pap_mean': 0.0,\n",
       " 'ay_mean': 0.0,\n",
       " 'jump_hyp_mean': 0.0,\n",
       " 'hop_mean': 0.0,\n",
       " 'cube_hyp_mean': 0.0,\n",
       " 'die_mean': 0.0,\n",
       " 'dead_mean': 0.0,\n",
       " 'scat_hyp_mean': 0.0,\n",
       " 'flee_mean': 0.0,\n",
       " 'spirit_hyp_mean': 0.0,\n",
       " 'soul_mean': 0.0,\n",
       " 'atmosphere_hyp_mean': 0.0,\n",
       " 'sky_mean': 0.0,\n",
       " 'lose_syn_mean': 0.0,\n",
       " 'lose_mean': 0.0,\n",
       " 'actinic_radiation_hyp_mean': 0.0,\n",
       " 'light_mean': 0.0,\n",
       " 'formation_hyp_mean': 0.0,\n",
       " 'flight_mean': 0.0,\n",
       " 'move_hyp_mean': 0.0,\n",
       " 'part_mean': 0.0,\n",
       " 'parent_hyp_mean': 0.0,\n",
       " 'father_mean': 0.0,\n",
       " 'conclusion_hyp_mean': 0.0,\n",
       " 'epilogue_mean': 0.0,\n",
       " 'bergomask_mean': 0.0,\n",
       " 'art_hyp_mean': 0.0,\n",
       " 'dance_mean': 0.0,\n",
       " 'philomel_mean': 0.0,\n",
       " 'music_hyp_mean': 0.0,\n",
       " 'melody_mean': 0.0,\n",
       " 'lullaby_mean': 0.0,\n",
       " 'lulla_mean': 0.0,\n",
       " 'psychological_state_hyp_mean': 0.0,\n",
       " 'spell_mean': 0.0,\n",
       " 'attractiveness_hyp_mean': 0.0,\n",
       " 'charm_mean': 0.0,\n",
       " 'near_syn_mean': 0.0,\n",
       " 'nigh_mean': 0.0,\n",
       " 'precipitation_hyp_mean': 0.0,\n",
       " 'hail_mean': 0.0,\n",
       " 'yield_syn_mean': 0.0,\n",
       " 'relent_mean': 0.0,\n",
       " 'production_hyp_mean': 0.0,\n",
       " 'yield_mean': 0.0,\n",
       " 'madden_syn_mean': 0.0,\n",
       " 'crazed_mean': 0.0,\n",
       " 'heading_hyp_mean': 0.0,\n",
       " 'title_mean': 0.0,\n",
       " 'certain_syn_mean': 0.0,\n",
       " 'certain_mean': 0.0,\n",
       " 'pursue_mean': 0.0,\n",
       " 'foundation_garment_hyp_mean': 0.0,\n",
       " 'unto_mean': 0.0,\n",
       " 'shift_hyp_mean': 0.0,\n",
       " 'go_mean': 0.0,\n",
       " 'travel_hyp_mean': 0.0,\n",
       " 'follow_mean': 0.0,\n",
       " 'provoke_hyp_mean': 0.0,\n",
       " 'entice_mean': 0.0,\n",
       " 'land_hyp_mean': 0.0,\n",
       " 'plain_mean': 0.0,\n",
       " 'invite_hyp_mean': 0.0,\n",
       " 'tempt_mean': 0.0,\n",
       " 'hatred_mean': 0.0,\n",
       " 'sick_mean': 0.0,\n",
       " 'impeach_mean': 0.0,\n",
       " 'decency_hyp_mean': 0.0,\n",
       " 'modesty_mean': 0.0,\n",
       " 'municipality_hyp_mean': 0.0,\n",
       " 'city_mean': 0.0,\n",
       " 'commit_mean': 0.0,\n",
       " 'guardianship_hyp_mean': 0.0,\n",
       " 'possibility_hyp_mean': 0.0,\n",
       " 'opportunity_mean': 0.0,\n",
       " 'disorder_hyp_mean': 0.0,\n",
       " 'ill_mean': 0.0,\n",
       " 'lawyer_hyp_mean': 0.0,\n",
       " 'counsel_mean': 0.0,\n",
       " 'biome_hyp_mean': 0.0,\n",
       " 'desert_mean': 0.0,\n",
       " 'rich_mean': 0.0,\n",
       " 'indefinite_quantity_hyp_mean': 0.0,\n",
       " 'worth_mean': 0.0,\n",
       " 'condition_hyp_mean': 0.0,\n",
       " 'virginity_mean': 0.0,\n",
       " 'brake_hyp_mean': 0.0,\n",
       " 'brake_mean': 0.0,\n",
       " 'wild_mean': 0.0,\n",
       " 'organism_hyp_mean': 0.0,\n",
       " 'beast_mean': 0.0,\n",
       " 'questioning_hyp_mean': 0.0,\n",
       " 'question_mean': 0.0,\n",
       " 'accept_hyp_mean': 0.0,\n",
       " 'believe_mean': 0.0,\n",
       " 'misbehavior_hyp_mean': 0.0,\n",
       " 'mischief_mean': 0.0,\n",
       " 'attack_hyp_mean': 0.0,\n",
       " 'charge_mean': 0.0,\n",
       " 'haunt_mean': 0.0,\n",
       " 'danger_hyp_mean': 0.0,\n",
       " 'peril_mean': 0.0,\n",
       " 'criticism_hyp_mean': 0.0,\n",
       " 'rebuke_mean': 0.0,\n",
       " 'lay_mean': 0.0,\n",
       " 'ale_hyp_mean': 0.0,\n",
       " 'bitter_mean': 0.0,\n",
       " 'adversary_hyp_mean': 0.0,\n",
       " 'foe_mean': 0.0,\n",
       " 'kill_hyp_mean': 0.0,\n",
       " 'murdered_mean': 0.0,\n",
       " 'penetrate_hyp_mean': 0.0,\n",
       " 'pierce_mean': 0.0,\n",
       " 'rear_hyp_mean': 0.0,\n",
       " 'stern_mean': 0.0,\n",
       " 'maltreatment_hyp_mean': 0.0,\n",
       " 'cruelty_mean': 0.0,\n",
       " 'innocence_hyp_mean': 0.0,\n",
       " 'clear_mean': 0.0,\n",
       " 'venus_syn_mean': 0.0,\n",
       " 'venus_mean': 0.0,\n",
       " 'suggestion_hyp_mean': 0.0,\n",
       " 'glimmering_mean': 0.0,\n",
       " 'environment_hyp_mean': 0.0,\n",
       " 'sphere_mean': 0.0,\n",
       " 'body_hyp_mean': 0.0,\n",
       " 'carcass_mean': 0.0,\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a52a06e8-05a3-47bc-80a9-5de88baa5f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2b1ad5f4100>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(logreg_rs_rocauc.best_estimator_['logreg'], Xs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "694c12be-fcaf-4298-a866-eaf297b3ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_pipe = Pipeline([\n",
    "    ('et', ExtraTreesClassifier(random_state = 42))\n",
    "])\n",
    "\n",
    "et_params = {\n",
    "    'et__criterion': Categorical(['gini', 'entropy']),\n",
    "    'et__n_estimators': randint(5, 200),\n",
    "    'et__min_samples_split': uniform(0, .5),\n",
    "    'et__min_samples_leaf': uniform(0, .5),\n",
    "    'et__max_depth': randint(1, 100),\n",
    "    'et__max_features': Categorical(['auto', 'sqrt', 'log2']),\n",
    "    'et__min_impurity_decrease': uniform(0, .2),\n",
    "    'et__ccp_alpha':  uniform(0, .2),\n",
    "    'et__max_samples':  uniform(0, 1)\n",
    "}\n",
    "\n",
    "et_rs_rocauc = RandomizedSearchCV(estimator = et_pipe,\n",
    "                     param_distributions = et_params,\n",
    "                     scoring = 'roc_auc',\n",
    "                     n_iter = 100,\n",
    "                     cv = 5,\n",
    "                     refit = True,\n",
    "                     n_jobs = 8,\n",
    "                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2a6063b-5c1c-4e1c-96a9-ebe26caa7ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('et',\n",
       "                                              ExtraTreesClassifier(random_state=42))]),\n",
       "                   n_iter=100, n_jobs=8,\n",
       "                   param_distributions={'et__ccp_alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002B1F1675580>,\n",
       "                                        'et__criterion': Categorical(categories=('gini', 'entropy'), prior=None),\n",
       "                                        'et__max_depth': <scipy.stats._distn_infrastructure.rv_...\n",
       "                                        'et__min_impurity_decrease': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002B1F16752B0>,\n",
       "                                        'et__min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002B1F166AD00>,\n",
       "                                        'et__min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002B1F166A940>,\n",
       "                                        'et__n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002B215AC4AF0>},\n",
       "                   random_state=42, scoring='roc_auc')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "et_rs_rocauc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "148c1e2e-d2f9-471e-8fda-49a89ca3a989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9061302681992337, 0.9054441260744985)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_rs_rocauc.best_estimator_.score(X_train, y_train), et_rs_rocauc.best_estimator_.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "345e50ae-ee25-466f-b3fb-684d75a453f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(ccp_alpha=0.0749080237694725, criterion='entropy',\n",
       "                     max_depth=72, max_features='sqrt',\n",
       "                     max_samples=0.15601864044243652,\n",
       "                     min_impurity_decrease=0.031198904067240532,\n",
       "                     min_samples_leaf=0.02904180608409973,\n",
       "                     min_samples_split=0.4330880728874676, n_estimators=104,\n",
       "                     random_state=42)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_rs_rocauc.best_estimator_['et']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13248b49-b7f1-4f3e-aef7-f242597fcc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {key: value for key, value in zip(x_list, et_rs_rocauc.best_estimator_['et'].feature_importances_)}\n",
    "features = {k: v for k, v in sorted(features.items(), key=lambda item: item[1], reverse = True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d148f55c-426e-46da-906c-0b8a2277744e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_sentiment_mean': 0.0,\n",
       " 'neg_sentiment_mean': 0.0,\n",
       " 'neu_sentiment_mean': 0.0,\n",
       " 'compound_sentiment_mean': 0.0,\n",
       " 'endowment_hyp_mean': 0.0,\n",
       " 'hang_mean': 0.0,\n",
       " 'VERB_mean': 0.0,\n",
       " 'character_name_mean': 0.0,\n",
       " 'PROPN_mean': 0.0,\n",
       " 'shall_mean': 0.0,\n",
       " 'attempt_hyp_mean': 0.0,\n",
       " 'good_mean': 0.0,\n",
       " 'ADJ_mean': 0.0,\n",
       " 'by_and_large_syn_mean': 0.0,\n",
       " 'generally_mean': 0.0,\n",
       " 'ADV_mean': 0.0,\n",
       " 'match_hyp_mean': 0.0,\n",
       " 'accord_mean': 0.0,\n",
       " 'security_hyp_mean': 0.0,\n",
       " 'scrip_mean': 0.0,\n",
       " 'advantage_hyp_mean': 0.0,\n",
       " 'dramatic_composition_hyp_mean': 0.0,\n",
       " 'play_mean': 0.0,\n",
       " 'NOUN_mean': 0.0,\n",
       " 'nutriment_hyp_mean': 0.0,\n",
       " 'treat_mean': 0.0,\n",
       " 'publication_hyp_mean': 0.0,\n",
       " 'read_mean': 0.0,\n",
       " 'defamation_hyp_mean': 0.0,\n",
       " 'name_mean': 0.0,\n",
       " 'performer_hyp_mean': 0.0,\n",
       " 'actor_mean': 0.0,\n",
       " 'change_hyp_mean': 0.0,\n",
       " 'grow_mean': 0.0,\n",
       " 'component_hyp_mean': 0.0,\n",
       " 'point_mean': 0.0,\n",
       " 'part_hyp_mean': 0.0,\n",
       " 'piece_mean': 0.0,\n",
       " 'activity_hyp_mean': 0.0,\n",
       " 'work_mean': 0.0,\n",
       " 'guarantee_syn_mean': 0.0,\n",
       " 'assure_mean': 0.0,\n",
       " 'gay_syn_mean': 0.0,\n",
       " 'merry_mean': 0.0,\n",
       " 'forth_syn_mean': 0.0,\n",
       " 'forth_mean': 0.0,\n",
       " 'round_shape_hyp_mean': 0.0,\n",
       " 'scroll_mean': 0.0,\n",
       " 'masters_syn_mean': 0.0,\n",
       " 'masters_mean': 0.0,\n",
       " 'change_of_location_hyp_mean': 0.0,\n",
       " 'spread_mean': 0.0,\n",
       " 'readiness_hyp_mean': 0.0,\n",
       " 'ready_mean': 0.0,\n",
       " 'talk_hyp_mean': 0.0,\n",
       " 'proceed_mean': 0.0,\n",
       " 'pyramus_mean': 0.0,\n",
       " 'person_hyp_mean': 0.0,\n",
       " 'lover_mean': 0.0,\n",
       " 'dictator_hyp_mean': 0.0,\n",
       " 'tyrant_mean': 0.0,\n",
       " 'communicate_hyp_mean': 0.0,\n",
       " 'ask_mean': 0.0,\n",
       " 'bodily_process_hyp_mean': 0.0,\n",
       " 'tear_mean': 0.0,\n",
       " 'alignment_hyp_mean': 0.0,\n",
       " 'true_mean': 0.0,\n",
       " 'performing_mean': 0.0,\n",
       " 'lashkar-e-taiba_syn_mean': 0.0,\n",
       " 'let_mean': 0.0,\n",
       " 'gathering_hyp_mean': 0.0,\n",
       " 'audience_mean': 0.0,\n",
       " 'countenance_hyp_mean': 0.0,\n",
       " 'look_mean': 0.0,\n",
       " 'opinion_hyp_mean': 0.0,\n",
       " 'eye_mean': 0.0,\n",
       " 'atmospheric_phenomenon_hyp_mean': 0.0,\n",
       " 'storm_mean': 0.0,\n",
       " 'commiserate_hyp_mean': 0.0,\n",
       " 'condole_mean': 0.0,\n",
       " 'maneuver_hyp_mean': 0.0,\n",
       " 'measure_mean': 0.0,\n",
       " 'rest_mean': 0.0,\n",
       " 'leader_hyp_mean': 0.0,\n",
       " 'chief_mean': 0.0,\n",
       " 'message_hyp_mean': 0.0,\n",
       " 'humor_mean': 0.0,\n",
       " 'ercles_mean': 0.0,\n",
       " 'rarely_syn_mean': 0.0,\n",
       " 'rarely_mean': 0.0,\n",
       " 'drop_hyp_mean': 0.0,\n",
       " 'feline_hyp_mean': 0.0,\n",
       " 'cat_mean': 0.0,\n",
       " 'acrobatic_stunt_hyp_mean': 0.0,\n",
       " 'split_mean': 0.0,\n",
       " 'act_hyp_mean': 0.0,\n",
       " 'rage_mean': 0.0,\n",
       " 'natural_object_hyp_mean': 0.0,\n",
       " 'rock_mean': 0.0,\n",
       " 'symptom_hyp_mean': 0.0,\n",
       " 'shivering_mean': 0.0,\n",
       " 'stupefaction_hyp_mean': 0.0,\n",
       " 'shock_mean': 0.0,\n",
       " 'happening_hyp_mean': 0.0,\n",
       " 'break_mean': 0.0,\n",
       " 'fastener_hyp_mean': 0.0,\n",
       " 'lock_mean': 0.0,\n",
       " 'correctional_institution_hyp_mean': 0.0,\n",
       " 'prison_mean': 0.0,\n",
       " 'movable_barrier_hyp_mean': 0.0,\n",
       " 'gate_mean': 0.0,\n",
       " 'phibbus_mean': 0.0,\n",
       " 'motor_vehicle_hyp_mean': 0.0,\n",
       " 'car_mean': 0.0,\n",
       " 'brightness_hyp_mean': 0.0,\n",
       " 'shine_mean': 0.0,\n",
       " 'army_for_the_liberation_of_rwanda_syn_mean': 0.0,\n",
       " 'far_mean': 0.0,\n",
       " 'gregorian_calendar_month_hyp_mean': 0.0,\n",
       " 'mar_mean': 0.0,\n",
       " 'foolish_syn_mean': 0.0,\n",
       " 'foolish_mean': 0.0,\n",
       " 'fate_mean': 0.0,\n",
       " 'exalted_syn_mean': 0.0,\n",
       " 'lofty_mean': 0.0,\n",
       " 'contestant_hyp_mean': 0.0,\n",
       " 'player_mean': 0.0,\n",
       " 'blood_vessel_hyp_mean': 0.0,\n",
       " 'vein_mean': 0.0,\n",
       " 'condoling_mean': 0.0,\n",
       " 'animal_skin_hyp_mean': 0.0,\n",
       " 'hide_mean': 0.0,\n",
       " 'external_body_part_hyp_mean': 0.0,\n",
       " 'face_mean': 0.0,\n",
       " 'thisbe_mean': 0.0,\n",
       " 'speak_mean': 0.0,\n",
       " 'monstrous_syn_mean': 0.0,\n",
       " 'monstrous_mean': 0.0,\n",
       " 'small_indefinite_quantity_hyp_mean': 0.0,\n",
       " 'little_mean': 0.0,\n",
       " 'sound_hyp_mean': 0.0,\n",
       " 'voice_mean': 0.0,\n",
       " 'thisne_mean': 0.0,\n",
       " 'ah_mean': 0.0,\n",
       " 'INTJ_mean': 0.0,\n",
       " 'lover_hyp_mean': 0.0,\n",
       " 'dear_mean': 0.0,\n",
       " 'big_cat_hyp_mean': 0.0,\n",
       " 'lion_mean': 0.0,\n",
       " 'noise_hyp_mean': 0.0,\n",
       " 'roar_mean': 0.0,\n",
       " 'intuition_hyp_mean': 0.0,\n",
       " 'heart_mean': 0.0,\n",
       " 'perceive_hyp_mean': 0.0,\n",
       " 'hear_mean': 0.0,\n",
       " 'aid_hyp_mean': 0.0,\n",
       " 'grant_mean': 0.0,\n",
       " 'friend_mean': 0.0,\n",
       " 'emotion_hyp_mean': 0.0,\n",
       " 'fright_mean': 0.0,\n",
       " 'intelligence_hyp_mean': 0.0,\n",
       " 'wit_mean': 0.0,\n",
       " 'liberty_hyp_mean': 0.0,\n",
       " 'discretion_mean': 0.0,\n",
       " 'aggravate_mean': 0.0,\n",
       " 'gently_syn_mean': 0.0,\n",
       " 'gently_mean': 0.0,\n",
       " 'consumption_hyp_mean': 0.0,\n",
       " 'sucking_mean': 0.0,\n",
       " 'pigeon_hyp_mean': 0.0,\n",
       " 'dove_mean': 0.0,\n",
       " 'thrush_hyp_mean': 0.0,\n",
       " 'nightingale_mean': 0.0,\n",
       " 'initiate_hyp_mean': 0.0,\n",
       " 'undertake_mean': 0.0,\n",
       " 'facial_hair_hyp_mean': 0.0,\n",
       " 'beard_mean': 0.0,\n",
       " 'discharge_mean': 0.0,\n",
       " 'plant_fiber_hyp_mean': 0.0,\n",
       " 'straw_mean': 0.0,\n",
       " 'visual_property_hyp_mean': 0.0,\n",
       " 'color_mean': 0.0,\n",
       " 'citrus_hyp_mean': 0.0,\n",
       " 'orange_mean': 0.0,\n",
       " 'tawny_syn_mean': 0.0,\n",
       " 'tawny_mean': 0.0,\n",
       " 'chromatic_color_hyp_mean': 0.0,\n",
       " 'purple_mean': 0.0,\n",
       " 'atom_hyp_mean': 0.0,\n",
       " 'grain_mean': 0.0,\n",
       " 'romance_hyp_mean': 0.0,\n",
       " 'french_mean': 0.0,\n",
       " 'symbol_hyp_mean': 0.0,\n",
       " 'crown_mean': 0.0,\n",
       " 'perfit_mean': 0.0,\n",
       " 'yellow_mean': 0.0,\n",
       " 'athletic_contest_hyp_mean': 0.0,\n",
       " 'meet_mean': 0.0,\n",
       " 'perform_hyp_mean': 0.0,\n",
       " 'rehearse_mean': 0.0,\n",
       " 'obscenely_syn_mean': 0.0,\n",
       " 'obscenely_mean': 0.0,\n",
       " 'bravely_syn_mean': 0.0,\n",
       " 'courageously_mean': 0.0,\n",
       " 'pain_mean': 0.0,\n",
       " 'farewell_hyp_mean': 0.0,\n",
       " 'adieu_mean': 0.0,\n",
       " 'grasping_hyp_mean': 0.0,\n",
       " 'hold_mean': 0.0,\n",
       " 'share_hyp_mean': 0.0,\n",
       " 'cut_mean': 0.0,\n",
       " 'cord_hyp_mean': 0.0,\n",
       " 'bowstring_mean': 0.0,\n",
       " 'property_hyp_mean': 0.0,\n",
       " 'thing_mean': 0.0,\n",
       " 'drama_hyp_mean': 0.0,\n",
       " 'comedy_mean': 0.0,\n",
       " 'gully_hyp_mean': 0.0,\n",
       " 'draw_mean': 0.0,\n",
       " 'weapon_hyp_mean': 0.0,\n",
       " 'sword_mean': 0.0,\n",
       " 'termination_hyp_mean': 0.0,\n",
       " 'kill_mean': 0.0,\n",
       " 'stay_hyp_mean': 0.0,\n",
       " 'abide_mean': 0.0,\n",
       " 'statement_hyp_mean': 0.0,\n",
       " 'answer_mean': 0.0,\n",
       " 'whit_mean': 0.0,\n",
       " 'instrumentality_hyp_mean': 0.0,\n",
       " 'device_mean': 0.0,\n",
       " 'create_verbally_hyp_mean': 0.0,\n",
       " 'write_mean': 0.0,\n",
       " 'ill_health_hyp_mean': 0.0,\n",
       " 'harm_mean': 0.0,\n",
       " 'good_hyp_mean': 0.0,\n",
       " 'well_mean': 0.0,\n",
       " 'certainty_hyp_mean': 0.0,\n",
       " 'assurance_mean': 0.0,\n",
       " 'tell_syn_mean': 0.0,\n",
       " 'tell_mean': 0.0,\n",
       " 'craftsman_hyp_mean': 0.0,\n",
       " 'weaver_mean': 0.0,\n",
       " 'fear_mean': 0.0,\n",
       " 'artist_hyp_mean': 0.0,\n",
       " 'master_mean': 0.0,\n",
       " 'ought_mean': 0.0,\n",
       " 'think_hyp_mean': 0.0,\n",
       " 'consider_mean': 0.0,\n",
       " 'transport_hyp_mean': 0.0,\n",
       " 'bring_mean': 0.0,\n",
       " 'god_syn_mean': 0.0,\n",
       " 'god_mean': 0.0,\n",
       " 'protective_covering_hyp_mean': 0.0,\n",
       " 'shield_mean': 0.0,\n",
       " 'awful_syn_mean': 0.0,\n",
       " 'dreadful_mean': 0.0,\n",
       " 'situation_hyp_mean': 0.0,\n",
       " 'fearful_syn_mean': 0.0,\n",
       " 'fearful_mean': 0.0,\n",
       " 'bird_hyp_mean': 0.0,\n",
       " 'wildfowl_mean': 0.0,\n",
       " 'experience_hyp_mean': 0.0,\n",
       " 'living_mean': 0.0,\n",
       " 'negative_hyp_mean': 0.0,\n",
       " 'nay_mean': 0.0,\n",
       " 'common_fraction_hyp_mean': 0.0,\n",
       " 'half_mean': 0.0,\n",
       " 'DET_mean': 0.0,\n",
       " 'see_mean': 0.0,\n",
       " 'neck_mean': 0.0,\n",
       " 'speech_hyp_mean': 0.0,\n",
       " 'say_mean': 0.0,\n",
       " 'imperfection_hyp_mean': 0.0,\n",
       " 'defect_mean': 0.0,\n",
       " 'show_hyp_mean': 0.0,\n",
       " 'fair_mean': 0.0,\n",
       " 'desire_hyp_mean': 0.0,\n",
       " 'wish_mean': 0.0,\n",
       " 'request_mean': 0.0,\n",
       " 'plead_hyp_mean': 0.0,\n",
       " 'entreat_mean': 0.0,\n",
       " 'reflex_hyp_mean': 0.0,\n",
       " 'tremble_mean': 0.0,\n",
       " 'being_hyp_mean': 0.0,\n",
       " 'life_mean': 0.0,\n",
       " 'deliberation_hyp_mean': 0.0,\n",
       " 'think_mean': 0.0,\n",
       " 'liquid_body_substance_hyp_mean': 0.0,\n",
       " 'come_mean': 0.0,\n",
       " 'here_syn_mean': 0.0,\n",
       " 'hither_mean': 0.0,\n",
       " 'sympathy_hyp_mean': 0.0,\n",
       " 'pity_mean': 0.0,\n",
       " 'force_hyp_mean': 0.0,\n",
       " 'man_mean': 0.0,\n",
       " 'obviously_syn_mean': 0.0,\n",
       " 'plainly_mean': 0.0,\n",
       " 'member_hyp_mean': 0.0,\n",
       " 'joiner_mean': 0.0,\n",
       " 'arrangement_hyp_mean': 0.0,\n",
       " 'calendar_mean': 0.0,\n",
       " 'annual_hyp_mean': 0.0,\n",
       " 'almanac_mean': 0.0,\n",
       " 'insight_hyp_mean': 0.0,\n",
       " 'find_mean': 0.0,\n",
       " 'light_hyp_mean': 0.0,\n",
       " 'moonshine_mean': 0.0,\n",
       " 'time_off_hyp_mean': 0.0,\n",
       " 'leave_mean': 0.0,\n",
       " 'sash_hyp_mean': 0.0,\n",
       " 'casement_mean': 0.0,\n",
       " 'achiever_hyp_mean': 0.0,\n",
       " 'great_mean': 0.0,\n",
       " 'enclosure_hyp_mean': 0.0,\n",
       " 'chamber_mean': 0.0,\n",
       " 'framework_hyp_mean': 0.0,\n",
       " 'window_mean': 0.0,\n",
       " 'area_hyp_mean': 0.0,\n",
       " 'open_mean': 0.0,\n",
       " 'moon_syn_mean': 0.0,\n",
       " 'moon_mean': 0.0,\n",
       " 'time_hyp_mean': 0.0,\n",
       " 'present_mean': 0.0,\n",
       " 'partition_hyp_mean': 0.0,\n",
       " 'wall_mean': 0.0,\n",
       " 'covering_material_hyp_mean': 0.0,\n",
       " 'plaster_mean': 0.0,\n",
       " 'soil_hyp_mean': 0.0,\n",
       " 'loam_mean': 0.0,\n",
       " 'plaster_hyp_mean': 0.0,\n",
       " 'roughcast_mean': 0.0,\n",
       " 'mean_syn_mean': 0.0,\n",
       " 'signify_mean': 0.0,\n",
       " 'digit_hyp_mean': 0.0,\n",
       " 'finger_mean': 0.0,\n",
       " 'depression_hyp_mean': 0.0,\n",
       " 'cranny_mean': 0.0,\n",
       " 'speaking_hyp_mean': 0.0,\n",
       " 'whisper_mean': 0.0,\n",
       " 'angiosperm_hyp_mean': 0.0,\n",
       " 'flower_mean': 0.0,\n",
       " 'abominable_syn_mean': 0.0,\n",
       " 'odious_mean': 0.0,\n",
       " 'taste_hyp_mean': 0.0,\n",
       " 'savor_mean': 0.0,\n",
       " 'sweet_syn_mean': 0.0,\n",
       " 'sweet_mean': 0.0,\n",
       " 'odor_mean': 0.0,\n",
       " 'breath_mean': 0.0,\n",
       " 'listen_hyp_mean': 0.0,\n",
       " 'hark_mean': 0.0,\n",
       " 'stay_mean': 0.0,\n",
       " 'awhile_syn_mean': 0.0,\n",
       " 'awhile_mean': 0.0,\n",
       " 'be_hyp_mean': 0.0,\n",
       " 'appear_mean': 0.0,\n",
       " 'score_hyp_mean': 0.0,\n",
       " 'run_mean': 0.0,\n",
       " 'away_syn_mean': 0.0,\n",
       " 'away_mean': 0.0,\n",
       " 'wrongdoing_hyp_mean': 0.0,\n",
       " 'knavery_mean': 0.0,\n",
       " 'afeard_syn_mean': 0.0,\n",
       " 'afeard_mean': 0.0,\n",
       " 'body_part_hyp_mean': 0.0,\n",
       " 'ass_mean': 0.0,\n",
       " 'head_mean': 0.0,\n",
       " 'disturbance_hyp_mean': 0.0,\n",
       " 'stir_mean': 0.0,\n",
       " 'point_hyp_mean': 0.0,\n",
       " 'place_mean': 0.0,\n",
       " 'locomotion_hyp_mean': 0.0,\n",
       " 'walk_mean': 0.0,\n",
       " 'interpret_hyp_mean': 0.0,\n",
       " 'sing_mean': 0.0,\n",
       " 'afraid_syn_mean': 0.0,\n",
       " 'afraid_mean': 0.0,\n",
       " 'ouzel_mean': 0.0,\n",
       " 'penis_hyp_mean': 0.0,\n",
       " 'cock_mean': 0.0,\n",
       " 'achromatic_color_hyp_mean': 0.0,\n",
       " 'black_mean': 0.0,\n",
       " 'color_property_hyp_mean': 0.0,\n",
       " 'hue_mean': 0.0,\n",
       " 'legal_document_hyp_mean': 0.0,\n",
       " 'bill_mean': 0.0,\n",
       " 'spinning_machine_hyp_mean': 0.0,\n",
       " 'throstle_mean': 0.0,\n",
       " 'written_record_hyp_mean': 0.0,\n",
       " 'note_mean': 0.0,\n",
       " 'wren_syn_mean': 0.0,\n",
       " 'wren_mean': 0.0,\n",
       " 'pen_hyp_mean': 0.0,\n",
       " 'quill_mean': 0.0,\n",
       " 'oscine_hyp_mean': 0.0,\n",
       " 'finch_mean': 0.0,\n",
       " 'passerine_hyp_mean': 0.0,\n",
       " 'sparrow_mean': 0.0,\n",
       " 'new_world_oriole_hyp_mean': 0.0,\n",
       " 'lark_mean': 0.0,\n",
       " 'chant_hyp_mean': 0.0,\n",
       " 'plainsong_mean': 0.0,\n",
       " 'fool_hyp_mean': 0.0,\n",
       " 'cuckoo_mean': 0.0,\n",
       " 'gray_mean': 0.0,\n",
       " 'evaluation_hyp_mean': 0.0,\n",
       " 'mark_mean': 0.0,\n",
       " 'challenge_hyp_mean': 0.0,\n",
       " 'dare_mean': 0.0,\n",
       " 'collection_hyp_mean': 0.0,\n",
       " 'set_mean': 0.0,\n",
       " 'vertebrate_hyp_mean': 0.0,\n",
       " 'bird_mean': 0.0,\n",
       " 'falsehood_hyp_mean': 0.0,\n",
       " 'lie_mean': 0.0,\n",
       " 'utterance_hyp_mean': 0.0,\n",
       " 'cry_mean': 0.0,\n",
       " 'mistress_mean': 0.0,\n",
       " 'rational_motive_hyp_mean': 0.0,\n",
       " 'reason_mean': 0.0,\n",
       " 'fact_hyp_mean': 0.0,\n",
       " 'truth_mean': 0.0,\n",
       " 'love_mean': 0.0,\n",
       " 'institution_hyp_mean': 0.0,\n",
       " 'company_mean': 0.0,\n",
       " 'nowadays_mean': 0.0,\n",
       " 'honest_syn_mean': 0.0,\n",
       " 'honest_mean': 0.0,\n",
       " 'neighbor_mean': 0.0,\n",
       " 'disrespect_hyp_mean': 0.0,\n",
       " 'insult_mean': 0.0,\n",
       " 'occasion_mean': 0.0,\n",
       " 'plant_material_hyp_mean': 0.0,\n",
       " 'wood_mean': 0.0,\n",
       " 'tennis_stroke_hyp_mean': 0.0,\n",
       " 'serve_mean': 0.0,\n",
       " 'curve_hyp_mean': 0.0,\n",
       " 'turn_mean': 0.0,\n",
       " 'worships_mean': 0.0,\n",
       " 'lenience_hyp_mean': 0.0,\n",
       " 'mercy_mean': 0.0,\n",
       " 'heartily_syn_mean': 0.0,\n",
       " 'heartily_mean': 0.0,\n",
       " 'beseech_mean': 0.0,\n",
       " 'worship_mean': 0.0,\n",
       " 'feeling_hyp_mean': 0.0,\n",
       " 'desire_mean': 0.0,\n",
       " 'information_hyp_mean': 0.0,\n",
       " 'acquaintance_mean': 0.0,\n",
       " 'font_hyp_mean': 0.0,\n",
       " 'bold_mean': 0.0,\n",
       " 'commune_hyp_mean': 0.0,\n",
       " 'pray_mean': 0.0,\n",
       " 'praise_hyp_mean': 0.0,\n",
       " 'commend_mean': 0.0,\n",
       " 'vine_hyp_mean': 0.0,\n",
       " 'squash_mean': 0.0,\n",
       " 'peascod_mean': 0.0,\n",
       " 'man_hyp_mean': 0.0,\n",
       " 'sir_mean': 0.0,\n",
       " 'crucifer_hyp_mean': 0.0,\n",
       " 'mustard_mean': 0.0,\n",
       " 'fruit_hyp_mean': 0.0,\n",
       " 'seed_mean': 0.0,\n",
       " 'knowing_hyp_mean': 0.0,\n",
       " 'know_mean': 0.0,\n",
       " 'cowardly_syn_mean': 0.0,\n",
       " 'cowardly_mean': 0.0,\n",
       " 'animal_hyp_mean': 0.0,\n",
       " 'giant_mean': 0.0,\n",
       " 'kind_hyp_mean': 0.0,\n",
       " 'like_mean': 0.0,\n",
       " 'SCONJ_mean': 0.0,\n",
       " 'cattle_hyp_mean': 0.0,\n",
       " 'ox_mean': 0.0,\n",
       " 'beef_mean': 0.0,\n",
       " 'destroy_hyp_mean': 0.0,\n",
       " 'devour_mean': 0.0,\n",
       " 'building_hyp_mean': 0.0,\n",
       " 'house_mean': 0.0,\n",
       " 'commitment_hyp_mean': 0.0,\n",
       " 'promise_mean': 0.0,\n",
       " 'social_group_hyp_mean': 0.0,\n",
       " 'kindred_mean': 0.0,\n",
       " 'binary_compound_hyp_mean': 0.0,\n",
       " 'water_mean': 0.0,\n",
       " 'wound_hyp_mean': 0.0,\n",
       " 'scratch_mean': 0.0,\n",
       " 'monsieur_mean': 0.0,\n",
       " 'instrument_hyp_mean': 0.0,\n",
       " 'weapon_mean': 0.0,\n",
       " 'extremity_hyp_mean': 0.0,\n",
       " 'hand_mean': 0.0,\n",
       " 'red_mean': 0.0,\n",
       " 'hipped_syn_mean': 0.0,\n",
       " 'hippe_mean': 0.0,\n",
       " 'humble_mean': 0.0,\n",
       " 'hymenopterous_insect_hyp_mean': 0.0,\n",
       " 'bee_mean': 0.0,\n",
       " 'weed_hyp_mean': 0.0,\n",
       " 'thistle_mean': 0.0,\n",
       " 'sweetening_hyp_mean': 0.0,\n",
       " 'honey_mean': 0.0,\n",
       " 'container_hyp_mean': 0.0,\n",
       " 'bag_mean': 0.0,\n",
       " 'agitation_hyp_mean': 0.0,\n",
       " 'fret_mean': 0.0,\n",
       " 'action_mean': 0.0,\n",
       " 'work_hyp_mean': 0.0,\n",
       " 'care_mean': 0.0,\n",
       " 'loath_syn_mean': 0.0,\n",
       " 'loath_mean': 0.0,\n",
       " 'spill_hyp_mean': 0.0,\n",
       " 'overflown_mean': 0.0,\n",
       " 'signior_mean': 0.0,\n",
       " 'politeness_hyp_mean': 0.0,\n",
       " 'courtesy_mean': 0.0,\n",
       " 'help_mean': 0.0,\n",
       " 'military_personnel_hyp_mean': 0.0,\n",
       " 'cavalry_mean': 0.0,\n",
       " 'barber_syn_mean': 0.0,\n",
       " 'barber_mean': 0.0,\n",
       " 'marvel_mean': 0.0,\n",
       " 'hairy_syn_mean': 0.0,\n",
       " 'hairy_mean': 0.0,\n",
       " 'medium_of_exchange_hyp_mean': 0.0,\n",
       " 'tender_mean': 0.0,\n",
       " 'body_covering_hyp_mean': 0.0,\n",
       " 'hair_mean': 0.0,\n",
       " 'cutaneous_sensation_hyp_mean': 0.0,\n",
       " 'tickle_mean': 0.0,\n",
       " 'reasonable_syn_mean': 0.0,\n",
       " 'reasonable_mean': 0.0,\n",
       " 'sense_organ_hyp_mean': 0.0,\n",
       " 'ear_mean': 0.0,\n",
       " 'auditory_communication_hyp_mean': 0.0,\n",
       " 'music_mean': 0.0,\n",
       " 'device_hyp_mean': 0.0,\n",
       " 'tong_mean': 0.0,\n",
       " 'percussion_instrument_hyp_mean': 0.0,\n",
       " 'bone_mean': 0.0,\n",
       " 'truly_syn_mean': 0.0,\n",
       " 'truly_mean': 0.0,\n",
       " 'large_indefinite_quantity_hyp_mean': 0.0,\n",
       " 'peck_mean': 0.0,\n",
       " 'food_hyp_mean': 0.0,\n",
       " 'provender_mean': 0.0,\n",
       " 'munch_syn_mean': 0.0,\n",
       " 'munch_mean': 0.0,\n",
       " 'reformer_hyp_mean': 0.0,\n",
       " 'dry_mean': 0.0,\n",
       " 'cereal_hyp_mean': 0.0,\n",
       " 'oats_mean': 0.0,\n",
       " 'vessel_hyp_mean': 0.0,\n",
       " 'bottle_mean': 0.0,\n",
       " 'fodder_hyp_mean': 0.0,\n",
       " 'hay_mean': 0.0,\n",
       " 'male_hyp_mean': 0.0,\n",
       " 'fellow_mean': 0.0,\n",
       " 'handful_mean': 0.0,\n",
       " 'legume_hyp_mean': 0.0,\n",
       " 'pea_mean': 0.0,\n",
       " 'group_hyp_mean': 0.0,\n",
       " 'people_mean': 0.0,\n",
       " 'interpretation_hyp_mean': 0.0,\n",
       " 'exposition_mean': 0.0,\n",
       " 'physical_condition_hyp_mean': 0.0,\n",
       " 'sleep_mean': 0.0,\n",
       " \"actor's_line_hyp_mean\": 0.0,\n",
       " 'cue_mean': 0.0,\n",
       " 'hey_mean': 0.0,\n",
       " 'metallic_element_hyp_mean': 0.0,\n",
       " 'ho_mean': 0.0,\n",
       " 'blower_hyp_mean': 0.0,\n",
       " 'bellow_mean': 0.0,\n",
       " 'skilled_worker_hyp_mean': 0.0,\n",
       " 'mender_mean': 0.0,\n",
       " 'experimenter_hyp_mean': 0.0,\n",
       " 'tinker_mean': 0.0,\n",
       " 'take_hyp_mean': 0.0,\n",
       " 'steal_mean': 0.0,\n",
       " 'position_hyp_mean': 0.0,\n",
       " 'asleep_syn_mean': 0.0,\n",
       " 'asleep_mean': 0.0,\n",
       " 'rare_syn_mean': 0.0,\n",
       " 'rare_mean': 0.0,\n",
       " 'imagination_hyp_mean': 0.0,\n",
       " 'vision_mean': 0.0,\n",
       " 'dream_mean': 0.0,\n",
       " 'past_mean': 0.0,\n",
       " 'ADP_mean': 0.0,\n",
       " 'clarify_hyp_mean': 0.0,\n",
       " 'expound_mean': 0.0,\n",
       " 'content_hyp_mean': 0.0,\n",
       " 'join_hyp_mean': 0.0,\n",
       " 'patched_mean': 0.0,\n",
       " 'speech_act_hyp_mean': 0.0,\n",
       " 'offer_mean': 0.0,\n",
       " 'able_syn_mean': 0.0,\n",
       " 'able_mean': 0.0,\n",
       " 'sensation_hyp_mean': 0.0,\n",
       " 'taste_mean': 0.0,\n",
       " 'articulator_hyp_mean': 0.0,\n",
       " 'tongue_mean': 0.0,\n",
       " 'create_by_mental_act_hyp_mean': 0.0,\n",
       " 'conceive_mean': 0.0,\n",
       " 'document_hyp_mean': 0.0,\n",
       " 'report_mean': 0.0,\n",
       " 'song_hyp_mean': 0.0,\n",
       " 'ballad_mean': 0.0,\n",
       " 'label_hyp_mean': 0.0,\n",
       " 'call_mean': 0.0,\n",
       " 'end_mean': 0.0,\n",
       " 'doubt_hyp_mean': 0.0,\n",
       " 'peradventure_mean': 0.0,\n",
       " 'gracious_syn_mean': 0.0,\n",
       " 'gracious_mean': 0.0,\n",
       " 'death_mean': 0.0,\n",
       " 'lad_mean': 0.0,\n",
       " 'whist_hyp_mean': 0.0,\n",
       " 'language_unit_hyp_mean': 0.0,\n",
       " 'discourse_mean': 0.0,\n",
       " 'astonishment_hyp_mean': 0.0,\n",
       " 'wonder_mean': 0.0,\n",
       " 'greek_hyp_mean': 0.0,\n",
       " 'athenian_mean': 0.0,\n",
       " 'abstraction_hyp_mean': 0.0,\n",
       " 'right_mean': 0.0,\n",
       " 'fall_mean': 0.0,\n",
       " 'word_mean': 0.0,\n",
       " 'eat_hyp_mean': 0.0,\n",
       " 'dine_mean': 0.0,\n",
       " 'clothing_hyp_mean': 0.0,\n",
       " 'apparel_mean': 0.0,\n",
       " 'section_hyp_mean': 0.0,\n",
       " 'string_mean': 0.0,\n",
       " 'new_syn_mean': 0.0,\n",
       " 'new_mean': 0.0,\n",
       " 'object_hyp_mean': 0.0,\n",
       " 'ribbon_mean': 0.0,\n",
       " 'mechanical_device_hyp_mean': 0.0,\n",
       " 'pump_mean': 0.0,\n",
       " 'soon_syn_mean': 0.0,\n",
       " 'presently_mean': 0.0,\n",
       " 'mansion_hyp_mean': 0.0,\n",
       " 'palace_mean': 0.0,\n",
       " 'tract_hyp_mean': 0.0,\n",
       " 'short_mean': 0.0,\n",
       " 'long_mean': 0.0,\n",
       " 'like_hyp_mean': 0.0,\n",
       " 'prefer_mean': 0.0,\n",
       " 'case_mean': 0.0,\n",
       " 'weightlift_hyp_mean': 0.0,\n",
       " 'clean_mean': 0.0,\n",
       " 'fabric_hyp_mean': 0.0,\n",
       " 'linen_mean': 0.0,\n",
       " 'decrease_hyp_mean': 0.0,\n",
       " 'pare_mean': 0.0,\n",
       " 'horny_structure_hyp_mean': 0.0,\n",
       " 'nail_mean': 0.0,\n",
       " 'claws_mean': 0.0,\n",
       " 'consume_hyp_mean': 0.0,\n",
       " 'eat_mean': 0.0,\n",
       " 'bulb_hyp_mean': 0.0,\n",
       " 'onion_mean': 0.0,\n",
       " 'alliaceous_plant_hyp_mean': 0.0,\n",
       " 'garlic_mean': 0.0,\n",
       " 'express_syn_mean': 0.0,\n",
       " 'utter_mean': 0.0,\n",
       " 'cognitive_state_hyp_mean': 0.0,\n",
       " 'doubt_mean': 0.0,\n",
       " 'grim_syn_mean': 0.0,\n",
       " 'grim_mean': 0.0,\n",
       " 'time_period_hyp_mean': 0.0,\n",
       " 'night_mean': 0.0,\n",
       " 'creation_hyp_mean': 0.0,\n",
       " 'art_mean': 0.0,\n",
       " 'time_unit_hyp_mean': 0.0,\n",
       " 'day_mean': 0.0,\n",
       " 'process_hyp_mean': 0.0,\n",
       " 'alas_mean': 0.0,\n",
       " 'forget_syn_mean': 0.0,\n",
       " 'forgot_mean': 0.0,\n",
       " \"photographer's_model_hyp_mean\": 0.0,\n",
       " 'lovely_mean': 0.0,\n",
       " 'support_hyp_mean': 0.0,\n",
       " 'stand_mean': 0.0,\n",
       " 'ground_mean': 0.0,\n",
       " 'chinese_hyp_mean': 0.0,\n",
       " 'chink_mean': 0.0,\n",
       " 'blink_mean': 0.0,\n",
       " 'acknowledgment_hyp_mean': 0.0,\n",
       " 'thank_mean': 0.0,\n",
       " 'courteous_syn_mean': 0.0,\n",
       " 'courteous_mean': 0.0,\n",
       " 'jupiter_syn_mean': 0.0,\n",
       " 'jove_mean': 0.0,\n",
       " 'wicked_syn_mean': 0.0,\n",
       " 'wicked_mean': 0.0,\n",
       " 'elation_hyp_mean': 0.0,\n",
       " 'bliss_mean': 0.0,\n",
       " 'express_hyp_mean': 0.0,\n",
       " 'cursed_mean': 0.0,\n",
       " 'stone_mean': 0.0,\n",
       " 'victimize_hyp_mean': 0.0,\n",
       " 'deceive_mean': 0.0,\n",
       " 'enter_syn_mean': 0.0,\n",
       " 'enter_mean': 0.0,\n",
       " 'secret_agent_hyp_mean': 0.0,\n",
       " 'spy_mean': 0.0,\n",
       " 'season_hyp_mean': 0.0,\n",
       " 'pat_mean': 0.0,\n",
       " 'yonder_syn_mean': 0.0,\n",
       " 'yonder_mean': 0.0,\n",
       " 'plant_disease_hyp_mean': 0.0,\n",
       " 'wilt_mean': 0.0,\n",
       " 'state_hyp_mean': 0.0,\n",
       " 'grace_mean': 0.0,\n",
       " 'limander_mean': 0.0,\n",
       " 'convict_hyp_mean': 0.0,\n",
       " 'trusty_mean': 0.0,\n",
       " 'shafalus_mean': 0.0,\n",
       " 'procrus_mean': 0.0,\n",
       " 'touch_hyp_mean': 0.0,\n",
       " 'kiss_mean': 0.0,\n",
       " 'opening_hyp_mean': 0.0,\n",
       " 'hole_mean': 0.0,\n",
       " 'despicable_syn_mean': 0.0,\n",
       " 'vile_mean': 0.0,\n",
       " 'simpleton_hyp_mean': 0.0,\n",
       " 'ninny_mean': 0.0,\n",
       " 'topographic_point_hyp_mean': 0.0,\n",
       " 'tomb_mean': 0.0,\n",
       " 'straightway_syn_mean': 0.0,\n",
       " 'straightway_mean': 0.0,\n",
       " 'convey_hyp_mean': 0.0,\n",
       " 'cheery_syn_mean': 0.0,\n",
       " 'sunny_mean': 0.0,\n",
       " 'signal_hyp_mean': 0.0,\n",
       " 'beam_mean': 0.0,\n",
       " 'bright_syn_mean': 0.0,\n",
       " 'bright_mean': 0.0,\n",
       " 'aureate_syn_mean': 0.0,\n",
       " 'golden_mean': 0.0,\n",
       " 'look_hyp_mean': 0.0,\n",
       " 'glitter_mean': 0.0,\n",
       " 'radiance_hyp_mean': 0.0,\n",
       " 'gleam_mean': 0.0,\n",
       " 'trust_mean': 0.0,\n",
       " 'visual_percept_hyp_mean': 0.0,\n",
       " 'sight_mean': 0.0,\n",
       " 'malevolence_hyp_mean': 0.0,\n",
       " 'spite_mean': 0.0,\n",
       " 'people_hyp_mean': 0.0,\n",
       " 'poor_mean': 0.0,\n",
       " 'dole_mean': 0.0,\n",
       " 'dainty_mean': 0.0,\n",
       " 'anseriform_bird_hyp_mean': 0.0,\n",
       " 'duck_mean': 0.0,\n",
       " 'mantle_mean': 0.0,\n",
       " 'dye_hyp_mean': 0.0,\n",
       " 'stain_mean': 0.0,\n",
       " 'blood_mean': 0.0,\n",
       " 'conceptualization_hyp_mean': 0.0,\n",
       " 'approach_mean': 0.0,\n",
       " 'anger_hyp_mean': 0.0,\n",
       " 'furies_mean': 0.0,\n",
       " 'thread_mean': 0.0,\n",
       " 'thrum_mean': 0.0,\n",
       " 'wildfowl_hyp_mean': 0.0,\n",
       " 'quail_mean': 0.0,\n",
       " 'leather_hyp_mean': 0.0,\n",
       " 'crush_mean': 0.0,\n",
       " 'conclude_mean': 0.0,\n",
       " 'suppress_hyp_mean': 0.0,\n",
       " 'quell_mean': 0.0,\n",
       " 'reason_hyp_mean': 0.0,\n",
       " 'wherefore_mean': 0.0,\n",
       " 'quality_hyp_mean': 0.0,\n",
       " 'nature_mean': 0.0,\n",
       " 'frame_mean': 0.0,\n",
       " 'copulate_hyp_mean': 0.0,\n",
       " 'deflower_mean': 0.0,\n",
       " 'girl_hyp_mean': 0.0,\n",
       " 'dame_mean': 0.0,\n",
       " 'live_mean': 0.0,\n",
       " 'approval_hyp_mean': 0.0,\n",
       " 'cheer_mean': 0.0,\n",
       " 'confound_mean': 0.0,\n",
       " 'injury_hyp_mean': 0.0,\n",
       " 'wound_mean': 0.0,\n",
       " 'drivel_hyp_mean': 0.0,\n",
       " 'pap_mean': 0.0,\n",
       " 'ay_mean': 0.0,\n",
       " 'jump_hyp_mean': 0.0,\n",
       " 'hop_mean': 0.0,\n",
       " 'cube_hyp_mean': 0.0,\n",
       " 'die_mean': 0.0,\n",
       " 'dead_mean': 0.0,\n",
       " 'scat_hyp_mean': 0.0,\n",
       " 'flee_mean': 0.0,\n",
       " 'spirit_hyp_mean': 0.0,\n",
       " 'soul_mean': 0.0,\n",
       " 'atmosphere_hyp_mean': 0.0,\n",
       " 'sky_mean': 0.0,\n",
       " 'lose_syn_mean': 0.0,\n",
       " 'lose_mean': 0.0,\n",
       " 'actinic_radiation_hyp_mean': 0.0,\n",
       " 'light_mean': 0.0,\n",
       " 'formation_hyp_mean': 0.0,\n",
       " 'flight_mean': 0.0,\n",
       " 'move_hyp_mean': 0.0,\n",
       " 'part_mean': 0.0,\n",
       " 'parent_hyp_mean': 0.0,\n",
       " 'father_mean': 0.0,\n",
       " 'conclusion_hyp_mean': 0.0,\n",
       " 'epilogue_mean': 0.0,\n",
       " 'bergomask_mean': 0.0,\n",
       " 'art_hyp_mean': 0.0,\n",
       " 'dance_mean': 0.0,\n",
       " 'philomel_mean': 0.0,\n",
       " 'music_hyp_mean': 0.0,\n",
       " 'melody_mean': 0.0,\n",
       " 'lullaby_mean': 0.0,\n",
       " 'lulla_mean': 0.0,\n",
       " 'psychological_state_hyp_mean': 0.0,\n",
       " 'spell_mean': 0.0,\n",
       " 'attractiveness_hyp_mean': 0.0,\n",
       " 'charm_mean': 0.0,\n",
       " 'near_syn_mean': 0.0,\n",
       " 'nigh_mean': 0.0,\n",
       " 'precipitation_hyp_mean': 0.0,\n",
       " 'hail_mean': 0.0,\n",
       " 'yield_syn_mean': 0.0,\n",
       " 'relent_mean': 0.0,\n",
       " 'production_hyp_mean': 0.0,\n",
       " 'yield_mean': 0.0,\n",
       " 'madden_syn_mean': 0.0,\n",
       " 'crazed_mean': 0.0,\n",
       " 'heading_hyp_mean': 0.0,\n",
       " 'title_mean': 0.0,\n",
       " 'certain_syn_mean': 0.0,\n",
       " 'certain_mean': 0.0,\n",
       " 'pursue_mean': 0.0,\n",
       " 'foundation_garment_hyp_mean': 0.0,\n",
       " 'unto_mean': 0.0,\n",
       " 'shift_hyp_mean': 0.0,\n",
       " 'go_mean': 0.0,\n",
       " 'travel_hyp_mean': 0.0,\n",
       " 'follow_mean': 0.0,\n",
       " 'provoke_hyp_mean': 0.0,\n",
       " 'entice_mean': 0.0,\n",
       " 'land_hyp_mean': 0.0,\n",
       " 'plain_mean': 0.0,\n",
       " 'invite_hyp_mean': 0.0,\n",
       " 'tempt_mean': 0.0,\n",
       " 'hatred_mean': 0.0,\n",
       " 'sick_mean': 0.0,\n",
       " 'impeach_mean': 0.0,\n",
       " 'decency_hyp_mean': 0.0,\n",
       " 'modesty_mean': 0.0,\n",
       " 'municipality_hyp_mean': 0.0,\n",
       " 'city_mean': 0.0,\n",
       " 'commit_mean': 0.0,\n",
       " 'guardianship_hyp_mean': 0.0,\n",
       " 'possibility_hyp_mean': 0.0,\n",
       " 'opportunity_mean': 0.0,\n",
       " 'disorder_hyp_mean': 0.0,\n",
       " 'ill_mean': 0.0,\n",
       " 'lawyer_hyp_mean': 0.0,\n",
       " 'counsel_mean': 0.0,\n",
       " 'biome_hyp_mean': 0.0,\n",
       " 'desert_mean': 0.0,\n",
       " 'rich_mean': 0.0,\n",
       " 'indefinite_quantity_hyp_mean': 0.0,\n",
       " 'worth_mean': 0.0,\n",
       " 'condition_hyp_mean': 0.0,\n",
       " 'virginity_mean': 0.0,\n",
       " 'brake_hyp_mean': 0.0,\n",
       " 'brake_mean': 0.0,\n",
       " 'wild_mean': 0.0,\n",
       " 'organism_hyp_mean': 0.0,\n",
       " 'beast_mean': 0.0,\n",
       " 'questioning_hyp_mean': 0.0,\n",
       " 'question_mean': 0.0,\n",
       " 'accept_hyp_mean': 0.0,\n",
       " 'believe_mean': 0.0,\n",
       " 'misbehavior_hyp_mean': 0.0,\n",
       " 'mischief_mean': 0.0,\n",
       " 'attack_hyp_mean': 0.0,\n",
       " 'charge_mean': 0.0,\n",
       " 'haunt_mean': 0.0,\n",
       " 'danger_hyp_mean': 0.0,\n",
       " 'peril_mean': 0.0,\n",
       " 'criticism_hyp_mean': 0.0,\n",
       " 'rebuke_mean': 0.0,\n",
       " 'lay_mean': 0.0,\n",
       " 'ale_hyp_mean': 0.0,\n",
       " 'bitter_mean': 0.0,\n",
       " 'adversary_hyp_mean': 0.0,\n",
       " 'foe_mean': 0.0,\n",
       " 'kill_hyp_mean': 0.0,\n",
       " 'murdered_mean': 0.0,\n",
       " 'penetrate_hyp_mean': 0.0,\n",
       " 'pierce_mean': 0.0,\n",
       " 'rear_hyp_mean': 0.0,\n",
       " 'stern_mean': 0.0,\n",
       " 'maltreatment_hyp_mean': 0.0,\n",
       " 'cruelty_mean': 0.0,\n",
       " 'innocence_hyp_mean': 0.0,\n",
       " 'clear_mean': 0.0,\n",
       " 'venus_syn_mean': 0.0,\n",
       " 'venus_mean': 0.0,\n",
       " 'suggestion_hyp_mean': 0.0,\n",
       " 'glimmering_mean': 0.0,\n",
       " 'environment_hyp_mean': 0.0,\n",
       " 'sphere_mean': 0.0,\n",
       " 'body_hyp_mean': 0.0,\n",
       " 'carcass_mean': 0.0,\n",
       " 'hunting_dog_hyp_mean': 0.0,\n",
       " 'hound_mean': 0.0,\n",
       " 'spend_syn_mean': 0.0,\n",
       " 'spend_mean': 0.0,\n",
       " 'passion_mean': 0.0,\n",
       " 'identify_hyp_mean': 0.0,\n",
       " 'mistaken_mean': 0.0,\n",
       " 'mood_mean': 0.0,\n",
       " 'guilty_syn_mean': 0.0,\n",
       " 'guilty_mean': 0.0,\n",
       " 'relative_quantity_hyp_mean': 0.0,\n",
       " 'aught_mean': 0.0,\n",
       " 'therefor_syn_mean': 0.0,\n",
       " 'therefor_mean': 0.0,\n",
       " 'multitude_hyp_mean': 0.0,\n",
       " 'ferocious_syn_mean': 0.0,\n",
       " 'fierce_mean': 0.0,\n",
       " 'remain_mean': 0.0,\n",
       " 'sadness_hyp_mean': 0.0,\n",
       " 'sorrow_mean': 0.0,\n",
       " 'weight_hyp_mean': 0.0,\n",
       " 'heaviness_mean': 0.0,\n",
       " 'heavy_syn_mean': 0.0,\n",
       " 'heavier_mean': 0.0,\n",
       " 'indebtedness_hyp_mean': 0.0,\n",
       " 'debt_mean': 0.0,\n",
       " 'failure_hyp_mean': 0.0,\n",
       " 'bankrupt_mean': 0.0,\n",
       " 'owe_syn_mean': 0.0,\n",
       " 'owe_mean': 0.0,\n",
       " 'discourtesy_hyp_mean': 0.0,\n",
       " 'slight_mean': 0.0,\n",
       " 'regular_payment_hyp_mean': 0.0,\n",
       " 'pay_mean': 0.0,\n",
       " 'deity_hyp_mean': 0.0,\n",
       " 'goddess_mean': 0.0,\n",
       " 'greco-roman_deity_hyp_mean': 0.0,\n",
       " 'nymph_mean': 0.0,\n",
       " 'tense_hyp_mean': 0.0,\n",
       " 'perfect_mean': 0.0,\n",
       " 'godhead_syn_mean': 0.0,\n",
       " 'divine_mean': 0.0,\n",
       " 'likeness_hyp_mean': 0.0,\n",
       " 'compare_mean': 0.0,\n",
       " 'solid_hyp_mean': 0.0,\n",
       " 'crystal_mean': 0.0,\n",
       " 'dirty_hyp_mean': 0.0,\n",
       " 'muddy_mean': 0.0,\n",
       " 'ripe_syn_mean': 0.0,\n",
       " 'ripe_mean': 0.0,\n",
       " 'lip_mean': 0.0,\n",
       " 'foreplay_hyp_mean': 0.0,\n",
       " 'wood_hyp_mean': 0.0,\n",
       " 'cherry_mean': 0.0,\n",
       " 'pure_syn_mean': 0.0,\n",
       " 'pure_mean': 0.0,\n",
       " 'solidify_hyp_mean': 0.0,\n",
       " 'congealed_mean': 0.0,\n",
       " 'white_mean': 0.0,\n",
       " 'degree_hyp_mean': 0.0,\n",
       " 'high_mean': 0.0,\n",
       " 'snow_mean': 0.0,\n",
       " 'strike_out_hyp_mean': 0.0,\n",
       " 'fan_mean': 0.0,\n",
       " 'eastern_syn_mean': 0.0,\n",
       " 'eastern_mean': 0.0,\n",
       " 'weather_hyp_mean': 0.0,\n",
       " 'wind_mean': 0.0,\n",
       " 'corvine_bird_hyp_mean': 0.0,\n",
       " 'crow_mean': 0.0,\n",
       " 'seal_mean': 0.0,\n",
       " 'visitor_hyp_mean': 0.0,\n",
       " 'guest_mean': 0.0,\n",
       " 'manner_hyp_mean': 0.0,\n",
       " 'wise_mean': 0.0,\n",
       " 'spend_hyp_mean': 0.0,\n",
       " 'sojourn_mean': 0.0,\n",
       " 'residence_hyp_mean': 0.0,\n",
       " 'home_mean': 0.0,\n",
       " 'return_mean': 0.0,\n",
       " 'knock_hyp_mean': 0.0,\n",
       " ...}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c2e0e29-df8b-4828-b11b-bd0d189d92fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(random_state = 42)\n",
    "Z_train = pca.fit_transform(Xs_train)\n",
    "Z_test = pca.transform(Xs_test)\n",
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a2d5f9d-c2fc-4e23-88b4-8953e3639498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA1LklEQVR4nO3dd3xV5f3A8c83k5FAgIQ9gggiyI64Le4tVuvAQbFaa11V2/5qt62ttVarttoiIop1ay2ixVUXKipL9pAVIawEQjbZ398f54lcY8ZJzM1J7v2+X6/7yrln3e9z78353vM85zyPqCrGGGOiV0zQARhjjAmWJQJjjIlylgiMMSbKWSIwxpgoZ4nAGGOinCUCY4yJcpYIDAAicruIPPkNtl8tIpNaLqLwEpFMETnZ57pFInJQGGKYJiIftvR+63mt40RkfWu8ll8icoyIbHDv73lBxxPNLBEETEQuFZHF7p9hp4i8JiLHBh1XQ0TkcRH5Q+g8VR2pqu+18Ouki4i69yb0cXFLvk5jVDVJVTe31uuJSAcRyRORE+tYdp+IvNjUfarqB6p6SMtE2GJ+Dzzo3t8533Rn7ntZ7r4juSLylogMD1k+TEReEJE9IpIvIitE5FYRiQ1Zp7Pbft43jac9sUQQIBG5FbgfuBPoBQwE/gFMDjCstijFHSxqHs8FHVA4qWop8BwwNXS+O2BNAWY3ZX8iEtdy0bWoQcDq5mzYQJnuVtUkoD+QDTzu1h8CfApsA0apalfgQiADSA7Z/jtAGXCqiPRpTmztkqraI4AH0BUoAi5sYJ3HgT+EPJ8EZIU8zwR+CqwAioFH8RLKa0Ah8D+gW13bhmx/spu+HXgyZNkLwC4gH5gPjHTzrwEqgHIX/yuh+wL6AvuB7iH7GgfsAeLd8+8Ba4F9wBvAoHrKnw4oEFfHsgRgGXCjex4LfAT8JqQ8L+IdUAuBpcCYeso+EfgYyAN2Ag8CCSHrKnBwyGfyEPBft99PgSEh6w4H3gJygfXARSHLegBzgQJgIXAH8GE9ZT/a7b9TyLwz8Q5uccCV7j0sBDYDP6j9PQF+5j7Df9X+/IHbgE1u+zXAt0OWTQM+BO5xn9EW4IyQ5d2Bx4AdbvmckGVnu88lD1gAjK6nfJuAavddKQIS3XdnrnvvNgLfD1m/5vN80r1/V/v4fzkLKHLTTwL/9fF/+Q7wR/d9+UnQx4nWetgZQXCOAjoA//mG+7kAOAUYBpyDlwR+AaTinfHd1Mz9vgYMBXri/VM8BaCqM9z03er9Oj8ndCNV3YF3UL0gZPalwIuqWuHqgn8BnA+kAR8AzzQ1OFUtBy4Hfi8ih+Id2GLx/olrTMZLaN2Bp4E5IhJfx+6qgFvw3rOjgJOA6xp4+SnA74BueAesP4JXrYCXBJ7Ge9+mAP8QkZFuu4eAUqAPXjL8XgPlW4CXlM4PmX0F8LSqVuIlhLOBLnhJ4T4RGR+ybm9X7kF4ybu2TcBxeD9Ifgc8WesX8BF4iSwVuBt4VETELfsX0AkY6cp5nyv/eGAW8AO8pPcwMFdEEuso3xBgK3CO+x6V4X0PsvASwneAO0XkpJDNJuMlgxTc97E+IpIEXAZ85mad7LZtaJuBeAnzKfeY2tD6ESXoTBStD7wv6a5G1nmcxs8ILgt5/m/gnyHPb8T9Wqu9bcj2dZ4R1FovBe9Xcde64qpjX1cD77hpwTsdP949fw24KmS7GKCEOs4KOHBGkFfrcWjIOj8G1uH9Mh0aMv924JNar7MTOK52vHW87s3Af0Ke1z4jmBmy7ExgnZu+GPig1r4eBn6Ll6QqgOEhy+6knjMCt/xXwJtuuot7n8bVs+4c4Echn3U50KG+704d2y8DJrvpacDGkGWd3HvQGy+JVePONGvt45/AHbXmrQe+Vc9rhn5nBuAl5OSQ5X8CHg/5POf7+H8pdd+RXXhnF0Pcsgrg9Ea2/xWwzE33dfHU+X5H2sPOCIKzF0htgfrb3SHT++t4ntTUHYpIrIjcJSKbRKQA7x8WvF+HfrwIHCUifYHj8Q4iH7hlg4AHXGNoHl41gAD9GthfqqqmhDzWhiybjZcw5qnqhlrbbauZUNVqDvza/ArXiPiqiOxy5b2zkbLuCpku4cB7PAg4oqZsrnyX4R1A0/CqdLaFbPtFA68B8ARwgoj0w/uFvFFVP3MxnyEin7hG0Ty8hBQac456bQ11EpGpIrIsJM7Dam3/ZRlVtcRNJuEdsHNVdV8dux0E/LhW+QdQx3teh75uv4Uh877gq9+LbTTuHvcd6a2q56rqJjd/L14Sa8hUDpz57gDeB77r4zXbPUsEwfkY79fLeQ2sU4z3a6xG72/wel/Zl2t4TKtn3UvxTsNPxqs6SK/ZzP1tsMtaVc0D3gQucvt6Rt3PLLx/5h/UOrB3VK8qpDn+AbwKnFbH1VYDaiZEJAavAXFHHfv4J95ZxVBV7YJXdSV1rNeYbcD7tcqWpKo/BHKAytCY8C4OqJeqbsVLoJfhVQs94cqSiHf2dw/QS1VTgHm1Yq73MxKRQcAjwA1AD7f9KvyVeRvQXURS6ln2x1rl76Sqfqr+drj9hjbcDgS2hzz/Jl0l/4+vVld+hYgcjVcV+nP3g2AXXvXYlDbc2N5iLBEERFXzgd8AD4nIeSLSSUTi3S+9u91qy4AzRaS7iPTGq7Jors+BDiJylqsn/xVeA11dkvGunNiLlzzurLV8N9DYdfVP4/3CusBN15iO9882EkBEuorIhU0pSA0RuQKYgFeVcRMw29UN15ggIue7f+SbXZk+qWNXyXgNkEXucsMfNicevIQ0TESucJ9lvIgcLiKHqmoV8BJwu/usR+Dv1+ZsvAP2MRyoF0/A++xygEoROQM4tQlxdsY7qOYAiMiVeGcEjVLVnXjVe/8QkW6ujMe7xY8A14rIEeLp7L5vyfXv8cv9bsNrXP6Tu3x2NHAVjbQFNMFvgaNF5C/ufwkROVhEnnRJ7bt47TsjgLHucRje9/+MFoqhzbJEECBV/StwK95BOQfvF9UNePW94DXKLcermnkT7wqY5r5WPl4D6Ey8X1nFeFUldXkC77R8O94VJbUPno8CI9zp/xzqNhfvF9ZuVV0eEsd/gD8Dz7pqmFU0/o+WJ1+9j+BW17B3PzBVVYtU9WlgMa7h0nkZr95+H94v6vNVtaKO/f8E78ylEO9g1qz32VVrnApcgvcLd5cra03CvQGvemUXXn32Yz52+yJeo/Tb7iBc8zo3Ac/jle1SvPfbb5xrgHvxzkp3A6Pwrrjy6wq8Ovd1eI3WN7v9Lga+j3fV1T68hvRpTdjvFLyzzx14F1H8VlXfasL29XJVREe5/a8WkXy8s6rFeGW5CPi7qu4KeWzB+x+M+OohOXDGbkzkEJHb8Rp4Lw86FmPaOjsjMMaYKGeJwBhjopxVDRljTJSzMwJjjIly7e762NTUVE1PTw86DGOMaVeWLFmyR1XrvHeo3SWC9PR0Fi9eHHQYxhjTrohIvXeyW9WQMcZEOUsExhgT5SwRGGNMlLNEYIwxUc4SgTHGRLmwJQIRmSUi2SKyqp7lIiJ/E5GN4g0iPb6u9YwxxoRXOM8IHgdOb2D5GXi9Uw7FG0rvn2GMxRhjTD3Cdh+Bqs4XkfQGVpkMPOEGLPlERFJEpE9NV7vGGBM0VaW8qpqyymrKKqopr6qmvLKassoqyitrpg/8raiqplqVqmrvUa1KtfLldOj8qmq85dVKlSo1vf18rdOfkG6AMtK7c/yw+saTar4gbyjrx1eHnsty876WCETkGtwA3AMHNjiokzHGAN5BvKC0kvySCvL2l5NXUsG+knLy91dQWFpJUVklxWUH/haXVVFcfmC6Zn5ldfD9sYkbO+7abw2JuERQ17B4db7jqjoDmAGQkZER/KdijGl1VdXKvpJycgrL2FPkPbzpcvYUlpG33x3oSyrI219B/v4Kqho4iMfFCJ0T40hKjKNzYuyX072SO7hpb17nxDgS42LcI5aEuBjvERtDYrz3N3ReTIwQK0JsjBATI8QIxIp8OT8mxlvmTUOMHJgflCATQRZfHb+1vvFkjTERrqS8kh15pezKL2VH/n525pWyq2A/O/JKyS70Dvi5xWXUdVxPiIshLSmRbp3jSemYQN+UjnTr5E2ndIqna8d4UjolePM6xdO1YwLJHbyDu0hwB9+2JMhEMBe4QUSexRskOt/aB4yJTIWlFWzL3c/W3BK25ZawNbeErH0l7MwvZWd+Kfn7vz6CaGpSAn26dqRfSgfG9O9KWnIiqUnew5tOIDU5keTEODugf0NhSwQi8gwwCUgVkSy8waPjAVR1OjAPOBNvXNMS4MpwxWKMCb/8kgo25hSyKbuYL3KL2Rpy4M8tLv/Kul07xtO/W0f6d+vE4end6ZPSgb5dO9K7q/e3V9dEEuNiAypJ9AnnVUNTGlmuwPXhen1jTMurrlZ25O9nY3YRm3KK2ZRTxMbsIjbnFLGn6MDBPjZG6JfSkYHdO3H6Yb0Z2L3Tl48B3TrRtVN8gKUwtbW7bqiNMa0jt7icdTsLWLOzgHW7Clm3q4CN2UWUVlR/uU5Kp3gOTkvipOG9GNKzMwf3TOKg1CT6d+tIXKx1XNBeWCIwJsqpKpl7S1iRlcfanYWs3VnAul0F7C4o+3Kd1KREDu2TzGVHDGJIWhJD0ryDfvfOCVY/HwEsERgTZXbll7I8K48VWXks35bPiqw8CkorAYiPFQ7umcwxQ1I5tE8XhvdJZnjvLqQlJwYctQknSwTGRLDSiipWbs9nUWYuS7/wDv7Zhd4v/dgYYXjvZM4a3Zcx/bsyqn9XhvZMJiHOqnSijSUCYyJIfkkFS7bmsihzH4szc1m+LZ/yKq9O/6DUzhxzcCqj+3dldP8URvbtQod4uzLHWCIwpl3bV1zOx5v3smDTHhZt2cf63YWAd9fsqP5dmXZMOhmDujFhUDd6JFn1jqmbJQJj2pH95VUsyszlo017+GjjHlbvKEAVOifEMiG9O2eP7kNGenfGDkihY4L92jf+WCIwpg2rrlZWbM/nww05fLhxD0u/yKO8qpr4WGHcwG7cfNIwjh3ag9H9U4i3yzVNM1kiMKaNyS+pYP6GHN5dn83763PY6+7KHdGnC9OOSefoIT2YOLg7nRLs39e0DPsmGRMwVWX97kLeWZfNe+tyWLJ1H1XVSkqneCYNS+OE4T059uBUq+M3YWOJwJgAVFZVszAzlzdW7eKtNbvZkV8KwMi+Xbhu0hAmHdKTsQNSiA2wa2ITPSwRGNNKSiuqWLBpD6+7g/++kgo6xMdw/NA0fnTyUCYd0pNeXToEHaaJQpYIjAmjssoq3lufw6srdvLuumyKyipJTozjpEN7cvphvTl+WJrV9ZvA2TfQmBZWXa18uiWXl5dtZ97KnRSUVtK9cwLnjOnDaSN7c/SQVLt717QplgiMaQGqyuodBcxdvoO5y3awq6CUzgmxnDayN+eO7cuxB6dab5ymzbJEYMw3kFtczn8+287zi7axfnchcTHCpEPS+OVZh3Lyob3spi7TLlgiMKaJqqqVDzbk8MLiLN5cs4uKKmXMgBT+cN5hnDWqD906JwQdojFNYonAGJ+25+3nuYVbeXFJFjvyS+nWKZ4rjkzn4sMHcEjv5KDDM6bZfCUCERkEDFXV/4lIRyBOVQvDG5oxwVNVFmzay+wFmfxv7W4UOG5oGr88awQnj+hp4+qaiNBoIhCR7wPXAN2BIUB/YDpwUnhDMyY4RWWVvLQ0i9kLMtmUU0z3zglc+60hXHrEQPp36xR0eMa0KD9nBNcDE4FPAVR1g4j0DGtUxgRkc04Rsxdk8u+l2ykqq2TMgBTuvXAMZ43uY333m4jlJxGUqWp5zbikIhIHaFijMqaVLc7M5eH5m/nf2t3Ex8Rw9pg+TD0qnbEDUoIOzZiw85MI3heRXwAdReQU4DrglfCGZUz4VVUrb63ZxYz5m1m6NY+UTvHceMLBTD06nVTr4M1EET+J4DbgKmAl8ANgHjAznEEZE06lFVW8uCSLmR9sJnNvCQO7d+L3k0fynQn9rbsHE5X8fOs7ArNU9REAEYl180rCGZgxLa2orJInPs7k0Q+2sLe4nDH9u/LQpeM5/bDe1suniWp+EsHbwMlAkXveEXgTODpcQRnTkgpKK3hiQSYzP9xCXkkFxw9L47pJQzhicHdq2r6MiWZ+EkEHVa1JAqhqkYjY9XOmzcsvqeCxBVuY9eEWCkorOWl4T248aag1ABtTi59EUCwi41V1KYCITAD2hzcsY5qvsLSCmR94CaCwrJJTR/TippOGcli/rkGHZkyb5CcR3Ay8ICI73PM+wMVhi8iYZiqtqOLJT77goXc3sq+kgtNH9uamk4Yyom+XoEMzpk1rNBGo6iIRGQ4cAgiwTlUrwh6ZMT5VVlXz4pIsHnh7AzvzSzluaCr/d9pwRvW3MwBj/PB7rdzhQLpbf5yIoKpPhC0qY3xQVeat3MW9b65n855ixg5I4d6LxnD0kNSgQzOmXfHT19C/8PoYWgZUudkKNJoIROR04AEgFpipqnfVWt4VeBIY6GK5R1Ufa0L8Jkot25bHHa+uYckX+xjWK4kZV0zglBG97CogY5rBzxlBBjBCVZvUrYS73+Ah4BQgC1gkInNVdU3IatcDa1T1HBFJA9aLyFOqWt6U1zLRY0fefu5+fR1zlu0gNSmRu84fxYUZA+w+AGO+AT+JYBXQG9jZxH1PBDaq6mYAEXkWmAyEJgIFksX7GZcE5AKVTXwdEwVKyiuZ/v5mZszfRLXCdZOGcN0JB5OUaHcCG/NN+fkvSgXWiMhCoKxmpqqe28h2/YBtIc+zgCNqrfMgMBfYASQDF6tqde0dicg1eF1hM3DgQB8hm0ihqsxZtp27XlvH7oIyzh7dh5+dPpwB3e1WFmNaip9EcHsz913XuXrt6qXT8NoeTsRrh3hLRD5Q1YKvbKQ6A5gBkJGRYT2fRon1uwr59curWLgll9GuO4iM9O5Bh2VMxPFz+ej7zdx3FjAg5Hl/vF/+oa4E7nLtDxtFZAswHFjYzNc0EaCorJIH/vc5sz7KJLlDHH86fxQXZwwgxtoBjAkLP1cNHQn8HTgUSMC7AqhYVRu7S2cRMFREBgPbgUuAS2utsxVvpLMPRKQX3r0Km5tUAhMxVJX/rtzJHa+uYXdBGZccPoD/O3043W0weGPCyk/V0IN4B/EX8K4gmgoMbWwjVa0UkRuAN/CSxyxVXS0i17rl04E7gMdFZCVeVdLPVHVPs0pi2rXNOUX85uXVfLhxDyP7duGfl09g/MBuQYdlTFTwdcmFqm4UkVhVrQIeE5EFPrebhzd+Qei86SHTO4BTmxCviTAVVdXMmL+ZB97eQGJcDL87dySXHznILgc1phX5SQQlIpIALBORu/EuI+0c3rBMNFiRlcfP/r2StTsLOHNUb24/dyQ9kzsEHZYxUcdPIrgCr2rnBuAWvAbgC8IZlIls+8uruO9/nzPzg82kJiXy8BUTOG1k76DDMiZq+blq6As3uR/4XXjDMZFuwaY9/PyllXyxt4QpEwdw2xmH0rVjfNBhGRPV6k0EIvK8ql7kGnK/du2+qo4Oa2Qmouwvr+Ku19Yy++MvSO/Riae/f4R1DmdMG9HQGcGP3N+zWyMQE7lWZOVx83PL2JxTzJXHpPN/pw2nY0Js0GEZY5x6E4Gq7nQdxz2qqie3YkwmQlRWVfOP9zbxt7c3kJacyFNXH8ExB9tZgDFtTYNtBKpaJSIlItJVVfNbKyjT/m3ZU8wtzy1j2bY8Jo/ty+/PPYyunawtwJi2yM9VQ6XAShF5CyiumamqN4UtKtOuvbxsO794aSWxMcLfp4zjnDF9gw7JGNMAP4ngv+5hTIP2l1dx+9zVPLd4G4end+OBS8bRN6Vj0GEZYxrh5/LR2a0RiGnfNuwu5Pqnl7Ihu4jrTxjCLScPIy42JuiwjDE++Ol0bijwJ2AE8OVtn6p6UBjjMu3Ii0uy+PWcVXRKiGX2lRM5flha0CEZY5rAT9XQY8BvgfuAE/C6jraOYAzlldX8/tXVPPnJVo48qDt/u2QcPbtYFxHGtDd+EkFHVX1bRMTdZXy7iHyAlxxMlMouLOW6J5ey+It9/OBbB/HTUw+xqiBj2ilfVw2JSAywwXUrvR3oGd6wTFu2dOs+fvjkEgr2V/LgpeM4e7RdFWRMe+bnJ9zNQCfgJmACcDnw3TDGZNqwZxZu5eKHPyYxLpb/XH+0JQFjIoCfM4JKVS0CivDaB0wUqqpW7nh1DY8vyOT4YWn87ZKxpHSykcOMiQR+EsFfRaQP3ghlz6rq6jDHZNqYorJKbnrmM95Zl83Vxw7m52ceagPHGBNB/NxHcIKI9AYuAmaISBfgOVX9Q9ijM4Hbkbef7z2+iA3ZRfzhvMO4/MhBQYdkjGlhvi7zUNVdqvo34FpgGfCbcAZl2oYVWXlMfugjtu/bz2PTDrckYEyEajQRiMihInK7iKzCG8h+AdA/7JGZQL2xehcXPfwxCbEx/Pu6o+0mMWMimN8byp4BTnWDzZsI9+QnX/Drl1cxpn8Kj0zNIC05MeiQjDFh5KeN4MjWCMQET1W5/38beODtDZw4vCcPXTreBpAxJgr4OSMwUaCqWvn1y6t4+tOtfGdCf/50/iji7U5hY6KCJQJDaUUVNz+7jNdX7+K6SUP46WmHIGKXhxoTLSwRRLniskqumr2ITzbn8puzR/C9YwcHHZIxppXVmwhE5BVA61uuqueGJSLTagpKK5g2ayHLs/K5/+KxnDeuX9AhGWMC0NAZwT3u7/lAb+BJ93wKkBnGmEwr2FdcztRZC1m3q4AHp4zjjFF9gg7JGBOQehOBqr4PICJ3qOrxIYteEZH5YY/MhE1OYRlXPPopm/cU8/AVEzhxeK+gQzLGBMjPZSFpIvLlaGQiMhiwu4vaqV35pVw842My9xYz67uHWxIwxvhqLL4FeE9ENrvn6cAPwhaRCZvdBaVcMuNjcgrLeOJ7RzBxcPegQzLGtAF+bih73Y1bPNzNWqeqZeENy7S0nMIypjzyiZcErprIhEGWBIwxHj99DXUCfgrcoKrLgYEicrafnYvI6SKyXkQ2isht9awzSUSWichqEXm/SdEbX/YWlXHZzE/YmVfKY1daEjDGfJWfNoLHgHLgKPc8C2i0C2oRiQUeAs4ARgBTRGRErXVSgH8A56rqSOBC35EbX/YVl3PZzE/ZmlvCo9MyrDrIGPM1fhLBEFW9G6gAUNX9gJ/bTicCG1V1s6qWA88Ck2utcynwkqpudfvO9h25aVRBaQVTZy1k855iHpmawdFDUoMOyRjTBvlJBOUi0hF3c5mIDAH8tBH0A7aFPM9y80INA7qJyHsiskREpta1IxG5RkQWi8jinJwcHy9tSiuq+P7sxazdWcDDl0/guKF2oZcxpm5+rhr6LfA6MEBEngKOAab52K6us4badyrHAROAk4COwMci8omqfv6VjVRnADMAMjIy6r3b2Xgqq6q58ZnPWJiZy/0Xj+WE4T2DDskY04b5uWroLRFZChyJd3D/karu8bHvLGBAyPP+QO3xDLKAPapaDBS7G9XGAJ9jmkVV+flLK3lrzW5+P3kkk8datxHGmIb57We4A7APKABGiMjxjawPsAgYKiKDRSQBuASYW2udl4HjRCTOXZ10BLDWZ0ymDne9to4XlmTxo5OGMvWo9KDDMca0A42eEYjIn4GLgdVAtZutQIPdTKhqpYjcALwBxAKzVHW1iFzrlk9X1bUi8jqwwu17pqquanZpotzMDzbz8PzNTD1qEDefPDTocIwx7YSoNlzlLiLrgdFt5SayjIwMXbx4cdBhtDmvrdzJdU8v5YzDevPglPHExNh4AsaYA0Rkiapm1LXMT9XQZiC+ZUMyLemzrfu4+blljB2Qwl8vGmtJwBjTJH6uGioBlonI24RcNqqqN4UtKuPbttwSrp69mJ5dEnlkagYd4m2MYWNM0/hJBHP5eiOvaQPySyqY9thCKquVx6ZNJDUpMeiQjDHtkJ/LR2e3RiCmaSqrqvnhU0vYmlvCv646goN7JgUdkjGmnWpoqMrnVfUiEVlJHUNWqurosEZmGnTnvHUs2LSXey4cw5EH9Qg6HGNMO9bQGcGP3F9fPY2a1vPS0ixmfbSFaUen850J/YMOxxjTzjU0VOVO9/eL1gvHNGZlVj4/f2klRx7UnV+edWjQ4RhjIoCf8QiOFJFFIlIkIuUiUiUiBa0RnPmqPUVl/OBfi0lNSuShS8cTH+v3xnBjjKmfnyPJg8AUYANex3BXA38PZ1Dm6yqrqrn+qaXsLS7n4Ssm0MOuEDLGtBA/l4+iqhtFJFZVq4DHRGRBmOMytdz/vw18uiWXey8cw2H9ugYdjjEmgvi6ocx1GrdMRO4GdgKdwxuWCTX/8xweem8jF2X05wJrHDbGtDA/VUNX4HUadwNQjNe19AXhDMocsLuglFueW8bQnkn87tzDgg7HGBOB/NxQVnPV0H7gd+ENx4SqrKrmpmc+o6S8iucuG0/HBOs+whjT8hq6oazOG8lq2A1l4ffA2wfaBQ7umRx0OMaYCNXQGYHdSBagBRv38OC71i5gjAm/hm4o+/JGMhHpDUzEO0NYpKq7WiG2qJVfUsGPX1jO4NTO1i5gjAk7PzeUXQ0sBM4HvgN8IiLfC3dg0ezXL68ip7CM+y8ea+0Cxpiw83P56E+Bcaq6F0BEegALgFnhDCxavbxsO3OX7+DHpwxjdP+UoMMxxkQBP5ePZgGFIc8LgW3hCSe67cjbz6/mrGL8wBR+OGlI0OEYY6KEnzOC7cCnIvIyXhvBZGChiNwKoKp/DWN8UaO6Wvnx88uprlbuu3gscdaPkDGmlfhJBJvco8bL7q9dz9iCZn20hY837+XPF4xiUA+7cdsY03r8JII/q2pp6AwRSVXVPWGKKep8vruQu19fzykjenFRxoCgwzHGRBk/9Q8LReTImicicgFeY7FpAZVV1fz0heUkdYjjT+ePQkSCDskYE2X8nBFcBswSkfeAvkAP4MRwBhVNZn64heVZ+Tx46TgbfN4YEwg/fQ2tFJE/Av/Cu2LoeFXNCntkUWBjdhF/fetzTh/Zm7NG9Qk6HGNMlGo0EYjIo8AQYDQwDHhFRB5U1YfCHVwkq6pWfvricjolxHLHeYdZlZAxJjB+2ghWASeo6hZVfQM4Ehgf3rAi32MfbeGzrXncfs5I0pKtSsgYE5xGE4Gq3gcMFJGT3axy4OZwBhXptuwp5i9vrOfkQ3syeWzfoMMxxkQ5P30NfR94EXjYzeoPzAljTBGtulr52YsrSIyL4Y/ftquEjDHB81M1dD1wDFAAoKobgJ7hDCqSPbd4Gwszc/nVWSPo1aVD0OEYY4yvRFCmquU1T0QkjgYGrDH1yy4s5U/z1nLE4O5cmGFjDBhj2gY/ieB9EfkF0FFETgFeAF7xs3MROV1E1ovIRhG5rYH1DheRKhH5jr+w26c/vLqW0opq7rQbx4wxbYifRHAbkAOsBH4AzAN+1dhGIhILPAScAYwApojIiHrW+zPwhv+w25/31mczd/kOrjthCEPSkoIOxxhjvuTnhrJq4BH3aIqJwEZV3QwgIs/i9Vy6ptZ6NwL/Bg5v4v7bjf3lVfz65VUclNbZupc2xrQ54ezruB9fHbcgy837koj0A74NTG9oRyJyjYgsFpHFOTk5LR5ouD3w9ga25e7nzm+PIjHORhwzxrQt4UwEdVWC125kvh/4mapWNbQjVZ2hqhmqmpGWltZS8bWK9bsKmfnBZi6c0J8jD+oRdDjGGPM1fjqdA0BEOqtqcRP2nQWE9qncH9hRa50M4FnXcJoKnCkilao6pwmv02apKr95eRVJHeL4xZmHBh2OMcbUyc8NZUeLyBpgrXs+RkT+4WPfi4ChIjJYRBKAS4C5oSuo6mBVTVfVdLyb1q6LlCQA8OqKnXy6JZefnHoI3TonBB2OMcbUyU/V0H3AacBeAFVdDhzf2EaqWgncgHc10FrgeVVdLSLXisi1zQ+5fSgpr+TOeWsZ2bcLUyYODDocY4ypl6+qIVXdVuu69wbr9EO2m4d3uWnovDobhlV1mp99thcPvbuRnfml/H3KOGJj7J4BY0zb5ScRbBORowF1VTw34aqJTN0y9xTzyPwtnD+uHxnp3YMOxxhjGuSnauhavP6G+uE1AI91z009fv/qGhLiYrjtjOFBh2KMMY3yc0YgqnpZ2COJEO+s280767L5xZnD6Wmdyhlj2gE/ZwQLRORNEblKRFLCHVB7VlZZxe9fWcOQtM5MO3pw0OEYY4wvfgamGYrXt9BIYKmIvCoil4c9snZo9oJMMveW8NtzRpIQF8579YwxpuX4Olqp6kJVvRWv/6BcYHZYo2qHcovL+fs7GznhkDSOH9a+7n42xkQ3PzeUdRGR74rIa8ACYCdeQjAh/vb2BorLKu0OYmNMu+OnsXg53tCUv1fVj8MbTvu0OaeIJz/5gksmDmRor+SgwzHGmCbxkwgOUlUbkawBf359HYlxMdxy8rCgQzHGmCarNxGIyP2qejMwV0S+lghU9dxwBtZeLNySyxurd/OTU4eRlpwYdDjGGNNkDZ0R/Mv9vac1AmmPVJU7562lT9cOXHXsQUGHY4wxzVJvY7GqLnGTY1X1/dAH3t3FUe/ttdks25bHzScPpWOCDThjjGmf/Fw++t065k1r4Tjanepq5d63Pie9RyfOH98/6HCMMabZGmojmAJcCgwWkdBxBJJxXVJHs3mrdrJ2ZwH3XzyW+Fi7ecwY03411EZQc89AKnBvyPxCYEU4g2rrKquq+etbnzOsVxLnjOkbdDjGGPON1JsIVPUL4AvgqNYLp32Ys2wHm3OKmX75eBtrwBjT7vm5s/hIEVkkIkUiUi4iVSJS0BrBtUWVVdU88PbnjOzbhdNG9g46HGOM+cb8VG4/CEwBNgAdgauBv4czqLbsvyt3si13Pz86aSi1Rm0zxph2ye9QlRtFJFZVq4DHRGRBmONqk1SVf763iYN7JnHyob2CDscYY1qEn0RQ4oaoXCYid+M1IHcOb1ht03uf57BuVyF/+c5oYqxtwBgTIfxUDV0BxAI3AMXAAOCCcAbVVk1/bxN9unZg8th+QYdijDEtptEzAnf1EMB+4HfhDaft+mzrPj7dksuvzjrUBp0xxkSUhm4oWwnU2+uoqo4OS0Rt1PT3N9GlQxyXTBwYdCjGGNOiGjojOLvVomjjtuWW8Oaa3fzwW0NISvTVvm6MMe1GYzeUGeCJjzOJEWHqUelBh2KMMS2u0Z+3IlLIgSqiBCAeKFbVLuEMrK0oLqvk2UXbOOOw3vTu2iHocIwxpsX5aSz+ytiLInIeUTRm8X8+205haSVXHpMedCjGGBMWTb78RVXnACe2fChtj6ry+IJMRvXryviB3YIOxxhjwsJP1dD5IU9jgAwauJookny4cQ8bs4u498Ix1p2EMSZi+bkE5pyQ6UogE5gclmjamMc/yiQ1KYGzx/QJOhRjjAkbP20EV7ZGIG3NttwS3lmfzY0nHExinA1DaYyJXH6qhgYDNwLpoeur6rk+tj0deACvi4qZqnpXreWXAT9zT4uAH6rqcr/Bh9Pzi7cB2A1kxpiI56dqaA7wKPAKUO13xyISCzwEnAJkAYtEZK6qrglZbQvwLVXdJyJnADOAI/y+RrhUVlXzwuIsvjUsjb4pHYMOxxhjwspPIihV1b81Y98TgY2quhlARJ7Fa1v4MhGoamh31p8AbWIU+PkbcthVUMrt544IOhRjjAk7P4ngARH5LfAmUFYzU1WXNrJdP2BbyPMsGv61fxXwmo94wu7ZhdtITUrgJBtzwBgTBfwkglF4XVGfyIGqIaXxewnqut6yzstOReQEvERwbD3LrwGuARg4MLx19tmFpby9LpurjxtMfKz1MmqMiXx+EsG3gYNUtbyJ+87CG7ugRn9gR+2VRGQ0MBM4Q1X31rUjVZ2B135ARkZGWO9heHFJFlXVysUZAxpf2RhjIoCfn7zLgZRm7HsRMFREBrsRzi4B5oauICIDgZeAK1T182a8RotSVV5cksXh6d04KC0p6HCMMaZV+Dkj6AWsE5FFfLWNoMHLR1W1UkRuAN7Au3x0lqquFpFr3fLpwG+AHsA/3J27laqa0ayStIBV2wvYnFPM1cceFFQIxhjT6vwkgt82d+eqOg+YV2ve9JDpq4Grm7v/ljZn2XbiY4UzR/UOOhRjjGk1fu4sfr81AglaVbXyyvIdTDqkJymdEoIOxxhjWo2NR+B8vGkv2YVlfHucDUxvjIkuNh6BM2fZdpIT4zhxeM+gQzHGmFZl4xEApRVVvL5qF6cf1psO8dbBnDEmuth4BMC767IpKqvkPKsWMsZEIRuPAHh99S66d07gyIN6BB2KMca0uqgfj6C8spp31mZzxqjexMbYKGTGmOjTaBuBiMwWkZSQ591EZFZYo2pFCzbtobCsktNG2r0Dxpjo5KexeLSq5tU8UdV9wLiwRdTK3li9m84JsRxzcGrQoRhjTCD8JIIYEelW80REuuOvbaHNq6pW3lqzm0nDe9rVQsaYqOXngH4vsEBEXsS7Wugi4I9hjaqVLN26jz1FZVYtZIyJan4ai58QkcV49w4IcH6t4SbbrTdW7SIhNoYTDkkLOhRjjAmMryoed+CPiIN/DVXljTW7OPrgHiR3iA86HGOMCUzUDsG1dmch23L3W7WQMSbqRW0ieHd9NgAnWd9CxpgoF72JYF02h/XrQs8uHYIOxRhjAhWViSC/pIKlW/dxwiF2NmCMMVGZCOZvyKFaYZIlAmOMic5E8O76bFI6xTN2QErQoRhjTOCiLhFUVyvzP8/hW8PSrJM5Y4whChPBhuwi9hSVc6z1LWSMMUAUJoJPt+wFsLEHjDHGib5EsDmXvl070L9bx6BDMcaYNiGqEoGq8umWvUwc3B0Rax8wxhiIskSwZU8xe4rKmTjYqoWMMaZGVCWCldvzARgzoGvAkRhjTNsRVYlgzc4C4mOFoT2Tgw7FGGPajOhKBDsKGNYrmYS4qCq2McY0KKqOiJl7ixmSlhR0GMYY06ZETSIor6xm+779pPfoFHQoxhjTpkRNItiet59qhYE9OgcdijHGtClhTQQicrqIrBeRjSJyWx3LRUT+5pavEJHx4Yolc28xgJ0RGGNMLWFLBCISCzwEnAGMAKaIyIhaq50BDHWPa4B/hiue5MQ4Th3Ri/RUOyMwxphQvgavb6aJwEZV3QwgIs8Ck4E1IetMBp5QVQU+EZEUEemjqjtbOpiM9O5kpHdv6d0aY0y7F86qoX7AtpDnWW5eU9cxxhgTRuFMBHV15qPNWAcRuUZEFovI4pycnBYJzhhjjCeciSALGBDyvD+woxnroKozVDVDVTPS0tJaPFBjjIlm4UwEi4ChIjJYRBKAS4C5tdaZC0x1Vw8dCeSHo33AGGNM/cLWWKyqlSJyA/AGEAvMUtXVInKtWz4dmAecCWwESoArwxWPMcaYuoXzqiFUdR7ewT503vSQaQWuD2cMxhhjGhY1dxYbY4ypmyUCY4yJcuLVzrQfIpIDfNHMzVOBPS0YTlsWLWWNlnJC9JTVyhkeg1S1zssu210i+CZEZLGqZgQdR2uIlrJGSzkhespq5Wx9VjVkjDFRzhKBMcZEuWhLBDOCDqAVRUtZo6WcED1ltXK2sqhqIzDGGPN10XZGYIwxphZLBMYYE+WiJhE0NmxmeyIiA0TkXRFZKyKrReRHbn53EXlLRDa4v91Ctvm5K/t6ETktuOibTkRiReQzEXnVPY/UcqaIyIsiss59tkdFYllF5Bb3vV0lIs+ISIdIKaeIzBKRbBFZFTKvyWUTkQkistIt+5uI1NVlf8tR1Yh/4HV6twk4CEgAlgMjgo7rG5SnDzDeTScDn+MNB3o3cJubfxvwZzc9wpU5ERjs3ovYoMvRhPLeCjwNvOqeR2o5ZwNXu+kEICXSyoo38NQWoKN7/jwwLVLKCRwPjAdWhcxrctmAhcBReGO2vAacEc64o+WM4MthM1W1HKgZNrNdUtWdqrrUTRcCa/H+wSbjHUxwf89z05OBZ1W1TFW34PX2OrFVg24mEekPnAXMDJkdieXsgncQeRRAVctVNY8ILCteZ5cdRSQO6IQ3BklElFNV5wO5tWY3qWwi0gfooqofq5cVngjZJiyiJRFE7JCYIpIOjAM+BXqpG8/B/e3pVmvP5b8f+D+gOmReJJbzICAHeMxVg80Ukc5EWFlVdTtwD7AV2Ik3BsmbRFg5a2lq2fq56drzwyZaEoGvITHbGxFJAv4N3KyqBQ2tWse8Nl9+ETkbyFbVJX43qWNemy+nE4dXpfBPVR0HFONVI9SnXZbV1Y9PxqsK6Qt0FpHLG9qkjnltvpw+1Ve2Vi9ztCQCX0NiticiEo+XBJ5S1Zfc7N3utBL3N9vNb6/lPwY4V0Qy8arzThSRJ4m8coIXe5aqfuqev4iXGCKtrCcDW1Q1R1UrgJeAo4m8coZqatmy3HTt+WETLYnAz7CZ7Ya7guBRYK2q/jVk0Vzgu276u8DLIfMvEZFEERkMDMVrjGrTVPXnqtpfVdPxPrN3VPVyIqycAKq6C9gmIoe4WScBa4i8sm4FjhSRTu57fBJeG1eklTNUk8rmqo8KReRI9x5NDdkmPIJuZW+tB96QmJ/jtcz/Muh4vmFZjsU7VVwBLHOPM4EewNvABve3e8g2v3RlX0+Yr0AIU5knceCqoYgsJzAWWOw+1zlAt0gsK/A7YB2wCvgX3lUzEVFO4Bm8to8KvF/2VzWnbECGe382AQ/ieoEI18O6mDDGmCgXLVVDxhhj6mGJwBhjopwlAmOMiXKWCIwxJspZIjDGmChnicC0eyLynoiEfRBwEbnJ9Qr6VLhfK0iuF9Trgo7DtB5LBCaquY7P/LoOOFNVLwtXPG1ECl5ZTZSwRGBahYiku1/Tj7i+6N8UkY5u2Ze/6EUk1XUpgYhME5E5IvKKiGwRkRtE5FbXKdsnItI95CUuF5EFro/7iW77zq5/+EVum8kh+31BRF4B3qwj1lvdflaJyM1u3nS8juHmisgttdaPFZF7XP/xK0TkRjf/JPe6K10ciW5+pojcKSIfi8hiERkvIm+IyCYRudatM0lE5ovIf0RkjYhMF5EYt2yK2+cqEflzSBxFIvJHEVnu3p9ebn6aiPzbvQ+LROQYN/92F9d7IrJZRG5yu7oLGCIiy0TkLyLSx8WyzL3mcc39Hpg2Kug78ewRHQ8gHagExrrnzwOXu+n3gAw3nQpkuulpeF3zJgNpQD5wrVt2H15nezXbP+Kmj8f1BQ/cGfIaKXh3lnd2+80i5A7PkDgnACvdeknAamCcW5YJpNaxzQ/x+n2Kc8+7Ax3wepYc5uY9ERJvJvDDkHKsCCljtps/CSjFSz6xwFvAd/A6atvq1o0D3gHOc9socI6bvhv4lZt+GjjWTQ/E65oE4HZgAd6dvanAXiDefVah/en/GHc3voslOejvkz1a9tGU02JjvqktqrrMTS/BO+A05l31xlwoFJF84BU3fyUwOmS9Z8DrD15EuohICnAqXqd1P3HrdMA7EAK8paq1+40Hr/uO/6hqMYCIvAQcB3zWQIwnA9NVtdLFkCsiY1x5P3frzAaux+tWGw70dbUSSAopY6mLHbx+Zza7OJ5xsVUA76lqjpv/FF7ymwOUA6+6bZcAp4TEN0IODHLVRUSS3fR/VbUMKBORbKBXHeVbBMwSr6PDOSGfoYkQlghMayoLma4COrrpSg5UU3ZoYJvqkOfVfPX7W7uvlJrufC9Q1fWhC0TkCLxunuvSnCEBpY7Xb2w/oeWoXcaactVXpvpUqGrNNlUh+4kBjlLV/V8J0EsMtT+Trx0TXHI9Hm+AoH+JyF9U9YkG4jDtjLURmLYgE69KBrzqj+a4GEBEjsUb7CQfeAO40fXgiIiM87Gf+cB5rnfMzsC3gQ8a2eZN4NqahmfXdrEOSBeRg906VwDvN7FME8XrMTcGr3wf4g1A9C3XlhILTPGx3zeBG2qeiMjYRtYvxKuqqll/EF6V1SN4vd6Ob2I5TBtnZwSmLbgHeF5ErsCr826OfSKyAOgCfM/NuwOvKmaFSwaZwNkN7URVl4rI4xzo6nimqjZULQTeMJrD3OtU4LVXPCgiVwIvuASxCJjexDJ9jNdwOwovQf1HVatF5OfAu3hnB/NUtbEuim8CHhKRFXj/8/OBa+tbWVX3ishH4g3A/hpeL5g/dWUrwusW2UQQ633UmDZIRCYBP1HVBhOXMS3BqoaMMSbK2RmBMcZEOTsjMMaYKGeJwBhjopwlAmOMiXKWCIwxJspZIjDGmCj3/7QOZzNUrB6qAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.cumsum(explained_variance))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.title('Cumulative Explained Variance for PCA');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "825fba8e-b694-4582-be77-5b47297fb0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 1000, random_state = 42)\n",
    "Z_train = pca.fit_transform(Xs_train)\n",
    "Z_test = pca.transform(Xs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69d99f45-eb09-445f-ba8a-33494ffaf499",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 1.3945 - val_loss: 0.8939\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1782 - val_loss: 0.8572\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0362 - val_loss: 0.8235\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9199 - val_loss: 0.7940\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8257 - val_loss: 0.7681\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7444 - val_loss: 0.7449\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6765 - val_loss: 0.7215\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6195 - val_loss: 0.6997\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5675 - val_loss: 0.6805\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5235 - val_loss: 0.6629\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4864 - val_loss: 0.6469\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4533 - val_loss: 0.6322\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4246 - val_loss: 0.6189\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3999 - val_loss: 0.6064\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3778 - val_loss: 0.5949\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3581 - val_loss: 0.5838\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3404 - val_loss: 0.5733\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3240 - val_loss: 0.5629\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3085 - val_loss: 0.5526\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2952 - val_loss: 0.5427\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2831 - val_loss: 0.5334\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2715 - val_loss: 0.5247\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2604 - val_loss: 0.5164\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2494 - val_loss: 0.5088\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2390 - val_loss: 0.5019\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2294 - val_loss: 0.4957\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2213 - val_loss: 0.4900\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2134 - val_loss: 0.4848\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2065 - val_loss: 0.4799\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1997 - val_loss: 0.4754\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1932 - val_loss: 0.4706\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1869 - val_loss: 0.4663\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1810 - val_loss: 0.4628\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1753 - val_loss: 0.4597\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1699 - val_loss: 0.4566\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1650 - val_loss: 0.4532\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1601 - val_loss: 0.4497\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1555 - val_loss: 0.4461\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1513 - val_loss: 0.4430\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1468 - val_loss: 0.4403\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1426 - val_loss: 0.4373\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1387 - val_loss: 0.4346\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1354 - val_loss: 0.4323\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1323 - val_loss: 0.4302\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1292 - val_loss: 0.4283\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1264 - val_loss: 0.4266\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1235 - val_loss: 0.4252\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1207 - val_loss: 0.4238\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1180 - val_loss: 0.4226\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1154 - val_loss: 0.4218\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1129 - val_loss: 0.4211\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1104 - val_loss: 0.4204\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1081 - val_loss: 0.4198\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1058 - val_loss: 0.4189\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1035 - val_loss: 0.4177\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1013 - val_loss: 0.4165\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0992 - val_loss: 0.4153\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0971 - val_loss: 0.4144\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0952 - val_loss: 0.4136\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0935 - val_loss: 0.4129\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0917 - val_loss: 0.4124\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0900 - val_loss: 0.4119\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0883 - val_loss: 0.4115\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0868 - val_loss: 0.4111\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0854 - val_loss: 0.4107\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0840 - val_loss: 0.4102\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0826 - val_loss: 0.4098\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0813 - val_loss: 0.4094\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0802 - val_loss: 0.4091\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0791 - val_loss: 0.4087\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0781 - val_loss: 0.4083\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0772 - val_loss: 0.4079\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0762 - val_loss: 0.4074\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0754 - val_loss: 0.4071\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0745 - val_loss: 0.4067\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0736 - val_loss: 0.4062\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0727 - val_loss: 0.4055\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0719 - val_loss: 0.4045\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0712 - val_loss: 0.4036\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0707 - val_loss: 0.4031\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0701 - val_loss: 0.4025\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0695 - val_loss: 0.4020\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0693 - val_loss: 0.4016\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0689 - val_loss: 0.4012\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0685 - val_loss: 0.4009\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0683 - val_loss: 0.4007\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0679 - val_loss: 0.4006\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0674 - val_loss: 0.4005\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0667 - val_loss: 0.4003\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0659 - val_loss: 0.4003\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0650 - val_loss: 0.4005\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0641 - val_loss: 0.4005\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0634 - val_loss: 0.4005\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0628 - val_loss: 0.4005\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0621 - val_loss: 0.4005\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0616 - val_loss: 0.4003\n",
      "Epoch 97/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0612 - val_loss: 0.4002\n",
      "Epoch 98/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0607 - val_loss: 0.4002\n",
      "Epoch 99/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0603 - val_loss: 0.4002\n",
      "Epoch 100/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0599 - val_loss: 0.4003\n",
      "Epoch 101/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0597 - val_loss: 0.4005\n",
      "Epoch 102/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0594 - val_loss: 0.4007\n",
      "Epoch 103/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0589 - val_loss: 0.4009\n",
      "Epoch 104/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0586 - val_loss: 0.4011\n",
      "Epoch 105/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0582 - val_loss: 0.4013\n",
      "Epoch 106/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0578 - val_loss: 0.4013\n",
      "Epoch 107/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0575 - val_loss: 0.4013\n",
      "Epoch 108/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0570 - val_loss: 0.4013\n",
      "Epoch 109/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0566 - val_loss: 0.4011\n",
      "Epoch 110/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0563 - val_loss: 0.4010\n",
      "Epoch 111/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0561 - val_loss: 0.4007\n",
      "Epoch 112/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0559 - val_loss: 0.4003\n",
      "Epoch 113/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0557 - val_loss: 0.4001\n",
      "Epoch 114/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0554 - val_loss: 0.4000\n",
      "Epoch 115/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0550 - val_loss: 0.4000\n",
      "Epoch 116/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0547 - val_loss: 0.4000\n",
      "Epoch 117/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0545 - val_loss: 0.4000\n",
      "Epoch 118/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0542 - val_loss: 0.4001\n",
      "Epoch 119/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0537 - val_loss: 0.4003\n",
      "Epoch 120/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0530 - val_loss: 0.4005\n",
      "Epoch 121/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0525 - val_loss: 0.4008\n",
      "Epoch 122/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0518 - val_loss: 0.4011\n",
      "Epoch 123/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0511 - val_loss: 0.4013\n",
      "Epoch 124/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0502 - val_loss: 0.4014\n",
      "Epoch 125/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0495 - val_loss: 0.4015\n",
      "Epoch 126/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0487 - val_loss: 0.4014\n",
      "Epoch 127/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0483 - val_loss: 0.4014\n",
      "Epoch 128/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0478 - val_loss: 0.4013\n",
      "Epoch 129/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0474 - val_loss: 0.4014\n",
      "Epoch 130/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0470 - val_loss: 0.4015\n",
      "Epoch 131/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0467 - val_loss: 0.4016\n",
      "Epoch 132/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0462 - val_loss: 0.4017\n",
      "Epoch 133/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.047 - 0s 4ms/step - loss: 0.0457 - val_loss: 0.4019\n",
      "Epoch 134/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0453 - val_loss: 0.4021\n",
      "Epoch 135/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0450 - val_loss: 0.4023\n",
      "Epoch 136/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0446 - val_loss: 0.4026\n",
      "Epoch 137/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0441 - val_loss: 0.4029\n",
      "Epoch 138/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0437 - val_loss: 0.4031\n",
      "Epoch 139/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.036 - 0s 4ms/step - loss: 0.0433 - val_loss: 0.4033\n",
      "Epoch 140/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0429 - val_loss: 0.4033\n",
      "Epoch 141/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0428 - val_loss: 0.4031\n",
      "Epoch 142/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0424 - val_loss: 0.4028\n",
      "Epoch 143/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0420 - val_loss: 0.4027\n",
      "Epoch 144/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0416 - val_loss: 0.4027\n",
      "Epoch 145/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0413 - val_loss: 0.4021\n",
      "Epoch 146/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0411 - val_loss: 0.4006\n",
      "Epoch 147/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0409 - val_loss: 0.3994\n",
      "Epoch 148/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0407 - val_loss: 0.3988\n",
      "Epoch 149/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0403 - val_loss: 0.3986\n",
      "Epoch 150/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0400 - val_loss: 0.3985\n",
      "Epoch 151/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0398 - val_loss: 0.3984\n",
      "Epoch 152/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0394 - val_loss: 0.3983\n",
      "Epoch 153/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0390 - val_loss: 0.3982\n",
      "Epoch 154/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0387 - val_loss: 0.3982\n",
      "Epoch 155/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0383 - val_loss: 0.3982\n",
      "Epoch 156/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0379 - val_loss: 0.3984\n",
      "Epoch 157/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0376 - val_loss: 0.3986\n",
      "Epoch 158/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.036 - 0s 4ms/step - loss: 0.0373 - val_loss: 0.3988\n",
      "Epoch 159/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0370 - val_loss: 0.3990\n",
      "Epoch 160/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0367 - val_loss: 0.3991\n",
      "Epoch 161/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0364 - val_loss: 0.3992\n",
      "Epoch 162/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0361 - val_loss: 0.3992\n",
      "Epoch 163/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0358 - val_loss: 0.3992\n",
      "Epoch 164/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0358 - val_loss: 0.3992\n",
      "Epoch 165/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0358 - val_loss: 0.3995\n",
      "Epoch 166/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0355 - val_loss: 0.3998\n",
      "Epoch 167/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0353 - val_loss: 0.4001\n",
      "Epoch 168/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0350 - val_loss: 0.4004\n",
      "Epoch 169/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0348 - val_loss: 0.4008\n",
      "Epoch 170/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0346 - val_loss: 0.4010\n",
      "Epoch 171/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0344 - val_loss: 0.4012\n",
      "Epoch 172/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0341 - val_loss: 0.4012\n",
      "Epoch 173/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0337 - val_loss: 0.4013\n",
      "Epoch 174/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0334 - val_loss: 0.4014\n",
      "Epoch 175/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0331 - val_loss: 0.4014\n",
      "Epoch 176/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0328 - val_loss: 0.4015\n",
      "Epoch 177/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0326 - val_loss: 0.4015\n",
      "Epoch 178/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0323 - val_loss: 0.4015\n",
      "Epoch 179/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0322 - val_loss: 0.4012\n",
      "Epoch 180/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0320 - val_loss: 0.4011\n",
      "Epoch 181/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0318 - val_loss: 0.4010\n",
      "Epoch 182/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0315 - val_loss: 0.4010\n",
      "Epoch 183/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0313 - val_loss: 0.4011\n",
      "Epoch 184/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0311 - val_loss: 0.4014\n",
      "Epoch 185/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0309 - val_loss: 0.4015\n",
      "Epoch 186/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0306 - val_loss: 0.4016\n",
      "Epoch 187/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0304 - val_loss: 0.4018\n",
      "Epoch 188/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0301 - val_loss: 0.4019\n",
      "Epoch 189/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0299 - val_loss: 0.4021\n",
      "Epoch 190/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0297 - val_loss: 0.4023\n",
      "Epoch 191/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0294 - val_loss: 0.4026\n",
      "Epoch 192/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0292 - val_loss: 0.4029\n",
      "Epoch 193/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.4032\n",
      "Epoch 194/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0286 - val_loss: 0.4035\n",
      "Epoch 195/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.027 - 0s 5ms/step - loss: 0.0284 - val_loss: 0.4035\n",
      "Epoch 196/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0282 - val_loss: 0.4036\n",
      "Epoch 197/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0280 - val_loss: 0.4039\n",
      "Epoch 198/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0278 - val_loss: 0.4042\n",
      "Epoch 199/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0277 - val_loss: 0.4042\n",
      "Epoch 200/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0280 - val_loss: 0.4042\n",
      "Epoch 201/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0281 - val_loss: 0.4044\n",
      "Epoch 202/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0281 - val_loss: 0.4047\n",
      "Epoch 203/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0280 - val_loss: 0.4050\n",
      "Epoch 204/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0279 - val_loss: 0.4054\n",
      "Epoch 205/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0277 - val_loss: 0.4057\n",
      "Epoch 206/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0280 - val_loss: 0.4057\n",
      "Epoch 207/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0280 - val_loss: 0.4057\n",
      "Epoch 208/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0281 - val_loss: 0.4058\n",
      "Epoch 209/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0281 - val_loss: 0.4058\n",
      "Epoch 210/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.026 - 0s 4ms/step - loss: 0.0279 - val_loss: 0.4060\n",
      "Epoch 211/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0276 - val_loss: 0.4061\n",
      "Epoch 212/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0273 - val_loss: 0.4062\n",
      "Epoch 213/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0269 - val_loss: 0.4062\n",
      "Epoch 214/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0266 - val_loss: 0.4062\n",
      "Epoch 215/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0262 - val_loss: 0.4064\n",
      "Epoch 216/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0260 - val_loss: 0.4066\n",
      "Epoch 217/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0259 - val_loss: 0.4069\n",
      "Epoch 218/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0258 - val_loss: 0.4072\n",
      "Epoch 219/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0257 - val_loss: 0.4075\n",
      "Epoch 220/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0256 - val_loss: 0.4080\n",
      "Epoch 221/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0254 - val_loss: 0.4085\n",
      "Epoch 222/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0252 - val_loss: 0.4088\n",
      "Epoch 223/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.029 - 0s 4ms/step - loss: 0.0251 - val_loss: 0.4091\n",
      "Epoch 224/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0251 - val_loss: 0.4093\n",
      "Epoch 225/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0252 - val_loss: 0.4095\n",
      "Epoch 226/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0252 - val_loss: 0.4097\n",
      "Epoch 227/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0252 - val_loss: 0.4098\n",
      "Epoch 228/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0252 - val_loss: 0.4099\n",
      "Epoch 229/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0252 - val_loss: 0.4099\n",
      "Epoch 230/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0251 - val_loss: 0.4100\n",
      "Epoch 231/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0250 - val_loss: 0.4102\n",
      "Epoch 232/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0249 - val_loss: 0.4103\n",
      "Epoch 233/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0249 - val_loss: 0.4104\n",
      "Epoch 234/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0248 - val_loss: 0.4104\n",
      "Epoch 235/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0244 - val_loss: 0.4101\n",
      "Epoch 236/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0240 - val_loss: 0.4100\n",
      "Epoch 237/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0237 - val_loss: 0.4099\n",
      "Epoch 238/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0234 - val_loss: 0.4099\n",
      "Epoch 239/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0233 - val_loss: 0.4099\n",
      "Epoch 240/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0232 - val_loss: 0.4100\n",
      "Epoch 241/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0231 - val_loss: 0.4101\n",
      "Epoch 242/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0229 - val_loss: 0.4103\n",
      "Epoch 243/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0228 - val_loss: 0.4105\n",
      "Epoch 244/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0227 - val_loss: 0.4106\n",
      "Epoch 245/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0225 - val_loss: 0.4107\n",
      "Epoch 246/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0223 - val_loss: 0.4107\n",
      "Epoch 247/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0222 - val_loss: 0.4107\n",
      "Epoch 248/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0220 - val_loss: 0.4107\n",
      "Epoch 249/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0219 - val_loss: 0.4107\n",
      "Epoch 250/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0219 - val_loss: 0.4108\n",
      "Epoch 251/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0219 - val_loss: 0.4110\n",
      "Epoch 252/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0218 - val_loss: 0.4111\n",
      "Epoch 253/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0216 - val_loss: 0.4114\n",
      "Epoch 254/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0214 - val_loss: 0.4118\n",
      "Epoch 255/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0212 - val_loss: 0.4121\n",
      "Epoch 256/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0210 - val_loss: 0.4123\n",
      "Epoch 257/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0209 - val_loss: 0.4124\n",
      "Epoch 258/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0208 - val_loss: 0.4125\n",
      "Epoch 259/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0208 - val_loss: 0.4128\n",
      "Epoch 260/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0207 - val_loss: 0.4132\n",
      "Epoch 261/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0206 - val_loss: 0.4137\n",
      "Epoch 262/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0205 - val_loss: 0.4142\n",
      "Epoch 263/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.024 - 0s 4ms/step - loss: 0.0204 - val_loss: 0.4147\n",
      "Epoch 264/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0203 - val_loss: 0.4151\n",
      "Epoch 265/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0201 - val_loss: 0.4154\n",
      "Epoch 266/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0200 - val_loss: 0.4157\n",
      "Epoch 267/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0199 - val_loss: 0.4159\n",
      "Epoch 268/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0198 - val_loss: 0.4147\n",
      "Epoch 269/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0201 - val_loss: 0.4136\n",
      "Epoch 270/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0202 - val_loss: 0.4128\n",
      "Epoch 271/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0204 - val_loss: 0.4121\n",
      "Epoch 272/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0202 - val_loss: 0.4116\n",
      "Epoch 273/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0202 - val_loss: 0.4113\n",
      "Epoch 274/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0202 - val_loss: 0.4110\n",
      "Epoch 275/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0201 - val_loss: 0.4109\n",
      "Epoch 276/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0200 - val_loss: 0.4109\n",
      "Epoch 277/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0199 - val_loss: 0.4110\n",
      "Epoch 278/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0197 - val_loss: 0.4111\n",
      "Epoch 279/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0195 - val_loss: 0.4113\n",
      "Epoch 280/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0193 - val_loss: 0.4114\n",
      "Epoch 281/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0191 - val_loss: 0.4115\n",
      "Epoch 282/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.4116\n",
      "Epoch 283/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.016 - 0s 4ms/step - loss: 0.0187 - val_loss: 0.4119\n",
      "Epoch 284/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.4123\n",
      "Epoch 285/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0184 - val_loss: 0.4127\n",
      "Epoch 286/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0183 - val_loss: 0.4130\n",
      "Epoch 287/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.4133\n",
      "Epoch 288/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.4136\n",
      "Epoch 289/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.4140\n",
      "Epoch 290/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.4143\n",
      "Epoch 291/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.4145\n",
      "Epoch 292/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.015 - 0s 4ms/step - loss: 0.0176 - val_loss: 0.4147\n",
      "Epoch 293/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0175 - val_loss: 0.4149\n",
      "Epoch 294/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0174 - val_loss: 0.4150\n",
      "Epoch 295/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0174 - val_loss: 0.4152\n",
      "Epoch 296/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0173 - val_loss: 0.4154\n",
      "Epoch 297/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0172 - val_loss: 0.4156\n",
      "Epoch 298/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0171 - val_loss: 0.4157\n",
      "Epoch 299/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0171 - val_loss: 0.4159\n",
      "Epoch 300/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0170 - val_loss: 0.4161\n",
      "Epoch 301/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0169 - val_loss: 0.4163\n",
      "Epoch 302/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0168 - val_loss: 0.4165\n",
      "Epoch 303/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0168 - val_loss: 0.4166\n",
      "Epoch 304/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0167 - val_loss: 0.4168\n",
      "Epoch 305/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0167 - val_loss: 0.4170\n",
      "Epoch 306/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0166 - val_loss: 0.4172\n",
      "Epoch 307/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0165 - val_loss: 0.4174\n",
      "Epoch 308/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0165 - val_loss: 0.4175\n",
      "Epoch 309/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0164 - val_loss: 0.4177\n",
      "Epoch 310/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0163 - val_loss: 0.4179\n",
      "Epoch 311/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0163 - val_loss: 0.4181\n",
      "Epoch 312/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0163 - val_loss: 0.4184\n",
      "Epoch 313/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0162 - val_loss: 0.4187\n",
      "Epoch 314/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0161 - val_loss: 0.4190\n",
      "Epoch 315/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0161 - val_loss: 0.4192\n",
      "Epoch 316/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0160 - val_loss: 0.4194\n",
      "Epoch 317/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0160 - val_loss: 0.4195\n",
      "Epoch 318/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.4197\n",
      "Epoch 319/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.4199\n",
      "Epoch 320/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.4200\n",
      "Epoch 321/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0157 - val_loss: 0.4203\n",
      "Epoch 322/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0157 - val_loss: 0.4206\n",
      "Epoch 323/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0156 - val_loss: 0.4209\n",
      "Epoch 324/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0155 - val_loss: 0.4212\n",
      "Epoch 325/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0155 - val_loss: 0.4216\n",
      "Epoch 326/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.4219\n",
      "Epoch 327/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0153 - val_loss: 0.4222\n",
      "Epoch 328/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0153 - val_loss: 0.4225\n",
      "Epoch 329/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0153 - val_loss: 0.4228\n",
      "Epoch 330/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.011 - 0s 4ms/step - loss: 0.0152 - val_loss: 0.4231\n",
      "Epoch 331/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0152 - val_loss: 0.4233\n",
      "Epoch 332/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.4235\n",
      "Epoch 333/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.015 - 0s 4ms/step - loss: 0.0151 - val_loss: 0.4237\n",
      "Epoch 334/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0150 - val_loss: 0.4239\n",
      "Epoch 335/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0150 - val_loss: 0.4241\n",
      "Epoch 336/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.4243\n",
      "Epoch 337/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.4244\n",
      "Epoch 338/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.4247\n",
      "Epoch 339/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.4249\n",
      "Epoch 340/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.4252\n",
      "Epoch 341/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.4254\n",
      "Epoch 342/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.4253\n",
      "Epoch 343/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.4253\n",
      "Epoch 344/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.4255\n",
      "Epoch 345/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.4257\n",
      "Epoch 346/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.4258\n",
      "Epoch 347/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.4259\n",
      "Epoch 348/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.4260\n",
      "Epoch 349/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.4262\n",
      "Epoch 350/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.4263\n",
      "Epoch 351/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.4265\n",
      "Epoch 352/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.4266\n",
      "Epoch 353/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.4268\n",
      "Epoch 354/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.4270\n",
      "Epoch 355/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.4273\n",
      "Epoch 356/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.4276\n",
      "Epoch 357/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.4278\n",
      "Epoch 358/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.4280\n",
      "Epoch 359/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.4281\n",
      "Epoch 360/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.4282\n",
      "Epoch 361/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.4284\n",
      "Epoch 362/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.4286\n",
      "Epoch 363/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.4288\n",
      "Epoch 364/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.4290\n",
      "Epoch 365/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.016 - 0s 4ms/step - loss: 0.0139 - val_loss: 0.4292\n",
      "Epoch 366/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.4293\n",
      "Epoch 367/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.4294\n",
      "Epoch 368/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.4294\n",
      "Epoch 369/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.4294\n",
      "Epoch 370/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.4292\n",
      "Epoch 371/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.4292\n",
      "Epoch 372/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.4291\n",
      "Epoch 373/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.4289\n",
      "Epoch 374/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.4287\n",
      "Epoch 375/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.4286\n",
      "Epoch 376/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.4286\n",
      "Epoch 377/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.4285\n",
      "Epoch 378/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.4284\n",
      "Epoch 379/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.4282\n",
      "Epoch 380/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.4279\n",
      "Epoch 381/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.4277\n",
      "Epoch 382/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.4277\n",
      "Epoch 383/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.4277\n",
      "Epoch 384/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.4278\n",
      "Epoch 385/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.015 - 0s 4ms/step - loss: 0.0137 - val_loss: 0.4279\n",
      "Epoch 386/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.4282\n",
      "Epoch 387/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.4283\n",
      "Epoch 388/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.4285\n",
      "Epoch 389/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.4286\n",
      "Epoch 390/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.4286\n",
      "Epoch 391/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.4287\n",
      "Epoch 392/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.4289\n",
      "Epoch 393/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.4290\n",
      "Epoch 394/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.4293\n",
      "Epoch 395/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.4294\n",
      "Epoch 396/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.4295\n",
      "Epoch 397/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.4295\n",
      "Epoch 398/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.4296\n",
      "Epoch 399/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.4298\n",
      "Epoch 400/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.4299\n",
      "Epoch 401/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.4301\n",
      "Epoch 402/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.4304\n",
      "Epoch 403/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.4306\n",
      "Epoch 404/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.4307\n",
      "Epoch 405/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.4309\n",
      "Epoch 406/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.4311\n",
      "Epoch 407/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.4314\n",
      "Epoch 408/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.4316\n",
      "Epoch 409/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.4319\n",
      "Epoch 410/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.4320\n",
      "Epoch 411/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.4321\n",
      "Epoch 412/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.4324\n",
      "Epoch 413/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.4327\n",
      "Epoch 414/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.4331\n",
      "Epoch 415/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.4334\n",
      "Epoch 416/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.4336\n",
      "Epoch 417/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.4339\n",
      "Epoch 418/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.4341\n",
      "Epoch 419/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.4343\n",
      "Epoch 420/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.4345\n",
      "Epoch 421/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.4347\n",
      "Epoch 422/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.4349\n",
      "Epoch 423/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.4351\n",
      "Epoch 424/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.4353\n",
      "Epoch 425/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.4356\n",
      "Epoch 426/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.4359\n",
      "Epoch 427/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.4362\n",
      "Epoch 428/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.4366\n",
      "Epoch 429/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.4370\n",
      "Epoch 430/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.4373\n",
      "Epoch 431/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.4376\n",
      "Epoch 432/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.4379\n",
      "Epoch 433/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.4381\n",
      "Epoch 434/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.4383\n",
      "Epoch 435/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.4386\n",
      "Epoch 436/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.4389\n",
      "Epoch 437/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.4391\n",
      "Epoch 438/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.4394\n",
      "Epoch 439/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.4396\n",
      "Epoch 440/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.4399\n",
      "Epoch 441/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.4401\n",
      "Epoch 442/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.4404\n",
      "Epoch 443/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.4406\n",
      "Epoch 444/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.4408\n",
      "Epoch 445/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.4409\n",
      "Epoch 446/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.4410\n",
      "Epoch 447/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.4413\n",
      "Epoch 448/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.4415\n",
      "Epoch 449/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.4417\n",
      "Epoch 450/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.4419\n",
      "Epoch 451/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.4420\n",
      "Epoch 452/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.4421\n",
      "Epoch 453/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.016 - 0s 4ms/step - loss: 0.0116 - val_loss: 0.4422\n",
      "Epoch 454/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.4423\n",
      "Epoch 455/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.4425\n",
      "Epoch 456/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.4426\n",
      "Epoch 457/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.013 - 0s 4ms/step - loss: 0.0116 - val_loss: 0.4428\n",
      "Epoch 458/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.4429\n",
      "Epoch 459/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.4430\n",
      "Epoch 460/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.4432\n",
      "Epoch 461/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.4434\n",
      "Epoch 462/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.4437\n",
      "Epoch 463/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.4441\n",
      "Epoch 464/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.4444\n",
      "Epoch 465/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.4446\n",
      "Epoch 466/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.4448\n",
      "Epoch 467/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.4451\n",
      "Epoch 468/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.4454\n",
      "Epoch 469/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.010 - 0s 4ms/step - loss: 0.0114 - val_loss: 0.4457\n",
      "Epoch 470/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.4460\n",
      "Epoch 471/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.4464\n",
      "Epoch 472/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.4470\n",
      "Epoch 473/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.4475\n",
      "Epoch 474/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.4479\n",
      "Epoch 475/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.4482\n",
      "Epoch 476/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.4484\n",
      "Epoch 477/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.4487\n",
      "Epoch 478/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.4489\n",
      "Epoch 479/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.4492\n",
      "Epoch 480/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.4494\n",
      "Epoch 481/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.4497\n",
      "Epoch 482/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.4499\n",
      "Epoch 483/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.4502\n",
      "Epoch 484/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.4504\n",
      "Epoch 485/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.4506\n",
      "Epoch 486/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.011 - 0s 4ms/step - loss: 0.0112 - val_loss: 0.4508\n",
      "Epoch 487/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.4510\n",
      "Epoch 488/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.013 - 0s 4ms/step - loss: 0.0112 - val_loss: 0.4511\n",
      "Epoch 489/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.4512\n",
      "Epoch 490/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.009 - 0s 4ms/step - loss: 0.0112 - val_loss: 0.4512\n",
      "Epoch 491/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.4513\n",
      "Epoch 492/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.4513\n",
      "Epoch 493/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.4514\n",
      "Epoch 494/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.4515\n",
      "Epoch 495/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.4516\n",
      "Epoch 496/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.4517\n",
      "Epoch 497/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.4516\n",
      "Epoch 498/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.4517\n",
      "Epoch 499/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.4517\n",
      "Epoch 500/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.4517\n",
      "Epoch 501/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.4516\n",
      "Epoch 502/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.008 - 0s 4ms/step - loss: 0.0111 - val_loss: 0.4516\n",
      "Epoch 503/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.4516\n",
      "Epoch 504/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.4516\n",
      "Epoch 505/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.4517\n",
      "Epoch 506/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.4517\n",
      "Epoch 507/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.005 - 0s 4ms/step - loss: 0.0111 - val_loss: 0.4517\n",
      "Epoch 508/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.4518\n",
      "Epoch 509/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.4519\n",
      "Epoch 510/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.4520\n",
      "Epoch 511/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.4522\n",
      "Epoch 512/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.4524\n",
      "Epoch 513/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.4526\n",
      "Epoch 514/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0110 - val_loss: 0.4527\n",
      "Epoch 515/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.4528\n",
      "Epoch 516/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.4529\n",
      "Epoch 517/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0110 - val_loss: 0.4530\n",
      "Epoch 518/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.4530\n",
      "Epoch 519/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.4530\n",
      "Epoch 520/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.4531\n",
      "Epoch 521/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.4532\n",
      "Epoch 522/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0110 - val_loss: 0.4531\n",
      "Epoch 523/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.4531\n",
      "Epoch 524/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.4532\n",
      "Epoch 525/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.4533\n",
      "Epoch 526/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.4534\n",
      "Epoch 527/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.4536\n",
      "Epoch 528/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.4538\n",
      "Epoch 529/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.4539\n",
      "Epoch 530/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0109 - val_loss: 0.4540\n",
      "Epoch 531/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.4541\n",
      "Epoch 532/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.4543\n",
      "Epoch 533/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.017 - 0s 4ms/step - loss: 0.0109 - val_loss: 0.4544\n",
      "Epoch 534/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.4546\n",
      "Epoch 535/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.4548\n",
      "Epoch 536/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.4549\n",
      "Epoch 537/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.4551\n",
      "Epoch 538/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.4553\n",
      "Epoch 539/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4555\n",
      "Epoch 540/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.010 - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4557\n",
      "Epoch 541/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0108 - val_loss: 0.4558\n",
      "Epoch 542/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4560\n",
      "Epoch 543/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4561\n",
      "Epoch 544/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4562\n",
      "Epoch 545/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4562\n",
      "Epoch 546/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0108 - val_loss: 0.4563\n",
      "Epoch 547/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.012 - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4564\n",
      "Epoch 548/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4565\n",
      "Epoch 549/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4566\n",
      "Epoch 550/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4566\n",
      "Epoch 551/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0108 - val_loss: 0.4567\n",
      "Epoch 552/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4568\n",
      "Epoch 553/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4570\n",
      "Epoch 554/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4571\n",
      "Epoch 555/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4573\n",
      "Epoch 556/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4574\n",
      "Epoch 557/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4575\n",
      "Epoch 558/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4577\n",
      "Epoch 559/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0108 - val_loss: 0.4578\n",
      "Epoch 560/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4579\n",
      "Epoch 561/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4579\n",
      "Epoch 562/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4579\n",
      "Epoch 563/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4579\n",
      "Epoch 564/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4578\n",
      "Epoch 565/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4577\n",
      "Epoch 566/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4577\n",
      "Epoch 567/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4577\n",
      "Epoch 568/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4577\n",
      "Epoch 569/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0108 - val_loss: 0.4577\n",
      "Epoch 570/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4577\n",
      "Epoch 571/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.4578\n",
      "Epoch 572/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.013 - 0s 4ms/step - loss: 0.0107 - val_loss: 0.4578\n",
      "Epoch 573/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.017 - 0s 4ms/step - loss: 0.0107 - val_loss: 0.4579\n",
      "Epoch 574/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.4579\n",
      "Epoch 575/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.4580\n",
      "Epoch 576/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.4581\n",
      "Epoch 577/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.4583\n",
      "Epoch 578/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.012 - 0s 4ms/step - loss: 0.0107 - val_loss: 0.4584\n",
      "Epoch 579/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.4585\n",
      "Epoch 580/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.4587\n",
      "Epoch 581/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.4588\n",
      "Epoch 582/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.4589\n",
      "Epoch 583/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.4590\n",
      "Epoch 584/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.4592\n",
      "Epoch 585/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0107 - val_loss: 0.4593\n",
      "Epoch 586/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.4595\n",
      "Epoch 587/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.4597\n",
      "Epoch 588/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.4598\n",
      "Epoch 589/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.4599\n",
      "Epoch 590/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.4599\n",
      "Epoch 591/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.4600\n",
      "Epoch 592/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.4601\n",
      "Epoch 593/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.4602\n",
      "Epoch 594/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.4603\n",
      "Epoch 595/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.4603\n",
      "Epoch 596/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.4604\n",
      "Epoch 597/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.4604\n",
      "Epoch 598/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.4604\n",
      "Epoch 599/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.4605\n",
      "Epoch 600/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.4605\n",
      "Epoch 601/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.4604\n",
      "Epoch 602/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.4603\n",
      "Epoch 603/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.4601\n",
      "Epoch 604/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.4600\n",
      "Epoch 605/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.4599\n",
      "Epoch 606/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.4600\n",
      "Epoch 607/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.4600\n",
      "Epoch 608/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.4601\n",
      "Epoch 609/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.4602\n",
      "Epoch 610/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.4604\n",
      "Epoch 611/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0106 - val_loss: 0.4605\n",
      "Epoch 612/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.4607\n",
      "Epoch 613/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4607\n",
      "Epoch 614/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4607\n",
      "Epoch 615/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4607\n",
      "Epoch 616/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4607\n",
      "Epoch 617/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4607\n",
      "Epoch 618/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4608\n",
      "Epoch 619/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0105 - val_loss: 0.4610\n",
      "Epoch 620/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4611\n",
      "Epoch 621/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4612\n",
      "Epoch 622/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4613\n",
      "Epoch 623/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4614\n",
      "Epoch 624/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4616\n",
      "Epoch 625/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4617\n",
      "Epoch 626/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4619\n",
      "Epoch 627/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4620\n",
      "Epoch 628/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4622\n",
      "Epoch 629/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4624\n",
      "Epoch 630/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4624\n",
      "Epoch 631/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4625\n",
      "Epoch 632/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4625\n",
      "Epoch 633/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4626\n",
      "Epoch 634/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.004 - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4627\n",
      "Epoch 635/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.012 - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4628\n",
      "Epoch 636/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4629\n",
      "Epoch 637/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4631\n",
      "Epoch 638/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4632\n",
      "Epoch 639/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4633\n",
      "Epoch 640/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4635\n",
      "Epoch 641/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4637\n",
      "Epoch 642/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.004 - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4639\n",
      "Epoch 643/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4640\n",
      "Epoch 644/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4642\n",
      "Epoch 645/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.4644\n",
      "Epoch 646/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0104 - val_loss: 0.4645\n",
      "Epoch 647/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.4647\n",
      "Epoch 648/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.4649\n",
      "Epoch 649/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.4650\n",
      "Epoch 650/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.4651\n",
      "Epoch 651/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.4651\n",
      "Epoch 652/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.4651\n",
      "Epoch 653/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.4651\n",
      "Epoch 654/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.017 - 0s 5ms/step - loss: 0.0104 - val_loss: 0.4652\n",
      "Epoch 655/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.4652\n",
      "Epoch 656/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.4653\n",
      "Epoch 657/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.4654\n",
      "Epoch 658/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.4656\n",
      "Epoch 659/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.4657\n",
      "Epoch 660/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.4659\n",
      "Epoch 661/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.005 - 0s 4ms/step - loss: 0.0104 - val_loss: 0.4660\n",
      "Epoch 662/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.4662\n",
      "Epoch 663/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.4663\n",
      "Epoch 664/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.4665\n",
      "Epoch 665/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.4666\n",
      "Epoch 666/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.4668\n",
      "Epoch 667/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4670\n",
      "Epoch 668/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4673\n",
      "Epoch 669/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4675\n",
      "Epoch 670/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4677\n",
      "Epoch 671/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4678\n",
      "Epoch 672/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4680\n",
      "Epoch 673/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4682\n",
      "Epoch 674/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4684\n",
      "Epoch 675/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4685\n",
      "Epoch 676/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4686\n",
      "Epoch 677/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4687\n",
      "Epoch 678/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4687\n",
      "Epoch 679/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4686\n",
      "Epoch 680/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4686\n",
      "Epoch 681/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4685\n",
      "Epoch 682/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4686\n",
      "Epoch 683/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4686\n",
      "Epoch 684/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4687\n",
      "Epoch 685/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4688\n",
      "Epoch 686/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4689\n",
      "Epoch 687/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4690\n",
      "Epoch 688/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4691\n",
      "Epoch 689/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4692\n",
      "Epoch 690/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.009 - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4693\n",
      "Epoch 691/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4692\n",
      "Epoch 692/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4693\n",
      "Epoch 693/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4694\n",
      "Epoch 694/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4695\n",
      "Epoch 695/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4696\n",
      "Epoch 696/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4698\n",
      "Epoch 697/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4699\n",
      "Epoch 698/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0103 - val_loss: 0.4700\n",
      "Epoch 699/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4701\n",
      "Epoch 700/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4701\n",
      "Epoch 701/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4702\n",
      "Epoch 702/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4703\n",
      "Epoch 703/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4705\n",
      "Epoch 704/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4706\n",
      "Epoch 705/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4707\n",
      "Epoch 706/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4708\n",
      "Epoch 707/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4710\n",
      "Epoch 708/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4710\n",
      "Epoch 709/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4709\n",
      "Epoch 710/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4708\n",
      "Epoch 711/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4708\n",
      "Epoch 712/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4707\n",
      "Epoch 713/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4706\n",
      "Epoch 714/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4705\n",
      "Epoch 715/1000\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0103 - val_loss: 0.4705\n",
      "Epoch 716/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4705\n",
      "Epoch 717/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4706\n",
      "Epoch 718/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4707\n",
      "Epoch 719/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4708\n",
      "Epoch 720/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4710\n",
      "Epoch 721/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4711\n",
      "Epoch 722/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.4713\n",
      "Epoch 723/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4714\n",
      "Epoch 724/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4716\n",
      "Epoch 725/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4717\n",
      "Epoch 726/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4718\n",
      "Epoch 727/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4719\n",
      "Epoch 728/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4719\n",
      "Epoch 729/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4719\n",
      "Epoch 730/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4718\n",
      "Epoch 731/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4718\n",
      "Epoch 732/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4719\n",
      "Epoch 733/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4719\n",
      "Epoch 734/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4720\n",
      "Epoch 735/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4721\n",
      "Epoch 736/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4723\n",
      "Epoch 737/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4724\n",
      "Epoch 738/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4725\n",
      "Epoch 739/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4725\n",
      "Epoch 740/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4726\n",
      "Epoch 741/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4727\n",
      "Epoch 742/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4728\n",
      "Epoch 743/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0102 - val_loss: 0.4730\n",
      "Epoch 744/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4731\n",
      "Epoch 745/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4733\n",
      "Epoch 746/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4735\n",
      "Epoch 747/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4737\n",
      "Epoch 748/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4739\n",
      "Epoch 749/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4739\n",
      "Epoch 750/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4740\n",
      "Epoch 751/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4741\n",
      "Epoch 752/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4742\n",
      "Epoch 753/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4742\n",
      "Epoch 754/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.007 - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4744\n",
      "Epoch 755/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4745\n",
      "Epoch 756/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4746\n",
      "Epoch 757/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4748\n",
      "Epoch 758/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4749\n",
      "Epoch 759/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4748\n",
      "Epoch 760/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4747\n",
      "Epoch 761/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4747\n",
      "Epoch 762/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4748\n",
      "Epoch 763/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4748\n",
      "Epoch 764/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4749\n",
      "Epoch 765/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4750\n",
      "Epoch 766/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4751\n",
      "Epoch 767/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4751\n",
      "Epoch 768/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4752\n",
      "Epoch 769/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0102 - val_loss: 0.4752\n",
      "Epoch 770/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4753\n",
      "Epoch 771/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4754\n",
      "Epoch 772/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4754\n",
      "Epoch 773/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4755\n",
      "Epoch 774/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4755\n",
      "Epoch 775/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4756\n",
      "Epoch 776/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4757\n",
      "Epoch 777/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.012 - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4758\n",
      "Epoch 778/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4759\n",
      "Epoch 779/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4761\n",
      "Epoch 780/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4763\n",
      "Epoch 781/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.012 - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4764\n",
      "Epoch 782/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4765\n",
      "Epoch 783/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4766\n",
      "Epoch 784/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4767\n",
      "Epoch 785/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4768\n",
      "Epoch 786/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.4770\n",
      "Epoch 787/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4771\n",
      "Epoch 788/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4772\n",
      "Epoch 789/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4773\n",
      "Epoch 790/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4774\n",
      "Epoch 791/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4774\n",
      "Epoch 792/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4775\n",
      "Epoch 793/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4775\n",
      "Epoch 794/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4776\n",
      "Epoch 795/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.008 - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4777\n",
      "Epoch 796/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4778\n",
      "Epoch 797/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4779\n",
      "Epoch 798/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4781\n",
      "Epoch 799/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4782\n",
      "Epoch 800/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4784\n",
      "Epoch 801/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0101 - val_loss: 0.4786\n",
      "Epoch 802/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4787\n",
      "Epoch 803/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4789\n",
      "Epoch 804/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4791\n",
      "Epoch 805/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4793\n",
      "Epoch 806/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4794\n",
      "Epoch 807/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4796\n",
      "Epoch 808/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4797\n",
      "Epoch 809/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4798\n",
      "Epoch 810/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4800\n",
      "Epoch 811/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4801\n",
      "Epoch 812/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4801\n",
      "Epoch 813/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4801\n",
      "Epoch 814/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4801\n",
      "Epoch 815/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4802\n",
      "Epoch 816/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4803\n",
      "Epoch 817/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4803\n",
      "Epoch 818/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4804\n",
      "Epoch 819/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4805\n",
      "Epoch 820/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4806\n",
      "Epoch 821/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.017 - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4807\n",
      "Epoch 822/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4808\n",
      "Epoch 823/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0101 - val_loss: 0.4809\n",
      "Epoch 824/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4810\n",
      "Epoch 825/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4810\n",
      "Epoch 826/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4811\n",
      "Epoch 827/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4811\n",
      "Epoch 828/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4810\n",
      "Epoch 829/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.008 - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4810\n",
      "Epoch 830/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4810\n",
      "Epoch 831/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4810\n",
      "Epoch 832/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4811\n",
      "Epoch 833/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4811\n",
      "Epoch 834/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4812\n",
      "Epoch 835/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4813\n",
      "Epoch 836/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4814\n",
      "Epoch 837/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4815\n",
      "Epoch 838/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4816\n",
      "Epoch 839/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4817\n",
      "Epoch 840/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.004 - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4818\n",
      "Epoch 841/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4819\n",
      "Epoch 842/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4819\n",
      "Epoch 843/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4820\n",
      "Epoch 844/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4821\n",
      "Epoch 845/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4821\n",
      "Epoch 846/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4822\n",
      "Epoch 847/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4823\n",
      "Epoch 848/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0101 - val_loss: 0.4824\n",
      "Epoch 849/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4825\n",
      "Epoch 850/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4826\n",
      "Epoch 851/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4827\n",
      "Epoch 852/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4828\n",
      "Epoch 853/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0101 - val_loss: 0.4829\n",
      "Epoch 854/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4831\n",
      "Epoch 855/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4833\n",
      "Epoch 856/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4835\n",
      "Epoch 857/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4836\n",
      "Epoch 858/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4837\n",
      "Epoch 859/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4839\n",
      "Epoch 860/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4840\n",
      "Epoch 861/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4842\n",
      "Epoch 862/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4843\n",
      "Epoch 863/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4844\n",
      "Epoch 864/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4845\n",
      "Epoch 865/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.4847\n",
      "Epoch 866/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4848\n",
      "Epoch 867/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4850\n",
      "Epoch 868/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4852\n",
      "Epoch 869/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4853\n",
      "Epoch 870/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4855\n",
      "Epoch 871/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4856\n",
      "Epoch 872/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4855\n",
      "Epoch 873/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4855\n",
      "Epoch 874/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4856\n",
      "Epoch 875/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4857\n",
      "Epoch 876/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4858\n",
      "Epoch 877/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4858\n",
      "Epoch 878/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4859\n",
      "Epoch 879/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4860\n",
      "Epoch 880/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4861\n",
      "Epoch 881/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4861\n",
      "Epoch 882/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4862\n",
      "Epoch 883/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4862\n",
      "Epoch 884/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4863\n",
      "Epoch 885/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4864\n",
      "Epoch 886/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4865\n",
      "Epoch 887/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4866\n",
      "Epoch 888/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4867\n",
      "Epoch 889/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0100 - val_loss: 0.4869\n",
      "Epoch 890/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4871\n",
      "Epoch 891/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4872\n",
      "Epoch 892/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4874\n",
      "Epoch 893/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4876\n",
      "Epoch 894/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4877\n",
      "Epoch 895/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4879\n",
      "Epoch 896/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4881\n",
      "Epoch 897/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4883\n",
      "Epoch 898/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4884\n",
      "Epoch 899/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4884\n",
      "Epoch 900/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4883\n",
      "Epoch 901/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4882\n",
      "Epoch 902/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4882\n",
      "Epoch 903/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4882\n",
      "Epoch 904/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4882\n",
      "Epoch 905/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4883\n",
      "Epoch 906/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4884\n",
      "Epoch 907/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4884\n",
      "Epoch 908/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4883\n",
      "Epoch 909/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4883\n",
      "Epoch 910/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4883\n",
      "Epoch 911/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4883\n",
      "Epoch 912/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4883\n",
      "Epoch 913/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4884\n",
      "Epoch 914/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4885\n",
      "Epoch 915/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4886\n",
      "Epoch 916/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4887\n",
      "Epoch 917/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4889\n",
      "Epoch 918/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4890\n",
      "Epoch 919/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4891\n",
      "Epoch 920/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4892\n",
      "Epoch 921/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4893\n",
      "Epoch 922/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4894\n",
      "Epoch 923/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4895\n",
      "Epoch 924/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4896\n",
      "Epoch 925/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.012 - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4897\n",
      "Epoch 926/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0100 - val_loss: 0.4897\n",
      "Epoch 927/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4898\n",
      "Epoch 928/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4899\n",
      "Epoch 929/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4900\n",
      "Epoch 930/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4901\n",
      "Epoch 931/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.007 - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4902\n",
      "Epoch 932/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4903\n",
      "Epoch 933/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4905\n",
      "Epoch 934/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4906\n",
      "Epoch 935/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4907\n",
      "Epoch 936/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4908\n",
      "Epoch 937/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4910\n",
      "Epoch 938/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4911\n",
      "Epoch 939/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4911\n",
      "Epoch 940/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4910\n",
      "Epoch 941/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4910\n",
      "Epoch 942/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4910\n",
      "Epoch 943/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4911\n",
      "Epoch 944/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4912\n",
      "Epoch 945/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4913\n",
      "Epoch 946/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4914\n",
      "Epoch 947/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4914\n",
      "Epoch 948/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4912\n",
      "Epoch 949/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4912\n",
      "Epoch 950/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4911\n",
      "Epoch 951/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4911\n",
      "Epoch 952/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4911\n",
      "Epoch 953/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4911\n",
      "Epoch 954/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4912\n",
      "Epoch 955/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4912\n",
      "Epoch 956/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4914\n",
      "Epoch 957/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.017 - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4914\n",
      "Epoch 958/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4915\n",
      "Epoch 959/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.002 - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4916\n",
      "Epoch 960/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4916\n",
      "Epoch 961/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4914\n",
      "Epoch 962/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4914\n",
      "Epoch 963/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4913\n",
      "Epoch 964/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4913\n",
      "Epoch 965/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4913\n",
      "Epoch 966/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4914\n",
      "Epoch 967/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4915\n",
      "Epoch 968/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4916\n",
      "Epoch 969/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4916\n",
      "Epoch 970/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4917\n",
      "Epoch 971/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4918\n",
      "Epoch 972/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0100 - val_loss: 0.4918\n",
      "Epoch 973/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4919\n",
      "Epoch 974/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4919\n",
      "Epoch 975/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4920\n",
      "Epoch 976/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4920\n",
      "Epoch 977/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4921\n",
      "Epoch 978/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4922\n",
      "Epoch 979/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4922\n",
      "Epoch 980/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4923\n",
      "Epoch 981/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4924\n",
      "Epoch 982/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4924\n",
      "Epoch 983/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4925\n",
      "Epoch 984/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4926\n",
      "Epoch 985/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4927\n",
      "Epoch 986/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4927\n",
      "Epoch 987/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.007 - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4928\n",
      "Epoch 988/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4928\n",
      "Epoch 989/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4928\n",
      "Epoch 990/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4929\n",
      "Epoch 991/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4930\n",
      "Epoch 992/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4931\n",
      "Epoch 993/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4931\n",
      "Epoch 994/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4932\n",
      "Epoch 995/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4933\n",
      "Epoch 996/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4934\n",
      "Epoch 997/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4935\n",
      "Epoch 998/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4935\n",
      "Epoch 999/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4935\n",
      "Epoch 1000/1000\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.4936\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(8, activation = 'relu', input_shape = (1000,)))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam')\n",
    "\n",
    "history = model.fit(Z_train, y_train, validation_data = (Z_test, y_test), batch_size = 512, \n",
    "                   epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eab6b40b-b459-41e3-b7e5-6c022d9afff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history['loss'], c='g');      # green - training loss # Loss\n",
    "plt.plot(history.epoch, history.history['val_loss'], c='b');  # blue - test loss # Val loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7ecfd-0d99-4509-8156-6e860112be9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c96bf29-2d47-481a-89fd-b0546c183932",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#credit to: lesson 7.6\n",
    "def model_func(layers, loss_fn = 'binary_crossentropy'):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    flag_first = True\n",
    "    \n",
    "    for layer in layers:\n",
    "        if flag_first:\n",
    "            model.add(Dense(layer, activation = 'relu', input_shape = (14258,)))\n",
    "            flag_first = False\n",
    "        else:\n",
    "            model.add(Dense(layer, activation = 'relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(loss = loss_fn, optimizer = 'adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "nn = KerasClassifier(build_fn = model, batch_size = 512, epochs = 20, verbose = 0)\n",
    "\n",
    "params = {'batch_size': [126, 512],\n",
    "          'epochs': [10, 15, 20]\n",
    "         }\n",
    "\n",
    "grid = GridSearchCV(nn, params, cv = 3, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8953eb9-b97b-442a-9e9b-9fa8306fa3c9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sc = StandardScaler()\n",
    "Xs_train = sc.fit_transform(X_train)\n",
    "grid.fit(Xs_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
